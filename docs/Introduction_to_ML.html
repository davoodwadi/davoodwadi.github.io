<!DOCTYPE html>
<html xmlns="http://www.w3.org/1999/xhtml" lang="en" xml:lang="en"><head>

<meta charset="utf-8">
<meta name="generator" content="quarto-1.3.450">

<meta name="viewport" content="width=device-width, initial-scale=1.0, user-scalable=yes">


<title>Davood Wadi - MATH60629A Fall 2022</title>
<style>
code{white-space: pre-wrap;}
span.smallcaps{font-variant: small-caps;}
div.columns{display: flex; gap: min(4vw, 1.5em);}
div.column{flex: auto; overflow-x: auto;}
div.hanging-indent{margin-left: 1.5em; text-indent: -1.5em;}
ul.task-list{list-style: none;}
ul.task-list li input[type="checkbox"] {
  width: 0.8em;
  margin: 0 0.8em 0.2em -1em; /* quarto-specific, see https://github.com/quarto-dev/quarto-cli/issues/4556 */ 
  vertical-align: middle;
}
/* CSS for syntax highlighting */
pre > code.sourceCode { white-space: pre; position: relative; }
pre > code.sourceCode > span { display: inline-block; line-height: 1.25; }
pre > code.sourceCode > span:empty { height: 1.2em; }
.sourceCode { overflow: visible; }
code.sourceCode > span { color: inherit; text-decoration: inherit; }
div.sourceCode { margin: 1em 0; }
pre.sourceCode { margin: 0; }
@media screen {
div.sourceCode { overflow: auto; }
}
@media print {
pre > code.sourceCode { white-space: pre-wrap; }
pre > code.sourceCode > span { text-indent: -5em; padding-left: 5em; }
}
pre.numberSource code
  { counter-reset: source-line 0; }
pre.numberSource code > span
  { position: relative; left: -4em; counter-increment: source-line; }
pre.numberSource code > span > a:first-child::before
  { content: counter(source-line);
    position: relative; left: -1em; text-align: right; vertical-align: baseline;
    border: none; display: inline-block;
    -webkit-touch-callout: none; -webkit-user-select: none;
    -khtml-user-select: none; -moz-user-select: none;
    -ms-user-select: none; user-select: none;
    padding: 0 4px; width: 4em;
  }
pre.numberSource { margin-left: 3em;  padding-left: 4px; }
div.sourceCode
  {   }
@media screen {
pre > code.sourceCode > span > a:first-child::before { text-decoration: underline; }
}
</style>


<script src="site_libs/quarto-nav/quarto-nav.js"></script>
<script src="site_libs/quarto-nav/headroom.min.js"></script>
<script src="site_libs/clipboard/clipboard.min.js"></script>
<script src="site_libs/quarto-search/autocomplete.umd.js"></script>
<script src="site_libs/quarto-search/fuse.min.js"></script>
<script src="site_libs/quarto-search/quarto-search.js"></script>
<meta name="quarto:offset" content="./">
<script src="site_libs/quarto-html/quarto.js"></script>
<script src="site_libs/quarto-html/popper.min.js"></script>
<script src="site_libs/quarto-html/tippy.umd.min.js"></script>
<script src="site_libs/quarto-html/anchor.min.js"></script>
<link href="site_libs/quarto-html/tippy.css" rel="stylesheet">
<link href="site_libs/quarto-html/quarto-syntax-highlighting.css" rel="stylesheet" id="quarto-text-highlighting-styles">
<script src="site_libs/bootstrap/bootstrap.min.js"></script>
<link href="site_libs/bootstrap/bootstrap-icons.css" rel="stylesheet">
<link href="site_libs/bootstrap/bootstrap.min.css" rel="stylesheet" id="quarto-bootstrap" data-mode="light">
<script id="quarto-search-options" type="application/json">{
  "location": "navbar",
  "copy-button": false,
  "collapse-after": 3,
  "panel-placement": "end",
  "type": "overlay",
  "limit": 20,
  "language": {
    "search-no-results-text": "No results",
    "search-matching-documents-text": "matching documents",
    "search-copy-link-title": "Copy link to search",
    "search-hide-matches-text": "Hide additional matches",
    "search-more-match-text": "more match in this document",
    "search-more-matches-text": "more matches in this document",
    "search-clear-button-title": "Clear",
    "search-detached-cancel-button-title": "Cancel",
    "search-submit-button-title": "Submit",
    "search-label": "Search"
  }
}</script>
<script src="https://cdnjs.cloudflare.com/ajax/libs/require.js/2.3.6/require.min.js" integrity="sha512-c3Nl8+7g4LMSTdrm621y7kf9v3SDPnhxLNhcjFJbKECVnmZHTdo+IRO05sNLTH/D3vA6u1X32ehoLC7WFVdheg==" crossorigin="anonymous"></script>
<script src="https://cdnjs.cloudflare.com/ajax/libs/jquery/3.5.1/jquery.min.js" integrity="sha512-bLT0Qm9VnAYZDflyKcBaQ2gg0hSYNQrJ8RilYldYQ1FxQYoCLtUjuuRuZo+fjqhx/qtq/1itJ0C2ejDxltZVFg==" crossorigin="anonymous"></script>
<script type="application/javascript">define('jquery', [],function() {return window.jQuery;})</script>

  <script src="https://polyfill.io/v3/polyfill.min.js?features=es6"></script>
  <script src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-chtml-full.js" type="text/javascript"></script>

<link rel="stylesheet" href="styles.css">
</head>

<body class="nav-fixed">

<div id="quarto-search-results"></div>
  <header id="quarto-header" class="headroom fixed-top">
    <nav class="navbar navbar-expand-lg navbar-dark ">
      <div class="navbar-container container-fluid">
      <div class="navbar-brand-container">
    <a class="navbar-brand" href="./index.html">
    <span class="navbar-title">Davood Wadi</span>
    </a>
  </div>
            <div id="quarto-search" class="" title="Search"></div>
          <button class="navbar-toggler" type="button" data-bs-toggle="collapse" data-bs-target="#navbarCollapse" aria-controls="navbarCollapse" aria-expanded="false" aria-label="Toggle navigation" onclick="if (window.quartoToggleHeadroom) { window.quartoToggleHeadroom(); }">
  <span class="navbar-toggler-icon"></span>
</button>
          <div class="collapse navbar-collapse" id="navbarCollapse">
            <ul class="navbar-nav navbar-nav-scroll me-auto">
  <li class="nav-item">
    <a class="nav-link" href="./index.html" rel="" target="">
 <span class="menu-text">Home</span></a>
  </li>  
  <li class="nav-item dropdown ">
    <a class="nav-link dropdown-toggle" href="#" id="nav-menu-courses" role="button" data-bs-toggle="dropdown" aria-expanded="false" rel="" target="">
 <span class="menu-text">Courses</span>
    </a>
    <ul class="dropdown-menu" aria-labelledby="nav-menu-courses">    
        <li>
    <a class="dropdown-item" href="https://professional.mit.edu/course-catalog/applied-data-science-program-leveraging-ai-effective-decision-making" rel="" target="">
 <span class="dropdown-text">MIT ADSP</span></a>
  </li>  
        <li>
    <a class="dropdown-item" href="./courses.html" rel="" target="">
 <span class="dropdown-text">MATH60629A</span></a>
  </li>  
    </ul>
  </li>
</ul>
            <div class="quarto-navbar-tools ms-auto">
</div>
          </div> <!-- /navcollapse -->
      </div> <!-- /container-fluid -->
    </nav>
</header>
<!-- content -->
<div id="quarto-content" class="quarto-container page-columns page-rows-contents page-layout-article page-navbar">
<!-- sidebar -->
<!-- margin-sidebar -->
    <div id="quarto-margin-sidebar" class="sidebar margin-sidebar">
        <nav id="TOC" role="doc-toc" class="toc-active">
    <h2 id="toc-title">On this page</h2>
   
  <ul>
  <li><a href="#tutorial-an-introduction-to-practical-machine-learning" id="toc-tutorial-an-introduction-to-practical-machine-learning" class="nav-link active" data-scroll-target="#tutorial-an-introduction-to-practical-machine-learning">Tutorial: An Introduction to Practical Machine Learning</a>
  <ul class="collapse">
  <li><a href="#authors" id="toc-authors" class="nav-link" data-scroll-target="#authors">Authors:</a></li>
  <li><a href="#table-of-content" id="toc-table-of-content" class="nav-link" data-scroll-target="#table-of-content">Table of Content</a></li>
  <li><a href="#machine-learning-terminology" id="toc-machine-learning-terminology" class="nav-link" data-scroll-target="#machine-learning-terminology">Machine Learning terminology</a></li>
  <li><a href="#setting-up-the-data" id="toc-setting-up-the-data" class="nav-link" data-scroll-target="#setting-up-the-data">Setting up the data</a></li>
  <li><a href="#start" id="toc-start" class="nav-link" data-scroll-target="#start">Start</a>
  <ul class="collapse">
  <li><a href="#a-first-model-mean-predictor" id="toc-a-first-model-mean-predictor" class="nav-link" data-scroll-target="#a-first-model-mean-predictor">2.1 A first model: mean predictor</a></li>
  <li><a href="#linear-regression" id="toc-linear-regression" class="nav-link" data-scroll-target="#linear-regression">2.2 Linear regression</a></li>
  <li><a href="#linear-regression-with-tag-featurescovariates" id="toc-linear-regression-with-tag-featurescovariates" class="nav-link" data-scroll-target="#linear-regression-with-tag-featurescovariates">2.3 Linear regression with tag features/covariates</a></li>
  <li><a href="#fitting-a-non-linear-model" id="toc-fitting-a-non-linear-model" class="nav-link" data-scroll-target="#fitting-a-non-linear-model">2.4 Fitting a non-linear model</a></li>
  </ul></li>
  <li><a href="#references" id="toc-references" class="nav-link" data-scroll-target="#references">References</a></li>
  </ul></li>
  </ul>
</nav>
    </div>
<!-- main -->
<main class="content" id="quarto-document-content">

<header id="title-block-header" class="quarto-title-block default">
<div class="quarto-title">
<h1 class="title">MATH60629A Fall 2022</h1>
</div>



<div class="quarto-title-meta">

    
  
    
  </div>
  

</header>

<section id="tutorial-an-introduction-to-practical-machine-learning" class="level1">
<h1>Tutorial: An Introduction to Practical Machine Learning</h1>
<p>This tutorial provides a short introduction to the practice of machine learning.</p>
<p>We assume that the user already has an understanding of the basic concepts that underlie the field. We review both methodological concepts like supervised learning and also use software libraries such as <code>scikit-learn</code>, <code>pandas</code>, and <code>numpy</code>.</p>
<p>In particular, we will: 1. load some data, 2. fit different supervised models on variations of the data, 3. and compare results.</p>
<p>This tutorial is not meant to be exhaustive (references are provided throughout, and links to extra material are provided at the end).</p>
<section id="authors" class="level3">
<h3 class="anchored" data-anchor-id="authors">Authors:</h3>
<ul>
<li>Laurent Charlin <a href="mailto:lcharlin@gmail.com" class="email">lcharlin@gmail.com</a></li>
</ul>
</section>
<section id="table-of-content" class="level3">
<h3 class="anchored" data-anchor-id="table-of-content">Table of Content</h3>
<ul>
<li><a href="#introduction">Section 0. Introduction</a></li>
<li><a href="#pre-processing">Section 1. Data Pre-Processing</a></li>
<li><a href="#modelling">Section 2. Modelling</a></li>
<li><a href="#concluding-remarks">Section 3. Concluding Remarks</a></li>
</ul>
<p><a id="introduction"></a> ### Section 0. Introduction We will use the example of a recommender system, i.e., a system which must recommend movies of interests to its users (e.g., Netflix). We will model user-movie preferences from a popular publicly available dataset (Movielens 1M). We will learn, from past user-movie ratings, to predict (missing/future) user-movie ratings from user socio-demographics and movie-tags data.</p>
<p>Mathematically, we are interested in learning the (parameters of the) following function:</p>
<p><span class="math display">\[ r_{um} = f_\theta(x_u, x_m)\]</span> where - <span class="math inline">\(u\)</span> indexes users - <span class="math inline">\(m\)</span> indexes items - <span class="math inline">\(r_{um}\)</span> is u’s rating for m (that user’s preference) – the dependent variable - <span class="math inline">\(f_\theta\)</span> is some model parametrized by <span class="math inline">\(\theta\)</span>. For example, a linear regression with coefficients <span class="math inline">\(\theta\)</span> - <span class="math inline">\(x_u\)</span> are user u’s covariates (e.g., age and occupation of this user) - <span class="math inline">\(x_m\)</span> are movie m’s covariates (e.g., tags associated with the movie)</p>
<p>The function <span class="math inline">\(f\)</span> can take several forms (in other words, we can use a variety of models for this task). In today’s tutorial we will assume that the problem is a regression one and we will experiment with several models ranging from a simple linear regression model to a more complicated two-hidden layer neural network.</p>
</section>
<section id="machine-learning-terminology" class="level3">
<h3 class="anchored" data-anchor-id="machine-learning-terminology">Machine Learning terminology</h3>
<p>It can be useful to think of machine learning as comprising three elements: 1. Task (T) 2. Experience (E) 3. Performance measure (P).</p>
<p>(a good description of these concepts is provided in <a href="https://www.deeplearningbook.org/contents/ml.html">Ch. 5 of the Deep Learning Book</a>)</p>
<p>The intuition is that the task (T) is “the type of problem you are trying the solve” (e.g., classification, regression, anomaly detection), the experience (E) is “how your data comes about” (e.g., does it come with labels or not, do you observe it all at once or as a stream), and the performance (P) is “how well your model does”. Standard performance measures include accuracy and mean-squared error.</p>
<p>Note that the above terminology does not define the model used to learn (fit) the data nor does it define the fitting procedure (e.g., gradient descent).</p>
<p>Relationship to the problem of rating prediction: - Task: Our task is to predict user-movie ratings. It can be modelled in different ways (more on this during week 11), but here we will model it as a regression problem. - Experience: The experience is a supervised learning one because we are predicting some dependent variable (rating) from a set of independent variables - Performance measure: We will be using the mean-squared error (MSE).</p>
</section>
<section id="setting-up-the-data" class="level3">
<h3 class="anchored" data-anchor-id="setting-up-the-data">Setting up the data</h3>
<p>For supervised learning, it is customary, to construct two data matrix <span class="math inline">\(X\)</span> and <span class="math inline">\(Y\)</span>. The former, <span class="math inline">\(X\)</span>, contains the covariates (features). It is a matrix of size <span class="math inline">\(n \times p\)</span> with <span class="math inline">\(n\)</span> the number of examples and <span class="math inline">\(p\)</span> the dimensionality of each example (in other words the number of covariates associated with each example). They are the input to the function.</p>
<p><span class="math display">\[X = \begin{bmatrix}
x_{11} &amp; x_{12} &amp; \ldots &amp; x_{1p} \\
\vdots &amp; \vdots       &amp;  \ddots      &amp; \vdots \\
x_{n1} &amp; x_{12} &amp; \ldots &amp; x_{np} \\
\end{bmatrix}
\]</span></p>
<p>The latter, <span class="math inline">\(Y\)</span>, is a (column) vector of length <span class="math inline">\(n\)</span> which contains the labels (here ratings). <span class="math inline">\(Y_1\)</span> corresponds to the rating of <span class="math inline">\(X_1\)</span> (row contains the labels (here ratings).</p>
<p><span class="math display">\[
Y = \begin{bmatrix}
r_1 \\
r_2 \\
\vdots \\
r_n
\end{bmatrix}\]</span></p>
<p>Of course, in a real problem we will differentiate the <code>train</code> and <code>test</code> sets, e.g., with <span class="math inline">\(X_\text{train}\)</span> and <span class="math inline">\(X_\text{test}\)</span>. Same for the labels using, e.g., <span class="math inline">\(Y_\text{train}\)</span> and <span class="math inline">\(Y_\text{test}\)</span>.</p>
</section>
<section id="start" class="level2">
<h2 class="anchored" data-anchor-id="start">Start</h2>
<p>Following this brief introduction, we now dive into the problem.</p>
<div class="cell" data-outputid="4cb1925c-c400-4c66-fbaa-2acfec742bae">
<div class="sourceCode cell-code" id="cb1"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb1-1"><a href="#cb1-1" aria-hidden="true" tabindex="-1"></a><span class="co"># We first download the repo to get access to data and some utility code (This is specifically for colab.)</span></span>
<span id="cb1-2"><a href="#cb1-2" aria-hidden="true" tabindex="-1"></a><span class="op">!</span>rm <span class="op">-</span>rf <span class="dv">80</span><span class="op">-</span><span class="dv">629</span><span class="op">/</span></span>
<span id="cb1-3"><a href="#cb1-3" aria-hidden="true" tabindex="-1"></a><span class="op">!</span>git clone https:<span class="op">//</span>github.com<span class="op">/</span>lcharlin<span class="op">/</span><span class="dv">80</span><span class="op">-</span><span class="dv">629</span><span class="op">/</span></span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>Cloning into '80-629'...
remote: Enumerating objects: 25, done.
remote: Counting objects: 100% (25/25), done.
remote: Compressing objects: 100% (15/15), done.
remote: Total 77 (delta 16), reused 19 (delta 10), pack-reused 52
Unpacking objects: 100% (77/77), done.</code></pre>
</div>
</div>
<p>We begin by importing the packages that we will need: - <code>reduce</code> function will come in handy to iteratively process data - <code>os</code> standard packages for performing system operations (e.g., opening files) - <code>re</code> package for regex - <code>sys</code> package to deal with system-level operations (here used to change the search path) - <code>time</code> package we will use to measure the duration of certain operations</p>
<ul>
<li><code>matplotlib</code> for plotting</li>
<li><code>numpy</code> for linear-algebra computations</li>
<li><code>pandas</code> for data wrangling</li>
<li><code>sklearn</code> (scikit-learn) for machine learning models and useful machine learning related routines</li>
</ul>
<div class="cell">
<div class="sourceCode cell-code" id="cb3"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb3-1"><a href="#cb3-1" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> functools <span class="im">import</span> <span class="bu">reduce</span></span>
<span id="cb3-2"><a href="#cb3-2" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> os</span>
<span id="cb3-3"><a href="#cb3-3" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> re</span>
<span id="cb3-4"><a href="#cb3-4" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> time</span>
<span id="cb3-5"><a href="#cb3-5" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb3-6"><a href="#cb3-6" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> numpy <span class="im">as</span> np</span>
<span id="cb3-7"><a href="#cb3-7" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> pandas <span class="im">as</span> pd</span>
<span id="cb3-8"><a href="#cb3-8" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb3-9"><a href="#cb3-9" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb3-10"><a href="#cb3-10" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> matplotlib.pyplot <span class="im">as</span> plt</span>
<span id="cb3-11"><a href="#cb3-11" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> sklearn <span class="im">import</span> preprocessing</span>
<span id="cb3-12"><a href="#cb3-12" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> sklearn <span class="im">import</span> datasets, linear_model</span>
<span id="cb3-13"><a href="#cb3-13" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> sklearn.metrics <span class="im">import</span> mean_squared_error, r2_score</span>
<span id="cb3-14"><a href="#cb3-14" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> sklearn.model_selection <span class="im">import</span> train_test_split</span>
<span id="cb3-15"><a href="#cb3-15" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> sklearn <span class="im">import</span> neural_network</span>
<span id="cb3-16"><a href="#cb3-16" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb3-17"><a href="#cb3-17" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> sys</span>
<span id="cb3-18"><a href="#cb3-18" aria-hidden="true" tabindex="-1"></a>sys.path <span class="op">+=</span> [<span class="st">'80-629/week4-PracticalSession/'</span>]</span>
<span id="cb3-19"><a href="#cb3-19" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> local_utils <span class="im">import</span> DrawNN</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<p><a id="pre-processing"></a> # Section 1: Data Pre-Processing</p>
<p>In the following we load data from several csv files and pre-process it.</p>
<p>While this is not really machine learning, machine learning needs data and so knowing how to manipulate (and how to plot) data in python is quite useful. (In fact, in lots of use cases, data acquisition and cleaning will often take more of your time than running the machine learning models.)</p>
<p><strong>I suggest that you read this section, but that you spend most of your time on the other sections. If you have time at the end, you can come back and do this more thoroughly.</strong></p>
<section id="details" class="level4">
<h4 class="anchored" data-anchor-id="details">Details</h4>
<p>We will use the publically available <a href="https://grouplens.org/datasets/movielens/">movielens dataset</a>. The group behind movielens has released several useful datasets in the last 20 years. Here we will focus on the <a href="https://grouplens.org/datasets/movielens/1m/">ML-1M data</a> (it contains 1M ratings) but we will also use movie tags from the <a href="https://grouplens.org/datasets/movielens/20m/">ML-20M dataset</a> (20M ratings).</p>
<p>Except for downloading the dataset (to save you some time), I have not processed nor modified the data in any way.</p>
<div class="cell">
<div class="sourceCode cell-code" id="cb4"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb4-1"><a href="#cb4-1" aria-hidden="true" tabindex="-1"></a>ROOT_DIR<span class="op">=</span><span class="st">'80-629/week4-PracticalSession'</span></span>
<span id="cb4-2"><a href="#cb4-2" aria-hidden="true" tabindex="-1"></a>DATA_DIR<span class="op">=</span>os.path.join(ROOT_DIR, <span class="st">'dat/ml-1m/'</span>) <span class="co"># this is where most of our data lives</span></span>
<span id="cb4-3"><a href="#cb4-3" aria-hidden="true" tabindex="-1"></a>DATA_DIR_20ML<span class="op">=</span>os.path.join(ROOT_DIR, <span class="st">'dat/ml-20m/'</span>) <span class="co"># for the tags data</span></span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
</section>
<section id="load-movie-namesgenres" class="level4">
<h4 class="anchored" data-anchor-id="load-movie-namesgenres">Load Movie Names/Genres</h4>
<p>We begin by loading the data that describes movies in the ML-1M dataset. Each line in the file contains one entry in the following format <code>MovieID::Name::Genres</code>.</p>
<p>After loading into a pandas <code>dataFrame</code> structure, we will have movie names (<code>mName</code>), IDs (<code>mid</code>), and movie genres (<code>mGenres</code>)</p>
<div class="cell">
<div class="sourceCode cell-code" id="cb5"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb5-1"><a href="#cb5-1" aria-hidden="true" tabindex="-1"></a>movies_pd <span class="op">=</span> pd.read_csv(os.path.join(DATA_DIR, <span class="st">'movies.dat'</span>),</span>
<span id="cb5-2"><a href="#cb5-2" aria-hidden="true" tabindex="-1"></a>                        sep<span class="op">=</span><span class="st">'::'</span>,</span>
<span id="cb5-3"><a href="#cb5-3" aria-hidden="true" tabindex="-1"></a>                        names<span class="op">=</span>[<span class="st">'mid'</span>, <span class="st">'mName'</span>, <span class="st">'mGenres'</span>], engine<span class="op">=</span><span class="st">'python'</span>,</span>
<span id="cb5-4"><a href="#cb5-4" aria-hidden="true" tabindex="-1"></a>                        encoding<span class="op">=</span><span class="st">'latin-1'</span>)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<div class="cell" data-outputid="4a7f0494-232b-47d5-a60d-5c3e55ef3268">
<div class="sourceCode cell-code" id="cb6"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb6-1"><a href="#cb6-1" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="ss">f'The dataset contains </span><span class="sc">{</span>movies_pd<span class="sc">.</span>shape[<span class="dv">0</span>]<span class="sc">}</span><span class="ss"> movies'</span>)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>The dataset contains 3883 movies</code></pre>
</div>
</div>
<div class="cell" data-outputid="b542617f-0d0f-4326-881e-444344faee45">
<div class="sourceCode cell-code" id="cb8"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb8-1"><a href="#cb8-1" aria-hidden="true" tabindex="-1"></a>display(movies_pd.head())</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-display">
<div>


<table class="dataframe table table-sm table-striped small" data-quarto-postprocess="true" data-border="1">
<thead>
<tr class="header">
<th data-quarto-table-cell-role="th"></th>
<th data-quarto-table-cell-role="th">mid</th>
<th data-quarto-table-cell-role="th">mName</th>
<th data-quarto-table-cell-role="th">mGenres</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td data-quarto-table-cell-role="th">0</td>
<td>1</td>
<td>Toy Story (1995)</td>
<td>Animation|Children's|Comedy</td>
</tr>
<tr class="even">
<td data-quarto-table-cell-role="th">1</td>
<td>2</td>
<td>Jumanji (1995)</td>
<td>Adventure|Children's|Fantasy</td>
</tr>
<tr class="odd">
<td data-quarto-table-cell-role="th">2</td>
<td>3</td>
<td>Grumpier Old Men (1995)</td>
<td>Comedy|Romance</td>
</tr>
<tr class="even">
<td data-quarto-table-cell-role="th">3</td>
<td>4</td>
<td>Waiting to Exhale (1995)</td>
<td>Comedy|Drama</td>
</tr>
<tr class="odd">
<td data-quarto-table-cell-role="th">4</td>
<td>5</td>
<td>Father of the Bride Part II (1995)</td>
<td>Comedy</td>
</tr>
</tbody>
</table>

</div>
</div>
</div>
<p>Using pandas we can also search for movies by <code>mid</code> or by their name:</p>
<div class="cell" data-outputid="c626fbc4-2cd2-4f11-c1c0-43f16648f610">
<div class="sourceCode cell-code" id="cb9"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb9-1"><a href="#cb9-1" aria-hidden="true" tabindex="-1"></a>mid <span class="op">=</span> <span class="dv">10</span></span>
<span id="cb9-2"><a href="#cb9-2" aria-hidden="true" tabindex="-1"></a>display(movies_pd[movies_pd.mid<span class="op">==</span>mid])</span>
<span id="cb9-3"><a href="#cb9-3" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb9-4"><a href="#cb9-4" aria-hidden="true" tabindex="-1"></a>name <span class="op">=</span> <span class="st">'Machine'</span></span>
<span id="cb9-5"><a href="#cb9-5" aria-hidden="true" tabindex="-1"></a>display(movies_pd[movies_pd.mName.<span class="bu">str</span>.contains(name,</span>
<span id="cb9-6"><a href="#cb9-6" aria-hidden="true" tabindex="-1"></a>                                               regex<span class="op">=</span><span class="va">False</span>, case<span class="op">=</span><span class="va">False</span>)])</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-display">
<div>


<table class="dataframe table table-sm table-striped small" data-quarto-postprocess="true" data-border="1">
<thead>
<tr class="header">
<th data-quarto-table-cell-role="th"></th>
<th data-quarto-table-cell-role="th">mid</th>
<th data-quarto-table-cell-role="th">mName</th>
<th data-quarto-table-cell-role="th">mGenres</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td data-quarto-table-cell-role="th">9</td>
<td>10</td>
<td>GoldenEye (1995)</td>
<td>Action|Adventure|Thriller</td>
</tr>
</tbody>
</table>

</div>
</div>
<div class="cell-output cell-output-display">
<div>


<table class="dataframe table table-sm table-striped small" data-quarto-postprocess="true" data-border="1">
<thead>
<tr class="header">
<th data-quarto-table-cell-role="th"></th>
<th data-quarto-table-cell-role="th">mid</th>
<th data-quarto-table-cell-role="th">mName</th>
<th data-quarto-table-cell-role="th">mGenres</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td data-quarto-table-cell-role="th">1409</td>
<td>1433</td>
<td>Machine, The (1994)</td>
<td>Comedy|Horror</td>
</tr>
</tbody>
</table>

</div>
</div>
</div>
</section>
<section id="load-ratings" class="level4">
<h4 class="anchored" data-anchor-id="load-ratings">Load Ratings</h4>
<p>Using a similar routine as above, we load the ratings data which is in this format <code>UserID::MovieID::Rating::Timestamp</code>, and we will name the column UserID with <code>uid</code>, the column MovieID with <code>mid</code>, the rating with <code>rating</code>, and the time of the rating with <code>timestamp</code>.</p>
<div class="cell" data-outputid="47614b7e-ba1a-46ff-b4e6-f23ccf5086e2">
<div class="sourceCode cell-code" id="cb10"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb10-1"><a href="#cb10-1" aria-hidden="true" tabindex="-1"></a>ratings_pd <span class="op">=</span> pd.read_csv(os.path.join(DATA_DIR, <span class="st">'ratings.dat'</span>),</span>
<span id="cb10-2"><a href="#cb10-2" aria-hidden="true" tabindex="-1"></a>                         sep<span class="op">=</span><span class="st">'::'</span>,</span>
<span id="cb10-3"><a href="#cb10-3" aria-hidden="true" tabindex="-1"></a>                         names<span class="op">=</span>[<span class="st">'uid'</span>, <span class="st">'mid'</span>, <span class="st">'rating'</span>, <span class="st">'timestamp'</span>],</span>
<span id="cb10-4"><a href="#cb10-4" aria-hidden="true" tabindex="-1"></a>                         parse_dates<span class="op">=</span>[<span class="st">'timestamp'</span>],</span>
<span id="cb10-5"><a href="#cb10-5" aria-hidden="true" tabindex="-1"></a>                         infer_datetime_format<span class="op">=</span><span class="va">True</span>,</span>
<span id="cb10-6"><a href="#cb10-6" aria-hidden="true" tabindex="-1"></a>                         engine<span class="op">=</span><span class="st">'python'</span>)</span>
<span id="cb10-7"><a href="#cb10-7" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb10-8"><a href="#cb10-8" aria-hidden="true" tabindex="-1"></a>display(ratings_pd.head())</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-display">
<div>


<table class="dataframe table table-sm table-striped small" data-quarto-postprocess="true" data-border="1">
<thead>
<tr class="header">
<th data-quarto-table-cell-role="th"></th>
<th data-quarto-table-cell-role="th">uid</th>
<th data-quarto-table-cell-role="th">mid</th>
<th data-quarto-table-cell-role="th">rating</th>
<th data-quarto-table-cell-role="th">timestamp</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td data-quarto-table-cell-role="th">0</td>
<td>1</td>
<td>1193</td>
<td>5</td>
<td>978300760</td>
</tr>
<tr class="even">
<td data-quarto-table-cell-role="th">1</td>
<td>1</td>
<td>661</td>
<td>3</td>
<td>978302109</td>
</tr>
<tr class="odd">
<td data-quarto-table-cell-role="th">2</td>
<td>1</td>
<td>914</td>
<td>3</td>
<td>978301968</td>
</tr>
<tr class="even">
<td data-quarto-table-cell-role="th">3</td>
<td>1</td>
<td>3408</td>
<td>4</td>
<td>978300275</td>
</tr>
<tr class="odd">
<td data-quarto-table-cell-role="th">4</td>
<td>1</td>
<td>2355</td>
<td>5</td>
<td>978824291</td>
</tr>
</tbody>
</table>

</div>
</div>
</div>
<div class="cell" data-outputid="5c28c977-94f0-4595-b79b-0e23e78687eb">
<div class="sourceCode cell-code" id="cb11"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb11-1"><a href="#cb11-1" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="ss">f"""The dataset contains </span><span class="sc">{</span>ratings_pd<span class="sc">.</span>shape[<span class="dv">0</span>]<span class="sc">}</span><span class="ss"> ratings,</span></span>
<span id="cb11-2"><a href="#cb11-2" aria-hidden="true" tabindex="-1"></a><span class="ss">      from </span><span class="sc">{</span>ratings_pd<span class="sc">.</span>uid<span class="sc">.</span>nunique()<span class="sc">}</span><span class="ss"> users,</span></span>
<span id="cb11-3"><a href="#cb11-3" aria-hidden="true" tabindex="-1"></a><span class="ss">      and </span><span class="sc">{</span>ratings_pd<span class="sc">.</span>mid<span class="sc">.</span>nunique()<span class="sc">}</span><span class="ss"> items."""</span>)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>The dataset contains 1000209 ratings, 
      from 6040 users, 
      and 3706 items.</code></pre>
</div>
</div>
</section>
<section id="load-user-socio-demographics-information" class="level4">
<h4 class="anchored" data-anchor-id="load-user-socio-demographics-information">Load User Socio-Demographics Information</h4>
<p>The file is in this format <code>UserID::Gender::Age::Occupation::Zip-code</code>, which we will load in a <code>dataFrame</code> with the following column names <code>uid,gender,age,occupation,zip</code>.</p>
<div class="cell" data-outputid="db4a5db9-66c6-4e84-bf63-e950f4fe18c3">
<div class="sourceCode cell-code" id="cb13"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb13-1"><a href="#cb13-1" aria-hidden="true" tabindex="-1"></a>users_pd <span class="op">=</span> pd.read_csv(os.path.join(DATA_DIR, <span class="st">'users.dat'</span>),</span>
<span id="cb13-2"><a href="#cb13-2" aria-hidden="true" tabindex="-1"></a>                       sep<span class="op">=</span><span class="st">'::'</span>,</span>
<span id="cb13-3"><a href="#cb13-3" aria-hidden="true" tabindex="-1"></a>                       names<span class="op">=</span>[<span class="st">'uid'</span>, <span class="st">'gender'</span>, <span class="st">'age'</span>, <span class="st">'occupation'</span>, <span class="st">'zip'</span>],</span>
<span id="cb13-4"><a href="#cb13-4" aria-hidden="true" tabindex="-1"></a>                       engine<span class="op">=</span><span class="st">"python"</span>)</span>
<span id="cb13-5"><a href="#cb13-5" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb13-6"><a href="#cb13-6" aria-hidden="true" tabindex="-1"></a>display(users_pd.head())</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-display">
<div>


<table class="dataframe table table-sm table-striped small" data-quarto-postprocess="true" data-border="1">
<thead>
<tr class="header">
<th data-quarto-table-cell-role="th"></th>
<th data-quarto-table-cell-role="th">uid</th>
<th data-quarto-table-cell-role="th">gender</th>
<th data-quarto-table-cell-role="th">age</th>
<th data-quarto-table-cell-role="th">occupation</th>
<th data-quarto-table-cell-role="th">zip</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td data-quarto-table-cell-role="th">0</td>
<td>1</td>
<td>F</td>
<td>1</td>
<td>10</td>
<td>48067</td>
</tr>
<tr class="even">
<td data-quarto-table-cell-role="th">1</td>
<td>2</td>
<td>M</td>
<td>56</td>
<td>16</td>
<td>70072</td>
</tr>
<tr class="odd">
<td data-quarto-table-cell-role="th">2</td>
<td>3</td>
<td>M</td>
<td>25</td>
<td>15</td>
<td>55117</td>
</tr>
<tr class="even">
<td data-quarto-table-cell-role="th">3</td>
<td>4</td>
<td>M</td>
<td>45</td>
<td>7</td>
<td>02460</td>
</tr>
<tr class="odd">
<td data-quarto-table-cell-role="th">4</td>
<td>5</td>
<td>M</td>
<td>25</td>
<td>20</td>
<td>55455</td>
</tr>
</tbody>
</table>

</div>
</div>
</div>
<div class="cell" data-outputid="636320d4-ccb9-41d7-ecbc-a0968cc23fb4">
<div class="sourceCode cell-code" id="cb14"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb14-1"><a href="#cb14-1" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="ss">f'This table contains </span><span class="sc">{</span>users_pd<span class="sc">.</span>shape[<span class="dv">0</span>]<span class="sc">}</span><span class="ss"> users'</span>)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>This table contains 6040 users</code></pre>
</div>
</div>
<p>Further we will truncate the 5-digit zip codes and only keep the leading two digits. The reason is that we will treat this variable as a categorical one and with only ~6K users and &gt;3.4K unique zip codes, it is unlikely that we can learn precise enough coefficients for this feature.</p>
<div class="cell" data-scrolled="true" data-outputid="75d857ce-0269-42e2-d58b-ee016cf92ecc">
<div class="sourceCode cell-code" id="cb16"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb16-1"><a href="#cb16-1" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="ss">f'We originally have </span><span class="sc">{</span>users_pd<span class="sc">.</span><span class="bu">zip</span><span class="sc">.</span>nunique()<span class="sc">}</span><span class="ss"> different zip codes'</span>)</span>
<span id="cb16-2"><a href="#cb16-2" aria-hidden="true" tabindex="-1"></a>users_pd[<span class="st">'zip'</span>] <span class="op">=</span> users_pd[<span class="st">'zip'</span>].<span class="bu">apply</span>(<span class="kw">lambda</span> x: x[:<span class="dv">2</span>])</span>
<span id="cb16-3"><a href="#cb16-3" aria-hidden="true" tabindex="-1"></a>display(users_pd[<span class="st">'zip'</span>].head())</span>
<span id="cb16-4"><a href="#cb16-4" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="ss">f'By only keep the first two digits of each zip code, </span><span class="ch">\</span></span>
<span id="cb16-5"><a href="#cb16-5" aria-hidden="true" tabindex="-1"></a><span class="ss">we reduced the unique number of zip codes to </span><span class="sc">{</span>users_pd<span class="sc">.</span><span class="bu">zip</span><span class="sc">.</span>nunique()<span class="sc">}</span><span class="ss">.'</span>)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>We originally have 3439 different zip codes
By only keep the first two digits of each zip code, we reduced the unique number of zip codes to 100.</code></pre>
</div>
<div class="cell-output cell-output-display">
<pre><code>0    48
1    70
2    55
3    02
4    55
Name: zip, dtype: object</code></pre>
</div>
</div>
</section>
<section id="load-movie-tags" class="level4">
<h4 class="anchored" data-anchor-id="load-movie-tags">Load Movie Tags</h4>
<p>The remaining data to be loaded are the movie tags (we will actually use the tags from the ml-20M dataset). The tags are user generated. Further each movie-tag pair comes with an affinity score (intuitively, if numerous users have used a tag on a particular movie than the tag-movie pair will have a high affinity).</p>
<p>We will load the csv data <code>movieId,tagId,relevance</code> into a <code>dataFrame</code> with the columns <code>mid,tid,relevance</code>.</p>
<div class="cell" data-outputid="be4ddb51-86e3-47d1-c46e-2cf696908429">
<div class="sourceCode cell-code" id="cb19"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb19-1"><a href="#cb19-1" aria-hidden="true" tabindex="-1"></a><span class="co"># load ml-20m tags</span></span>
<span id="cb19-2"><a href="#cb19-2" aria-hidden="true" tabindex="-1"></a>tags_scores <span class="op">=</span> pd.read_csv(os.path.join(DATA_DIR_20ML, <span class="st">'genome-scores.csv.gz'</span>),</span>
<span id="cb19-3"><a href="#cb19-3" aria-hidden="true" tabindex="-1"></a>                          skiprows<span class="op">=</span><span class="dv">1</span>,</span>
<span id="cb19-4"><a href="#cb19-4" aria-hidden="true" tabindex="-1"></a>                          names<span class="op">=</span>[<span class="st">'mid'</span>, <span class="st">'tid'</span>, <span class="st">'relevance'</span>])</span>
<span id="cb19-5"><a href="#cb19-5" aria-hidden="true" tabindex="-1"></a>display(tags_scores.head(<span class="dv">10</span>))</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-display">
<div>


<table class="dataframe table table-sm table-striped small" data-quarto-postprocess="true" data-border="1">
<thead>
<tr class="header">
<th data-quarto-table-cell-role="th"></th>
<th data-quarto-table-cell-role="th">mid</th>
<th data-quarto-table-cell-role="th">tid</th>
<th data-quarto-table-cell-role="th">relevance</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td data-quarto-table-cell-role="th">0</td>
<td>1</td>
<td>1</td>
<td>0.02500</td>
</tr>
<tr class="even">
<td data-quarto-table-cell-role="th">1</td>
<td>1</td>
<td>2</td>
<td>0.02500</td>
</tr>
<tr class="odd">
<td data-quarto-table-cell-role="th">2</td>
<td>1</td>
<td>3</td>
<td>0.05775</td>
</tr>
<tr class="even">
<td data-quarto-table-cell-role="th">3</td>
<td>1</td>
<td>4</td>
<td>0.09675</td>
</tr>
<tr class="odd">
<td data-quarto-table-cell-role="th">4</td>
<td>1</td>
<td>5</td>
<td>0.14675</td>
</tr>
<tr class="even">
<td data-quarto-table-cell-role="th">5</td>
<td>1</td>
<td>6</td>
<td>0.21700</td>
</tr>
<tr class="odd">
<td data-quarto-table-cell-role="th">6</td>
<td>1</td>
<td>7</td>
<td>0.06700</td>
</tr>
<tr class="even">
<td data-quarto-table-cell-role="th">7</td>
<td>1</td>
<td>8</td>
<td>0.26275</td>
</tr>
<tr class="odd">
<td data-quarto-table-cell-role="th">8</td>
<td>1</td>
<td>9</td>
<td>0.26200</td>
</tr>
<tr class="even">
<td data-quarto-table-cell-role="th">9</td>
<td>1</td>
<td>10</td>
<td>0.03200</td>
</tr>
</tbody>
</table>

</div>
</div>
</div>
<div class="cell" data-scrolled="true" data-outputid="7b3d3ed1-cb23-409d-fbd6-b6d00161e80c">
<div class="sourceCode cell-code" id="cb20"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb20-1"><a href="#cb20-1" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="ss">f'The data contains </span><span class="sc">{</span>tags_scores<span class="sc">.</span>tid<span class="sc">.</span>nunique()<span class="sc">}</span><span class="ss"> unique tags.'</span>)</span>
<span id="cb20-2"><a href="#cb20-2" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="ss">f'Affinities (relevances) are contained in the </span><span class="sc">{</span>tags_scores<span class="sc">.</span>relevance<span class="sc">.</span><span class="bu">min</span>()<span class="sc">}</span><span class="ss">--</span><span class="sc">{</span>tags_scores<span class="sc">.</span>relevance<span class="sc">.</span><span class="bu">max</span>()<span class="sc">}</span><span class="ss"> range.'</span>)</span>
<span id="cb20-3"><a href="#cb20-3" aria-hidden="true" tabindex="-1"></a>display(tags_scores.relevance.describe())</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>The data contains 1128 unique tags.
Affinities (relevances) are contained in the 0.00024999999999997247--1.0 range.</code></pre>
</div>
<div class="cell-output cell-output-display">
<pre><code>count    1.170977e+07
mean     1.164833e-01
std      1.542463e-01
min      2.500000e-04
25%      2.425000e-02
50%      5.650000e-02
75%      1.415000e-01
max      1.000000e+00
Name: relevance, dtype: float64</code></pre>
</div>
</div>
<p>From above we see that affinities (relevance) basically span the 0 to 1 range, and have an average of 0.12.</p>
<p>We also load the tag names. This will be useful for exploration purposes.</p>
<div class="cell" data-outputid="da17bc40-8539-48a1-d135-20f4d440fb2e">
<div class="sourceCode cell-code" id="cb23"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb23-1"><a href="#cb23-1" aria-hidden="true" tabindex="-1"></a>tags_names <span class="op">=</span> pd.read_csv(os.path.join(DATA_DIR_20ML, <span class="st">'genome-tags.csv'</span>), skiprows<span class="op">=</span><span class="dv">1</span>, names<span class="op">=</span>[<span class="st">'tid'</span>, <span class="st">'tName'</span>])</span>
<span id="cb23-2"><a href="#cb23-2" aria-hidden="true" tabindex="-1"></a>display(tags_names.head(<span class="dv">10</span>))</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-display">
<div>


<table class="dataframe table table-sm table-striped small" data-quarto-postprocess="true" data-border="1">
<thead>
<tr class="header">
<th data-quarto-table-cell-role="th"></th>
<th data-quarto-table-cell-role="th">tid</th>
<th data-quarto-table-cell-role="th">tName</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td data-quarto-table-cell-role="th">0</td>
<td>1</td>
<td>007</td>
</tr>
<tr class="even">
<td data-quarto-table-cell-role="th">1</td>
<td>2</td>
<td>007 (series)</td>
</tr>
<tr class="odd">
<td data-quarto-table-cell-role="th">2</td>
<td>3</td>
<td>18th century</td>
</tr>
<tr class="even">
<td data-quarto-table-cell-role="th">3</td>
<td>4</td>
<td>1920s</td>
</tr>
<tr class="odd">
<td data-quarto-table-cell-role="th">4</td>
<td>5</td>
<td>1930s</td>
</tr>
<tr class="even">
<td data-quarto-table-cell-role="th">5</td>
<td>6</td>
<td>1950s</td>
</tr>
<tr class="odd">
<td data-quarto-table-cell-role="th">6</td>
<td>7</td>
<td>1960s</td>
</tr>
<tr class="even">
<td data-quarto-table-cell-role="th">7</td>
<td>8</td>
<td>1970s</td>
</tr>
<tr class="odd">
<td data-quarto-table-cell-role="th">8</td>
<td>9</td>
<td>1980s</td>
</tr>
<tr class="even">
<td data-quarto-table-cell-role="th">9</td>
<td>10</td>
<td>19th century</td>
</tr>
</tbody>
</table>

</div>
</div>
</div>
<p>Since we loaded tag scores from a different dataset (ml-20M), we only need the tags that correspond to movies in the original data (ml-1M). Luckily, since both datasets are from movielens, the movie ids (<code>mid</code>) are the same across these two datasets (i.e., not need for messy string match).</p>
<p>(Note: Pandas’ functionalities allow you to do operations similar to what you would do in SQL for relational databases.)</p>
<div class="cell" data-outputid="974645ec-a3eb-4d2c-d217-87f0d0ef456e">
<div class="sourceCode cell-code" id="cb24"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb24-1"><a href="#cb24-1" aria-hidden="true" tabindex="-1"></a>tags_scores <span class="op">=</span> tags_scores.loc[tags_scores[<span class="st">'mid'</span>].isin(ratings_pd[<span class="st">'mid'</span>].unique())]</span>
<span id="cb24-2"><a href="#cb24-2" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(tags_scores.mid.nunique())</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>3470</code></pre>
</div>
</div>
<p>We lost a few movies compared to the original count of 3706 but we can live with that.</p>
<p>Next, instead of using the tag scores, we only keep the highly relevant tags for each movie. In other words, we assume that the presence of a tag is more meaningful than its absence. This also has the side benefit of reducing the number of available tags per movie.</p>
<div class="cell" data-scrolled="true" data-outputid="31932a8f-f7ce-4426-a9fa-1cd07724a56b">
<div class="sourceCode cell-code" id="cb26"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb26-1"><a href="#cb26-1" aria-hidden="true" tabindex="-1"></a><span class="co"># Keep only high-relevance tags (here this is defined as having a relevance above 0.9)</span></span>
<span id="cb26-2"><a href="#cb26-2" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="st">'unique tags:'</span>, tags_scores[<span class="st">'tid'</span>].nunique())</span>
<span id="cb26-3"><a href="#cb26-3" aria-hidden="true" tabindex="-1"></a>tags_scores_high <span class="op">=</span> tags_scores.loc[tags_scores[<span class="st">'relevance'</span>] <span class="op">&gt;</span> <span class="fl">0.9</span>]</span>
<span id="cb26-4"><a href="#cb26-4" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="st">'unique tags w. high relevance:'</span>, tags_scores_high[<span class="st">'tid'</span>].nunique())</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>unique tags: 1128
unique tags w. high relevance: 968</code></pre>
</div>
</div>
</section>
<section id="explore-tags" class="level4">
<h4 class="anchored" data-anchor-id="explore-tags">Explore tags</h4>
<p>Let’s get some understanding of how these tags are used. To help, we first build a <code>dataFrame</code> that contains, the tag names, the movie name, and its relevance (recall that currently these are in three different tables, as the tag relevance contains tag and movie IDs but not their names).</p>
<p>Pandas’ <code>merge</code> function can be used to join two dataFrames that share a common key. (This is an operation inspired by inner joins in SQL.)</p>
<div class="cell" data-scrolled="true" data-outputid="de4e685c-79ce-47c5-b35a-fece1dcbbe17">
<div class="sourceCode cell-code" id="cb28"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb28-1"><a href="#cb28-1" aria-hidden="true" tabindex="-1"></a>tags_high_names_movies <span class="op">=</span> pd.merge(tags_scores_high, tags_names, how<span class="op">=</span><span class="st">'inner'</span>, on<span class="op">=</span><span class="st">'tid'</span>)</span>
<span id="cb28-2"><a href="#cb28-2" aria-hidden="true" tabindex="-1"></a>tags_high_names_movies <span class="op">=</span> pd.merge(tags_high_names_movies, movies_pd, how<span class="op">=</span><span class="st">'inner'</span>, on<span class="op">=</span><span class="st">'mid'</span>)</span>
<span id="cb28-3"><a href="#cb28-3" aria-hidden="true" tabindex="-1"></a>display(tags_high_names_movies.head())</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-display">
<div>


<table class="dataframe table table-sm table-striped small" data-quarto-postprocess="true" data-border="1">
<thead>
<tr class="header">
<th data-quarto-table-cell-role="th"></th>
<th data-quarto-table-cell-role="th">mid</th>
<th data-quarto-table-cell-role="th">tid</th>
<th data-quarto-table-cell-role="th">relevance</th>
<th data-quarto-table-cell-role="th">tName</th>
<th data-quarto-table-cell-role="th">mName</th>
<th data-quarto-table-cell-role="th">mGenres</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td data-quarto-table-cell-role="th">0</td>
<td>1</td>
<td>63</td>
<td>0.93325</td>
<td>animated</td>
<td>Toy Story (1995)</td>
<td>Animation|Children's|Comedy</td>
</tr>
<tr class="even">
<td data-quarto-table-cell-role="th">1</td>
<td>1</td>
<td>64</td>
<td>0.98575</td>
<td>animation</td>
<td>Toy Story (1995)</td>
<td>Animation|Children's|Comedy</td>
</tr>
<tr class="odd">
<td data-quarto-table-cell-role="th">2</td>
<td>1</td>
<td>186</td>
<td>0.95650</td>
<td>cartoon</td>
<td>Toy Story (1995)</td>
<td>Animation|Children's|Comedy</td>
</tr>
<tr class="even">
<td data-quarto-table-cell-role="th">3</td>
<td>1</td>
<td>203</td>
<td>0.92625</td>
<td>childhood</td>
<td>Toy Story (1995)</td>
<td>Animation|Children's|Comedy</td>
</tr>
<tr class="odd">
<td data-quarto-table-cell-role="th">4</td>
<td>1</td>
<td>204</td>
<td>0.96425</td>
<td>children</td>
<td>Toy Story (1995)</td>
<td>Animation|Children's|Comedy</td>
</tr>
</tbody>
</table>

</div>
</div>
</div>
<p>Similarly as above we can search for top movies according to a particular tag:</p>
<div class="cell" data-outputid="bd7df760-4a87-40a1-be96-52c912e50019">
<div class="sourceCode cell-code" id="cb29"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb29-1"><a href="#cb29-1" aria-hidden="true" tabindex="-1"></a>tag <span class="op">=</span> <span class="st">'scary'</span> <span class="co"># This is the (sub) tag we search for</span></span>
<span id="cb29-2"><a href="#cb29-2" aria-hidden="true" tabindex="-1"></a>display(tags_high_names_movies[</span>
<span id="cb29-3"><a href="#cb29-3" aria-hidden="true" tabindex="-1"></a>    tags_high_names_movies.tName.<span class="bu">str</span>.contains(tag,</span>
<span id="cb29-4"><a href="#cb29-4" aria-hidden="true" tabindex="-1"></a>                                               regex<span class="op">=</span><span class="va">False</span>, case<span class="op">=</span><span class="va">False</span>)].sort_values(by<span class="op">=</span>[<span class="st">'relevance'</span>],</span>
<span id="cb29-5"><a href="#cb29-5" aria-hidden="true" tabindex="-1"></a>                                                                                    ascending<span class="op">=</span><span class="va">False</span>))</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-display">
<div>


<table class="dataframe table table-sm table-striped small" data-quarto-postprocess="true" data-border="1">
<thead>
<tr class="header">
<th data-quarto-table-cell-role="th"></th>
<th data-quarto-table-cell-role="th">mid</th>
<th data-quarto-table-cell-role="th">tid</th>
<th data-quarto-table-cell-role="th">relevance</th>
<th data-quarto-table-cell-role="th">tName</th>
<th data-quarto-table-cell-role="th">mName</th>
<th data-quarto-table-cell-role="th">mGenres</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td data-quarto-table-cell-role="th">13151</td>
<td>2710</td>
<td>882</td>
<td>0.96700</td>
<td>scary</td>
<td>Blair Witch Project, The (1999)</td>
<td>Horror</td>
</tr>
<tr class="even">
<td data-quarto-table-cell-role="th">14005</td>
<td>1342</td>
<td>882</td>
<td>0.96625</td>
<td>scary</td>
<td>Candyman (1992)</td>
<td>Horror</td>
</tr>
<tr class="odd">
<td data-quarto-table-cell-role="th">9205</td>
<td>1347</td>
<td>882</td>
<td>0.96550</td>
<td>scary</td>
<td>Nightmare on Elm Street, A (1984)</td>
<td>Horror</td>
</tr>
<tr class="even">
<td data-quarto-table-cell-role="th">14658</td>
<td>3892</td>
<td>882</td>
<td>0.96475</td>
<td>scary</td>
<td>Anatomy (Anatomie) (2000)</td>
<td>Horror</td>
</tr>
<tr class="odd">
<td data-quarto-table-cell-role="th">3187</td>
<td>1997</td>
<td>882</td>
<td>0.96200</td>
<td>scary</td>
<td>Exorcist, The (1973)</td>
<td>Horror</td>
</tr>
<tr class="even">
<td data-quarto-table-cell-role="th">14021</td>
<td>2550</td>
<td>882</td>
<td>0.95625</td>
<td>scary</td>
<td>Haunting, The (1963)</td>
<td>Horror|Thriller</td>
</tr>
<tr class="odd">
<td data-quarto-table-cell-role="th">11492</td>
<td>1350</td>
<td>882</td>
<td>0.94675</td>
<td>scary</td>
<td>Omen, The (1976)</td>
<td>Horror</td>
</tr>
<tr class="even">
<td data-quarto-table-cell-role="th">11546</td>
<td>2841</td>
<td>882</td>
<td>0.94650</td>
<td>scary</td>
<td>Stir of Echoes (1999)</td>
<td>Thriller</td>
</tr>
<tr class="odd">
<td data-quarto-table-cell-role="th">9340</td>
<td>1974</td>
<td>882</td>
<td>0.94625</td>
<td>scary</td>
<td>Friday the 13th (1980)</td>
<td>Horror</td>
</tr>
<tr class="even">
<td data-quarto-table-cell-role="th">2976</td>
<td>1387</td>
<td>882</td>
<td>0.94250</td>
<td>scary</td>
<td>Jaws (1975)</td>
<td>Action|Horror</td>
</tr>
<tr class="odd">
<td data-quarto-table-cell-role="th">5121</td>
<td>2460</td>
<td>882</td>
<td>0.93925</td>
<td>scary</td>
<td>Texas Chainsaw Massacre 2, The (1986)</td>
<td>Horror</td>
</tr>
<tr class="even">
<td data-quarto-table-cell-role="th">2488</td>
<td>1214</td>
<td>882</td>
<td>0.93875</td>
<td>scary</td>
<td>Alien (1979)</td>
<td>Action|Horror|Sci-Fi|Thriller</td>
</tr>
<tr class="odd">
<td data-quarto-table-cell-role="th">9478</td>
<td>3273</td>
<td>882</td>
<td>0.93825</td>
<td>scary</td>
<td>Scream 3 (2000)</td>
<td>Horror|Mystery|Thriller</td>
</tr>
<tr class="even">
<td data-quarto-table-cell-role="th">13208</td>
<td>1590</td>
<td>882</td>
<td>0.93525</td>
<td>scary</td>
<td>Event Horizon (1997)</td>
<td>Action|Mystery|Sci-Fi|Thriller</td>
</tr>
<tr class="odd">
<td data-quarto-table-cell-role="th">13916</td>
<td>1321</td>
<td>882</td>
<td>0.93475</td>
<td>scary</td>
<td>American Werewolf in London, An (1981)</td>
<td>Horror</td>
</tr>
<tr class="even">
<td data-quarto-table-cell-role="th">11518</td>
<td>2160</td>
<td>882</td>
<td>0.93325</td>
<td>scary</td>
<td>Rosemary's Baby (1968)</td>
<td>Horror|Thriller</td>
</tr>
<tr class="odd">
<td data-quarto-table-cell-role="th">4825</td>
<td>2719</td>
<td>882</td>
<td>0.92450</td>
<td>scary</td>
<td>Haunting, The (1999)</td>
<td>Horror|Thriller</td>
</tr>
<tr class="even">
<td data-quarto-table-cell-role="th">7636</td>
<td>3499</td>
<td>882</td>
<td>0.92350</td>
<td>scary</td>
<td>Misery (1990)</td>
<td>Horror</td>
</tr>
<tr class="odd">
<td data-quarto-table-cell-role="th">3452</td>
<td>2762</td>
<td>882</td>
<td>0.92075</td>
<td>scary</td>
<td>Sixth Sense, The (1999)</td>
<td>Thriller</td>
</tr>
<tr class="even">
<td data-quarto-table-cell-role="th">2781</td>
<td>1258</td>
<td>882</td>
<td>0.91675</td>
<td>scary</td>
<td>Shining, The (1980)</td>
<td>Horror</td>
</tr>
<tr class="odd">
<td data-quarto-table-cell-role="th">12355</td>
<td>3081</td>
<td>882</td>
<td>0.91425</td>
<td>scary</td>
<td>Sleepy Hollow (1999)</td>
<td>Horror|Romance</td>
</tr>
<tr class="even">
<td data-quarto-table-cell-role="th">2343</td>
<td>1200</td>
<td>882</td>
<td>0.90475</td>
<td>scary</td>
<td>Aliens (1986)</td>
<td>Action|Sci-Fi|Thriller|War</td>
</tr>
</tbody>
</table>

</div>
</div>
</div>
<p>This next step will allow us to further explore the tags data while providing an additional step of pre-processing that will be helpful for fitting this data.</p>
<p>In the current dataset, every movie-tag id pair is a separate entry (row of the <code>dataFrame</code>). Thinking ahead, we will want to use all tags as covariates to predict a single rating. As such, we want to construct a data matrix where each line corresponds to a single example.</p>
<p>To do so, we re-encode <code>tid</code>s using a 1-of-K encoding (also known as using dummy variables). This is important to encode categorial variables (e.g., “cats” and “dogs”) which may be represented numerically but but which cannit be ordered. For example, here each tag has a numerical index (e.g., tag <code>scary</code> is id <code>882</code>) but tags cannot be compared using their numbers (e.g., tag <code>882</code> is not “bigger” than tag <code>880</code> or smaller than tag <code>900</code>). 1-of-K encoding deals with this by encoding each tag as a binary vector of length <span class="math inline">\(K\)</span> with a single non-zero value which corresponds to the tag. In the present case, <span class="math inline">\(K=968\)</span> tags, and tag <code>scary</code> would have a <code>1</code> at position <code>882</code>.</p>
<p>Below we see that our data now has 971 columns: 968 for tag ids, 1 for <code>mid</code>, and 1 for <code>relevance</code>, and 1 for the pandas index.</p>
<div class="cell" data-outputid="40201045-20e8-4088-acbb-346e372ad68b">
<div class="sourceCode cell-code" id="cb30"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb30-1"><a href="#cb30-1" aria-hidden="true" tabindex="-1"></a><span class="co">#print(tags_scores_high.shape)</span></span>
<span id="cb30-2"><a href="#cb30-2" aria-hidden="true" tabindex="-1"></a>tags_scores_high_dum <span class="op">=</span> pd.get_dummies(tags_scores_high, columns<span class="op">=</span>[<span class="st">'tid'</span>])</span>
<span id="cb30-3"><a href="#cb30-3" aria-hidden="true" tabindex="-1"></a>tags_scores_high_dum <span class="op">=</span> tags_scores_high_dum.reset_index()</span>
<span id="cb30-4"><a href="#cb30-4" aria-hidden="true" tabindex="-1"></a><span class="co">#print(tags_scores_high_dum.shape)</span></span>
<span id="cb30-5"><a href="#cb30-5" aria-hidden="true" tabindex="-1"></a>display(tags_scores_high_dum.head())</span>
<span id="cb30-6"><a href="#cb30-6" aria-hidden="true" tabindex="-1"></a>tags_per_movie <span class="op">=</span> tags_scores_high_dum.groupby(<span class="st">"mid"</span>).<span class="bu">sum</span>()</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-display">
<div>


<table class="dataframe table table-sm table-striped small" data-quarto-postprocess="true" data-border="1">
<thead>
<tr class="header">
<th data-quarto-table-cell-role="th"></th>
<th data-quarto-table-cell-role="th">index</th>
<th data-quarto-table-cell-role="th">mid</th>
<th data-quarto-table-cell-role="th">relevance</th>
<th data-quarto-table-cell-role="th">tid_1</th>
<th data-quarto-table-cell-role="th">tid_2</th>
<th data-quarto-table-cell-role="th">tid_3</th>
<th data-quarto-table-cell-role="th">tid_5</th>
<th data-quarto-table-cell-role="th">tid_6</th>
<th data-quarto-table-cell-role="th">tid_7</th>
<th data-quarto-table-cell-role="th">tid_9</th>
<th data-quarto-table-cell-role="th">...</th>
<th data-quarto-table-cell-role="th">tid_1119</th>
<th data-quarto-table-cell-role="th">tid_1120</th>
<th data-quarto-table-cell-role="th">tid_1121</th>
<th data-quarto-table-cell-role="th">tid_1122</th>
<th data-quarto-table-cell-role="th">tid_1123</th>
<th data-quarto-table-cell-role="th">tid_1124</th>
<th data-quarto-table-cell-role="th">tid_1125</th>
<th data-quarto-table-cell-role="th">tid_1126</th>
<th data-quarto-table-cell-role="th">tid_1127</th>
<th data-quarto-table-cell-role="th">tid_1128</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td data-quarto-table-cell-role="th">0</td>
<td>62</td>
<td>1</td>
<td>0.93325</td>
<td>0</td>
<td>0</td>
<td>0</td>
<td>0</td>
<td>0</td>
<td>0</td>
<td>0</td>
<td>...</td>
<td>0</td>
<td>0</td>
<td>0</td>
<td>0</td>
<td>0</td>
<td>0</td>
<td>0</td>
<td>0</td>
<td>0</td>
<td>0</td>
</tr>
<tr class="even">
<td data-quarto-table-cell-role="th">1</td>
<td>63</td>
<td>1</td>
<td>0.98575</td>
<td>0</td>
<td>0</td>
<td>0</td>
<td>0</td>
<td>0</td>
<td>0</td>
<td>0</td>
<td>...</td>
<td>0</td>
<td>0</td>
<td>0</td>
<td>0</td>
<td>0</td>
<td>0</td>
<td>0</td>
<td>0</td>
<td>0</td>
<td>0</td>
</tr>
<tr class="odd">
<td data-quarto-table-cell-role="th">2</td>
<td>185</td>
<td>1</td>
<td>0.95650</td>
<td>0</td>
<td>0</td>
<td>0</td>
<td>0</td>
<td>0</td>
<td>0</td>
<td>0</td>
<td>...</td>
<td>0</td>
<td>0</td>
<td>0</td>
<td>0</td>
<td>0</td>
<td>0</td>
<td>0</td>
<td>0</td>
<td>0</td>
<td>0</td>
</tr>
<tr class="even">
<td data-quarto-table-cell-role="th">3</td>
<td>202</td>
<td>1</td>
<td>0.92625</td>
<td>0</td>
<td>0</td>
<td>0</td>
<td>0</td>
<td>0</td>
<td>0</td>
<td>0</td>
<td>...</td>
<td>0</td>
<td>0</td>
<td>0</td>
<td>0</td>
<td>0</td>
<td>0</td>
<td>0</td>
<td>0</td>
<td>0</td>
<td>0</td>
</tr>
<tr class="odd">
<td data-quarto-table-cell-role="th">4</td>
<td>203</td>
<td>1</td>
<td>0.96425</td>
<td>0</td>
<td>0</td>
<td>0</td>
<td>0</td>
<td>0</td>
<td>0</td>
<td>0</td>
<td>...</td>
<td>0</td>
<td>0</td>
<td>0</td>
<td>0</td>
<td>0</td>
<td>0</td>
<td>0</td>
<td>0</td>
<td>0</td>
<td>0</td>
</tr>
</tbody>
</table>

<p>5 rows × 971 columns</p>
</div>
</div>
</div>
<p>With this data we can then explore the distribution of movies per tag (and tags per movie below).</p>
<div class="cell" data-outputid="1192289e-fb28-4b80-b95b-daad27fce585">
<div class="sourceCode cell-code" id="cb31"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb31-1"><a href="#cb31-1" aria-hidden="true" tabindex="-1"></a>th <span class="op">=</span> tags_scores_high.groupby(<span class="st">"tid"</span>).count()</span>
<span id="cb31-2"><a href="#cb31-2" aria-hidden="true" tabindex="-1"></a>hists <span class="op">=</span> th.hist(bins<span class="op">=</span><span class="dv">50</span>, column<span class="op">=</span><span class="st">"mid"</span>, xlabelsize<span class="op">=</span><span class="dv">15</span>, ylabelsize<span class="op">=</span><span class="dv">15</span>)[<span class="dv">0</span>][<span class="dv">0</span>]</span>
<span id="cb31-3"><a href="#cb31-3" aria-hidden="true" tabindex="-1"></a>hists.set_ylabel(<span class="st">"Tags"</span>, size<span class="op">=</span><span class="dv">15</span>)</span>
<span id="cb31-4"><a href="#cb31-4" aria-hidden="true" tabindex="-1"></a>hists.set_xlabel(<span class="st">"Movies per tag"</span>, size<span class="op">=</span><span class="dv">15</span>)</span>
<span id="cb31-5"><a href="#cb31-5" aria-hidden="true" tabindex="-1"></a>hists.set_title(<span class="st">"Histogram of Movies per tag"</span>, size<span class="op">=</span><span class="dv">15</span>)<span class="op">;</span></span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-display">
<p><img src="Introduction_to_ML_files/figure-html/cell-22-output-1.png" class="img-fluid"></p>
</div>
</div>
<p>In this histogram each bar corresponds to the number of tags (y-axis) associated with a particular number of movies. For example, there are 350 tags that were used to tag a small number of movies (&lt;5). On the other hand, the most popular tag was used to tag 210 movies.</p>
<p>We note that the distribution is heavily skewed to the left which indicates that most tags are only used on a small number of movies.</p>
<div class="cell" data-outputid="70059bd3-e34c-4122-c619-d8ebc4f58c2a">
<div class="sourceCode cell-code" id="cb32"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb32-1"><a href="#cb32-1" aria-hidden="true" tabindex="-1"></a>tname <span class="op">=</span> tags_names.at[tags_names.tid.eq(th.mid.idxmax()).idxmax(), <span class="st">'tName'</span>]</span>
<span id="cb32-2"><a href="#cb32-2" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="ss">f'The most popular tag "</span><span class="sc">{</span>tname<span class="sc">}</span><span class="ss">" has been used for </span><span class="sc">{</span>th<span class="sc">.</span>mid<span class="sc">.</span><span class="bu">max</span>()<span class="sc">}</span><span class="ss"> movies'</span>)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>The most popular tag "comedy" has been used for 210 movies</code></pre>
</div>
</div>
<p>Using the same recipe, we can do something similar for movies instead of tags</p>
<div class="cell" data-outputid="ce3649a0-d1ab-4321-bc38-89e99ff0be95">
<div class="sourceCode cell-code" id="cb34"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb34-1"><a href="#cb34-1" aria-hidden="true" tabindex="-1"></a>hists <span class="op">=</span> tags_scores_high.groupby(<span class="st">"mid"</span>).count().hist(bins<span class="op">=</span><span class="dv">40</span>, column<span class="op">=</span><span class="st">"tid"</span>, xlabelsize<span class="op">=</span><span class="dv">15</span>, ylabelsize<span class="op">=</span><span class="dv">15</span>)</span>
<span id="cb34-2"><a href="#cb34-2" aria-hidden="true" tabindex="-1"></a>hists[<span class="dv">0</span>][<span class="dv">0</span>].set_ylabel(<span class="st">"Movies"</span>, size<span class="op">=</span><span class="dv">15</span>)</span>
<span id="cb34-3"><a href="#cb34-3" aria-hidden="true" tabindex="-1"></a>hists[<span class="dv">0</span>][<span class="dv">0</span>].set_xlabel(<span class="st">"Tags per movie"</span>, size<span class="op">=</span><span class="dv">15</span>)</span>
<span id="cb34-4"><a href="#cb34-4" aria-hidden="true" tabindex="-1"></a>hists[<span class="dv">0</span>][<span class="dv">0</span>].set_title(<span class="st">"Histogram of Tags per movie"</span>, size<span class="op">=</span><span class="dv">15</span>)<span class="op">;</span></span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-display">
<p><img src="Introduction_to_ML_files/figure-html/cell-24-output-1.png" class="img-fluid"></p>
</div>
</div>
<p>In this histogram each bar corresponds to the number of movies (y-axis) associated with a particular number of tags. For example, there are a bit less than 500 movies that received exactly 1 tags. On the other hand, the most popular movie received almost 40 tags.</p>
</section>
<section id="question-1" class="level4">
<h4 class="anchored" data-anchor-id="question-1">Question 1</h4>
<p>What is the most popular movie in terms of tag (the one with almost 40 tags)? Bonus: Can you list the top 5 movies in terms of number of tags?</p>
<div class="cell" data-outputid="138bb07f-d9ea-4e84-845a-daeb0132a0c8">
<div class="sourceCode cell-code" id="cb35"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb35-1"><a href="#cb35-1" aria-hidden="true" tabindex="-1"></a>mh <span class="op">=</span> ...</span>
<span id="cb35-2"><a href="#cb35-2" aria-hidden="true" tabindex="-1"></a>mname <span class="op">=</span> ...</span>
<span id="cb35-3"><a href="#cb35-3" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="ss">f'The most popular movie "</span><span class="sc">{</span>mname<span class="sc">}</span><span class="ss">" has </span><span class="sc">{</span>mh<span class="sc">.</span>tid<span class="sc">.</span><span class="bu">max</span>()<span class="sc">}</span><span class="ss"> tags'</span>)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-error">
<pre><code>AttributeError: 'ellipsis' object has no attribute 'tid'</code></pre>
</div>
</div>
<p>In the next few steps we further pre-process our data in order to create a dataset for supervised learning. Recall, that we wish to predict user-movie preferences from user and movie features.</p>
<div class="cell">
<div class="sourceCode cell-code" id="cb37"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb37-1"><a href="#cb37-1" aria-hidden="true" tabindex="-1"></a><span class="co"># Join users, ratings, and tags</span></span>
<span id="cb37-2"><a href="#cb37-2" aria-hidden="true" tabindex="-1"></a>data_pd <span class="op">=</span> pd.merge(users_pd, ratings_pd, how<span class="op">=</span><span class="st">'inner'</span>, on<span class="op">=</span><span class="st">'uid'</span>)</span>
<span id="cb37-3"><a href="#cb37-3" aria-hidden="true" tabindex="-1"></a>data_pd <span class="op">=</span> pd.merge(data_pd, tags_per_movie, how<span class="op">=</span><span class="st">'inner'</span>, on<span class="op">=</span><span class="st">'mid'</span>)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<p>For the purpose of this tutorial, we will only use a small fraction of our dataset to ensure that all operations (and especially model fitting) can be done in a matter of minutes.</p>
<div class="cell">
<div class="sourceCode cell-code" id="cb38"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb38-1"><a href="#cb38-1" aria-hidden="true" tabindex="-1"></a><span class="co"># shuffle data and keep 2% of the ratings.</span></span>
<span id="cb38-2"><a href="#cb38-2" aria-hidden="true" tabindex="-1"></a><span class="co"># (this small percentage ensures that all computations in this tutorial are fast)</span></span>
<span id="cb38-3"><a href="#cb38-3" aria-hidden="true" tabindex="-1"></a>data_pd <span class="op">=</span> data_pd.sample(frac<span class="op">=</span><span class="fl">0.02</span>, random_state<span class="op">=</span><span class="dv">1234</span>)</span>
<span id="cb38-4"><a href="#cb38-4" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(data_pd.shape)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<p>We can have a look at our current dataset.</p>
<div class="cell">
<div class="sourceCode cell-code" id="cb39"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb39-1"><a href="#cb39-1" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="st">'Final descriptive stats of our dataset.'</span>)</span>
<span id="cb39-2"><a href="#cb39-2" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="st">'</span><span class="ch">\t</span><span class="st">- </span><span class="sc">%d</span><span class="st"> items'</span>   <span class="op">%</span> data_pd[<span class="st">'mid'</span>].nunique())</span>
<span id="cb39-3"><a href="#cb39-3" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="st">'</span><span class="ch">\t</span><span class="st">- </span><span class="sc">%d</span><span class="st"> users'</span>   <span class="op">%</span> data_pd[<span class="st">'uid'</span>].nunique())</span>
<span id="cb39-4"><a href="#cb39-4" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="st">'</span><span class="ch">\t</span><span class="st">- </span><span class="sc">%d</span><span class="st"> ratings'</span> <span class="op">%</span> data_pd.shape[<span class="dv">0</span>])</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<p>Notice that we have several categorical variables (e.g., gender, occupation, zip, mid). Below, we transform these using dummy variables (just like we did above for tags).</p>
<div class="cell">
<div class="sourceCode cell-code" id="cb40"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb40-1"><a href="#cb40-1" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(data_pd.shape)</span>
<span id="cb40-2"><a href="#cb40-2" aria-hidden="true" tabindex="-1"></a>display(data_pd[:<span class="dv">10</span>])</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<div class="cell">
<div class="sourceCode cell-code" id="cb41"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb41-1"><a href="#cb41-1" aria-hidden="true" tabindex="-1"></a>cols <span class="op">=</span> [<span class="st">'gender'</span>,<span class="st">'occupation'</span>,<span class="st">'zip'</span>,<span class="st">'mid'</span>,<span class="st">'uid'</span>]</span>
<span id="cb41-2"><a href="#cb41-2" aria-hidden="true" tabindex="-1"></a>data_pd_dum <span class="op">=</span> pd.get_dummies(data_pd, columns<span class="op">=</span>cols)</span>
<span id="cb41-3"><a href="#cb41-3" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(data_pd_dum.shape)</span>
<span id="cb41-4"><a href="#cb41-4" aria-hidden="true" tabindex="-1"></a>display(data_pd_dum.head(<span class="dv">10</span>))</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<p>While we used pandas to create dummies, <code>scikit-learn</code> has similar capacities. The <code>preprocessing</code> module is detailed <a href="https://scikit-learn.org/stable/modules/preprocessing.html">here</a>. You can also checkout the section on <a href="https://scikit-learn.org/stable/modules/preprocessing.html#preprocessing-categorical-features">Categorical features</a>.</p>
<p>We are ready to construct our first dataset. We will first use a subset of the columns (not including tags).</p>
<p>Below you will also note that we split our data into train and test using <code>train_test_split</code> from scikit-learn.</p>
<div class="cell">
<div class="sourceCode cell-code" id="cb42"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb42-1"><a href="#cb42-1" aria-hidden="true" tabindex="-1"></a>attributes <span class="op">=</span> <span class="st">"mid_*|uid_*|gender_*|age|zip_*|occupation_*"</span></span>
<span id="cb42-2"><a href="#cb42-2" aria-hidden="true" tabindex="-1"></a>X <span class="op">=</span> data_pd_dum.<span class="bu">filter</span>(regex<span class="op">=</span>(<span class="st">'('</span><span class="op">+</span>attributes<span class="op">+</span><span class="st">')'</span>))</span>
<span id="cb42-3"><a href="#cb42-3" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(X.shape)</span>
<span id="cb42-4"><a href="#cb42-4" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb42-5"><a href="#cb42-5" aria-hidden="true" tabindex="-1"></a>rating <span class="op">=</span> data_pd_dum[<span class="st">'rating'</span>]</span>
<span id="cb42-6"><a href="#cb42-6" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(rating.shape)</span>
<span id="cb42-7"><a href="#cb42-7" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb42-8"><a href="#cb42-8" aria-hidden="true" tabindex="-1"></a><span class="co"># Split Train/Test</span></span>
<span id="cb42-9"><a href="#cb42-9" aria-hidden="true" tabindex="-1"></a><span class="co"># Keep 20% of the data for testing.</span></span>
<span id="cb42-10"><a href="#cb42-10" aria-hidden="true" tabindex="-1"></a>X_train, X_test, y_train, y_test <span class="op">=</span> train_test_split(</span>
<span id="cb42-11"><a href="#cb42-11" aria-hidden="true" tabindex="-1"></a>    X, rating, test_size<span class="op">=</span><span class="fl">0.2</span>, random_state<span class="op">=</span><span class="dv">1234</span>, shuffle<span class="op">=</span><span class="va">False</span>)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<p><em>Recommender Systems note:</em> We split the dataset without looking at users and items. In other words, more active users and popular items will be (on average) more represented in the heldout data. If this is not desired, for example one may wish a fairer treatment of users. We could then ensure that each user has the same amount of data in the heldout set (and similarly for items).</p>
<p><em>Recommender Systems note #2:</em> Practically speaking it would make more sense to divide ratings by timestamp. That is, train on ratings up to some date and test on ratings after that date (future ratings).</p>
<div class="cell">
<div class="sourceCode cell-code" id="cb43"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb43-1"><a href="#cb43-1" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(X_train.shape, X_test.shape, y_train.shape, y_test.shape)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<p><a id="modelling"></a> # Section 2: Modelling</p>
<p>Ratings (<a href="https://en.wikipedia.org/wiki/Likert_scale">likert scale</a>) are ordinal quantities. However, for ease of modelling and evaluation we treat ratings as real-valued (we will discuss in greater length some of these issues later this semester). Concretely, we will measure the loss/error using a mean-squared error function:</p>
<p><span class="math display">\[ \text{MSE}(f(x),y) := \frac{1}{n} \sum_{i=0}^n (f(x_i) - y_i)^2\]</span></p>
<p>The MSE can be understood as the average square distance between the predictor <span class="math inline">\(f(x_i)\)</span> and the target <span class="math inline">\(y_i\)</span>. MSE returns a non-negative quantity and the perfect predictor has an MSE of <span class="math inline">\(0\)</span>. If Model 1 has a smaller MSE than Model 2, its performance is higher according to that metric.</p>
<p><em>Train/Test:</em> Recall that while we estimate the parameters of the model using the <strong>train</strong> data, we evaluate the quality of the model (its performance) using <strong>test</strong> data.</p>
</section>
<section id="a-first-model-mean-predictor" class="level3">
<h3 class="anchored" data-anchor-id="a-first-model-mean-predictor">2.1 A first model: mean predictor</h3>
<p>It is often helpful to use a very simple benchmark to compare against the performance of our models.</p>
<p>Our initial benchmark is a model which simply predicts the mean (train) rating.</p>
<p><em>Recommender Systems note:</em> We could obtain a slightly better model by predicting with a user- or item-specific mean instead of the global mean.</p>
<div class="cell">
<div class="sourceCode cell-code" id="cb44"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb44-1"><a href="#cb44-1" aria-hidden="true" tabindex="-1"></a><span class="co"># Check accuracy of constant predictor</span></span>
<span id="cb44-2"><a href="#cb44-2" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb44-3"><a href="#cb44-3" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="st">"Constant predictor"</span>)</span>
<span id="cb44-4"><a href="#cb44-4" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb44-5"><a href="#cb44-5" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="st">"</span><span class="ch">\t</span><span class="st">Train mean-squared error: </span><span class="sc">%.3f</span><span class="st">"</span></span>
<span id="cb44-6"><a href="#cb44-6" aria-hidden="true" tabindex="-1"></a>      <span class="op">%</span> mean_squared_error(y_train,</span>
<span id="cb44-7"><a href="#cb44-7" aria-hidden="true" tabindex="-1"></a>                           np.full_like(y_train, y_train.mean())))</span>
<span id="cb44-8"><a href="#cb44-8" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="st">"</span><span class="ch">\t</span><span class="st">Test mean-squared error: </span><span class="sc">%.3f</span><span class="st">"</span></span>
<span id="cb44-9"><a href="#cb44-9" aria-hidden="true" tabindex="-1"></a>      <span class="op">%</span> mean_squared_error(y_test,</span>
<span id="cb44-10"><a href="#cb44-10" aria-hidden="true" tabindex="-1"></a>                           np.full_like(y_test, y_train.mean())))</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<p>The train and test errors are just about the same (I imagine that difference is not statistically significant). Our model is very simple (in machine learning term it has a high bias) and so you would not expect its performance to fluctuate much on the test set (i.e., small variance).</p>
<p>In terms of absolute values these indicate that, on average, our predictions are 1.3 units (<span class="math inline">\(\sqrt{1.6}\)</span>) away from the true rating. This indicates that you shouldn’t be too surprised that the model gives a rating below 4 to a movie that you would rate as a 5. Having said that, it is difficult to know how good this is before we compare to other methods.</p>
</section>
<section id="linear-regression" class="level3">
<h3 class="anchored" data-anchor-id="linear-regression">2.2 Linear regression</h3>
<p>For our second model, we will fit a linear regression that uses user features to predict ratings. In particular we use the users’ gender, age, zip, and occupation. We fit this model <span class="math display">\[
f(x_{ui}) = \theta_\text{gender} x_{\text{gender}_u} + \theta_{\text{age}} x_{\text{age}_u} + \theta_\text{zip} x_{\text{zip}_u} + \theta_\text{occupation} x_{\text{occupation}_u} + \theta_\text{uid} x_{\text{uid}_u} + \theta_{\text{mid}} x_{\text{mid}_i}
\]</span></p>
<p><span class="math inline">\(\theta_{1:6}\)</span> are the parameters, <span class="math inline">\(\text{gender}_u\)</span> stands for the gender of user <span class="math inline">\(u\)</span> and similarly for other covariates. Also, <span class="math inline">\(x_{\text{uid}_u}\)</span> represents the identity of the user and similarly for <span class="math inline">\(x_{\text{mid}_i}\)</span> and movies.</p>
<p>Note that some of these variables are categorial so in fact they are associated with a vector of parameters. For example, zip is a categorical variable with 100 different possible values and so <span class="math inline">\(\theta_{\text{zip}}\)</span> has 100 dimensions.</p>
<p>Training this model involves minimizing the train MSE, this is exactly what the <code>LinearRegression</code> class does. (This is a <a href="https://docs.scipy.org/doc/scipy/reference/generated/scipy.linalg.lstsq.html">least-squares problem</a> and it can be solved in closed form.)</p>
<div class="cell">
<div class="sourceCode cell-code" id="cb45"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb45-1"><a href="#cb45-1" aria-hidden="true" tabindex="-1"></a><span class="co"># Create linear regression object</span></span>
<span id="cb45-2"><a href="#cb45-2" aria-hidden="true" tabindex="-1"></a>reg <span class="op">=</span> linear_model.LinearRegression()</span>
<span id="cb45-3"><a href="#cb45-3" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb45-4"><a href="#cb45-4" aria-hidden="true" tabindex="-1"></a><span class="co"># Train the model using the training sets</span></span>
<span id="cb45-5"><a href="#cb45-5" aria-hidden="true" tabindex="-1"></a>reg.fit(X_train, y_train)</span>
<span id="cb45-6"><a href="#cb45-6" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb45-7"><a href="#cb45-7" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="st">"Number of parameters: "</span>, reg.coef_.shape[<span class="dv">0</span>]<span class="op">+</span><span class="dv">1</span>)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<div class="cell">
<div class="sourceCode cell-code" id="cb46"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb46-1"><a href="#cb46-1" aria-hidden="true" tabindex="-1"></a><span class="co"># Make train predictions</span></span>
<span id="cb46-2"><a href="#cb46-2" aria-hidden="true" tabindex="-1"></a>y_train_pred <span class="op">=</span> reg.predict(X_train)</span>
<span id="cb46-3"><a href="#cb46-3" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb46-4"><a href="#cb46-4" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="st">"Train Mean squared error: </span><span class="sc">%.3f</span><span class="st">"</span></span>
<span id="cb46-5"><a href="#cb46-5" aria-hidden="true" tabindex="-1"></a>      <span class="op">%</span> mean_squared_error(y_train, y_train_pred))</span>
<span id="cb46-6"><a href="#cb46-6" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb46-7"><a href="#cb46-7" aria-hidden="true" tabindex="-1"></a><span class="co"># Make test predictions</span></span>
<span id="cb46-8"><a href="#cb46-8" aria-hidden="true" tabindex="-1"></a>y_test_pred <span class="op">=</span> reg.predict(X_test)</span>
<span id="cb46-9"><a href="#cb46-9" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb46-10"><a href="#cb46-10" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="st">"Test Mean squared error: </span><span class="sc">%.3f</span><span class="st">"</span></span>
<span id="cb46-11"><a href="#cb46-11" aria-hidden="true" tabindex="-1"></a>      <span class="op">%</span> mean_squared_error(y_test, y_test_pred))</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<p>We note that train error <span class="math inline">\(&lt;&lt;\)</span> test error (<span class="math inline">\(&lt;&lt;\)</span> stands for “much smaller”). This is a clear case of overfitting. That is, the model has learned the training data and cannot generalize to new unseen data (it’s a low bias and high variance model).</p>
<p>Different methods can help prevent the model from overfitting, this is often referred to as <em>regularizing</em> the model. Here we will add a penalty that constrains the learned parameters to stay close to zero. Intuitively, this learns a function that is smoother and, the hope is, that generalizes better. This penalty or regularizer is added to the loss function which becomes: <span class="math display">\[  \text{loss} := \text{MSE} + \alpha \sum_i ||\theta_i||_2^2 \]</span></p>
<p>Instead of the previous $ := $.</p>
<p>Note: - <span class="math inline">\(||\cdot||_2\)</span> stands for the 2-Norm. That is, the square root of the sum of the operand’s squared elements. - <span class="math inline">\(\alpha\)</span> is a hyper-parameter which denotes the strength of the regularizer (if <span class="math inline">\(\alpha=0\)</span> the regularizer vanishes and if <span class="math inline">\(\alpha=\infty\)</span> all parameters must be equal to exactly 0). A hyperparameter is a parameter that is not learned during training but set a priori (here, learning <span class="math inline">\(\alpha\)</span> along with the <span class="math inline">\(\theta\)</span>s would lead to a <span class="math inline">\(\alpha=0\)</span>).</p>
<p>During learning the model must then tradeoff performance (MSE) and complexity (high <span class="math inline">\(\theta\)</span>s). There are different names for this particular regularizer including weight decay, L2-regularization, and ridge (regression). Scikit-learn offers the <code>Ridge</code> class from the <code>linear_model</code> package to fit regularized linear regression models.</p>
<div class="cell">
<div class="sourceCode cell-code" id="cb47"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb47-1"><a href="#cb47-1" aria-hidden="true" tabindex="-1"></a><span class="co"># Create linear regression object</span></span>
<span id="cb47-2"><a href="#cb47-2" aria-hidden="true" tabindex="-1"></a>regr <span class="op">=</span> linear_model.Ridge(alpha<span class="op">=</span><span class="dv">10</span>)</span>
<span id="cb47-3"><a href="#cb47-3" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb47-4"><a href="#cb47-4" aria-hidden="true" tabindex="-1"></a><span class="co"># Train the model using the training sets</span></span>
<span id="cb47-5"><a href="#cb47-5" aria-hidden="true" tabindex="-1"></a>start <span class="op">=</span> time.time()</span>
<span id="cb47-6"><a href="#cb47-6" aria-hidden="true" tabindex="-1"></a>regr.fit(X_train, y_train)</span>
<span id="cb47-7"><a href="#cb47-7" aria-hidden="true" tabindex="-1"></a>fit_time <span class="op">=</span> time.time() <span class="op">-</span> start</span>
<span id="cb47-8"><a href="#cb47-8" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb47-9"><a href="#cb47-9" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="st">"Fitting time: </span><span class="sc">%.2f</span><span class="st"> seconds"</span> <span class="op">%</span> fit_time)</span>
<span id="cb47-10"><a href="#cb47-10" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb47-11"><a href="#cb47-11" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="st">"Number of parameters:"</span>, regr.coef_.shape[<span class="dv">0</span>]<span class="op">+</span><span class="dv">1</span>)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<p><strong>Question 3</strong> Explain why there are 7,184 parameters.</p>
<p><strong>Hint:</strong> Don’t forget the intercept/bias term</p>
<div class="cell">
<div class="sourceCode cell-code" id="cb48"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb48-1"><a href="#cb48-1" aria-hidden="true" tabindex="-1"></a><span class="co"># Make train predictions</span></span>
<span id="cb48-2"><a href="#cb48-2" aria-hidden="true" tabindex="-1"></a>y_train_pred <span class="op">=</span> regr.predict(X_train)</span>
<span id="cb48-3"><a href="#cb48-3" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb48-4"><a href="#cb48-4" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="st">"Train Mean squared error: </span><span class="sc">%.3f</span><span class="st">"</span></span>
<span id="cb48-5"><a href="#cb48-5" aria-hidden="true" tabindex="-1"></a>      <span class="op">%</span> mean_squared_error(y_train, y_train_pred))</span>
<span id="cb48-6"><a href="#cb48-6" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb48-7"><a href="#cb48-7" aria-hidden="true" tabindex="-1"></a><span class="co"># Make test predictions</span></span>
<span id="cb48-8"><a href="#cb48-8" aria-hidden="true" tabindex="-1"></a>y_test_pred <span class="op">=</span> regr.predict(X_test)</span>
<span id="cb48-9"><a href="#cb48-9" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb48-10"><a href="#cb48-10" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="st">"Test Mean squared error: </span><span class="sc">%.3f</span><span class="st">"</span></span>
<span id="cb48-11"><a href="#cb48-11" aria-hidden="true" tabindex="-1"></a>      <span class="op">%</span> mean_squared_error(y_test, y_test_pred))</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<p>Compared to above, we see that with <span class="math inline">\(\alpha=10\)</span> the train and test errors are much closer (i.e., there’s less overfitting). Presumably different values of <span class="math inline">\(\alpha\)</span> would yield different generalizations.</p>
<p><strong>Question 4</strong> How do you find the “best” value of <span class="math inline">\(\alpha\)</span> for a given model and dataset?</p>
<p><strong>Hint:</strong> Have a look at the <a href="https://scikit-learn.org/stable/modules/generated/sklearn.linear_model.RidgeCV.html#sklearn.linear_model.RidgeCV">RidgeCV</a>, a cross-validation enabled version of Ridge.</p>
<p><strong>Answer:</strong> See below.</p>
<div class="cell">
<div class="sourceCode cell-code" id="cb49"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb49-1"><a href="#cb49-1" aria-hidden="true" tabindex="-1"></a><span class="co"># Create linear regression object</span></span>
<span id="cb49-2"><a href="#cb49-2" aria-hidden="true" tabindex="-1"></a>regRCV <span class="op">=</span> ...</span>
<span id="cb49-3"><a href="#cb49-3" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb49-4"><a href="#cb49-4" aria-hidden="true" tabindex="-1"></a><span class="co"># Train the model using the training sets</span></span>
<span id="cb49-5"><a href="#cb49-5" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb49-6"><a href="#cb49-6" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb49-7"><a href="#cb49-7" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="st">"Number of parameters: </span><span class="sc">%d</span><span class="st">, estimated alpha: </span><span class="sc">%d</span><span class="st">"</span> <span class="op">%</span> (regRCV.coef_.shape[<span class="dv">0</span>], regRCV.alpha_))</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<p>Technical remark: since the optimization is often done in log space, it’s typical for the set of <span class="math inline">\(\alpha\)</span>’s to be powers of 10.</p>
<div class="cell">
<div class="sourceCode cell-code" id="cb50"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb50-1"><a href="#cb50-1" aria-hidden="true" tabindex="-1"></a><span class="co"># Make train predictions</span></span>
<span id="cb50-2"><a href="#cb50-2" aria-hidden="true" tabindex="-1"></a>y_train_pred <span class="op">=</span> ...</span>
<span id="cb50-3"><a href="#cb50-3" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb50-4"><a href="#cb50-4" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="st">"Train Mean squared error: </span><span class="sc">%.3f</span><span class="st">"</span></span>
<span id="cb50-5"><a href="#cb50-5" aria-hidden="true" tabindex="-1"></a>      <span class="op">%</span> mean_squared_error(y_train, y_train_pred))</span>
<span id="cb50-6"><a href="#cb50-6" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb50-7"><a href="#cb50-7" aria-hidden="true" tabindex="-1"></a><span class="co"># Make test predictions</span></span>
<span id="cb50-8"><a href="#cb50-8" aria-hidden="true" tabindex="-1"></a>y_test_pred <span class="op">=</span> ...</span>
<span id="cb50-9"><a href="#cb50-9" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb50-10"><a href="#cb50-10" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="st">"Test Mean squared error: </span><span class="sc">%.3f</span><span class="st">"</span></span>
<span id="cb50-11"><a href="#cb50-11" aria-hidden="true" tabindex="-1"></a>      <span class="op">%</span> mean_squared_error(y_test, y_test_pred))</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<p>The advantage of doing cross validation (for example using <code>RidgeCV</code>) is clear. It automatically searches for the best values of hyperparameters (here <span class="math inline">\(\alpha\)</span>) from a given set (here <span class="math inline">\(\{ 1, 10, 100 \}\)</span>).</p>
<p>A validation set (or cross validation) should always be used to search for good hyperparameters (especially for non-linear models different values of hyperparameters may give very different results). In certain cases you may have to manually implement validation. In such cases you will likely need to split a separate validation set from your training data–in <code>sklearn</code> you can use the <code>train_test_split</code> function. It is typical for the validation set to be the same size as the test set.</p>
<p>You should also remember to <strong>never select model hyperparameters based on performance on test set</strong>, this would give you over-optimistic results because you are effectively using your test set to tune your models (its hyperparameters). The main purpose of the test set is to provide an unbiased way of comparing different models.</p>
<hr>
<p>Armed with a good model we can explore the learned model including some of its predictions</p>
<div class="cell">
<div class="sourceCode cell-code" id="cb51"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb51-1"><a href="#cb51-1" aria-hidden="true" tabindex="-1"></a><span class="co"># helper function to return non-zero columns</span></span>
<span id="cb51-2"><a href="#cb51-2" aria-hidden="true" tabindex="-1"></a><span class="kw">def</span> non_zero(row, columns):</span>
<span id="cb51-3"><a href="#cb51-3" aria-hidden="true" tabindex="-1"></a>    col_name <span class="op">=</span> <span class="bu">list</span>(columns[<span class="op">~</span>(row <span class="op">==</span> <span class="dv">0</span>)])[<span class="dv">0</span>]</span>
<span id="cb51-4"><a href="#cb51-4" aria-hidden="true" tabindex="-1"></a>    <span class="co">#r = re.sub('mid_','',l)</span></span>
<span id="cb51-5"><a href="#cb51-5" aria-hidden="true" tabindex="-1"></a>    <span class="cf">return</span> col_name</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<div class="cell">
<div class="sourceCode cell-code" id="cb52"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb52-1"><a href="#cb52-1" aria-hidden="true" tabindex="-1"></a><span class="co"># get number of ratings per movie (popularity)</span></span>
<span id="cb52-2"><a href="#cb52-2" aria-hidden="true" tabindex="-1"></a>mids <span class="op">=</span> X_test.<span class="bu">filter</span>(regex<span class="op">=</span>(<span class="st">'mid_*'</span>))</span>
<span id="cb52-3"><a href="#cb52-3" aria-hidden="true" tabindex="-1"></a>y_mid_cols <span class="op">=</span> mids.<span class="bu">apply</span>(<span class="kw">lambda</span> x: non_zero(x, mids.columns), axis<span class="op">=</span><span class="dv">1</span>)</span>
<span id="cb52-4"><a href="#cb52-4" aria-hidden="true" tabindex="-1"></a>movie_popularity <span class="op">=</span> X_train.<span class="bu">filter</span>(regex<span class="op">=</span>(<span class="st">'mid_*'</span>)).<span class="bu">sum</span>(axis<span class="op">=</span><span class="dv">0</span>)[ y_mid_cols ]</span>
<span id="cb52-5"><a href="#cb52-5" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb52-6"><a href="#cb52-6" aria-hidden="true" tabindex="-1"></a><span class="co"># get number of ratings per user (activity)</span></span>
<span id="cb52-7"><a href="#cb52-7" aria-hidden="true" tabindex="-1"></a>uids <span class="op">=</span> X_test.<span class="bu">filter</span>(regex<span class="op">=</span>(<span class="st">'uid_*'</span>))</span>
<span id="cb52-8"><a href="#cb52-8" aria-hidden="true" tabindex="-1"></a>y_uid_cols <span class="op">=</span> uids.<span class="bu">apply</span>(<span class="kw">lambda</span> x: non_zero(x, uids.columns), axis<span class="op">=</span><span class="dv">1</span>)</span>
<span id="cb52-9"><a href="#cb52-9" aria-hidden="true" tabindex="-1"></a>user_activity <span class="op">=</span> X_train.<span class="bu">filter</span>(regex<span class="op">=</span>(<span class="st">'uid_*'</span>)).<span class="bu">sum</span>(axis<span class="op">=</span><span class="dv">0</span>)[ y_uid_cols ]</span>
<span id="cb52-10"><a href="#cb52-10" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb52-11"><a href="#cb52-11" aria-hidden="true" tabindex="-1"></a>err <span class="op">=</span> (y_test_pred<span class="op">-</span>y_test)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<div class="cell">
<div class="sourceCode cell-code" id="cb53"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb53-1"><a href="#cb53-1" aria-hidden="true" tabindex="-1"></a><span class="co"># only plot a subsample for higher readability</span></span>
<span id="cb53-2"><a href="#cb53-2" aria-hidden="true" tabindex="-1"></a>subn <span class="op">=</span> <span class="dv">500</span></span>
<span id="cb53-3"><a href="#cb53-3" aria-hidden="true" tabindex="-1"></a>fig, (ax0, ax1) <span class="op">=</span> plt.subplots(ncols<span class="op">=</span><span class="dv">2</span>)</span>
<span id="cb53-4"><a href="#cb53-4" aria-hidden="true" tabindex="-1"></a>fig.set_figwidth(<span class="dv">15</span>)</span>
<span id="cb53-5"><a href="#cb53-5" aria-hidden="true" tabindex="-1"></a>ax0.scatter(movie_popularity[:subn], err[:subn])</span>
<span id="cb53-6"><a href="#cb53-6" aria-hidden="true" tabindex="-1"></a>ax0.set_ylabel(<span class="st">'Prediction error'</span>)</span>
<span id="cb53-7"><a href="#cb53-7" aria-hidden="true" tabindex="-1"></a>ax0.set_xlabel(<span class="st">'Movie Popularity'</span>)</span>
<span id="cb53-8"><a href="#cb53-8" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb53-9"><a href="#cb53-9" aria-hidden="true" tabindex="-1"></a>ax1.scatter(user_activity[:subn], err[:subn])</span>
<span id="cb53-10"><a href="#cb53-10" aria-hidden="true" tabindex="-1"></a>ax1.set_ylabel(<span class="st">'Prediction error'</span>)</span>
<span id="cb53-11"><a href="#cb53-11" aria-hidden="true" tabindex="-1"></a>ax1.set_xlabel(<span class="st">'User Activity'</span>)<span class="op">;</span></span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<p>Above we plotted the prediction error of (a subset of) test ratings compared to the popularity of movies (left) and activity level of users (right). We note that:</p>
<ul>
<li>This empirical distribution looks symmetrical so there doesn’t seem to be a bias toward lower or higher predictions</li>
<li>The prediction errors seem to show that movies and users with more data have smaller prediction error (i.e., the data forms a “triangle” pointing to the right, this is much clearer when running w. more training data which we limit here to save time). This is intuitive, the more data you have about an item the more accurate should be the estimation of its parameters (<span class="math inline">\(\theta_{\text{mid}}\)</span>). This could also be reinforced by the fact that we are splitting ratings randomly for train and test (versus splitting by user or item). Hence, popular movies and high-activity users have a great influence in the learning process.</li>
</ul>
</section>
<section id="linear-regression-with-tag-featurescovariates" class="level3">
<h3 class="anchored" data-anchor-id="linear-regression-with-tag-featurescovariates">2.3 Linear regression with tag features/covariates</h3>
<p>We use a linear regression model as above but also model movie tags:</p>
<p><span class="math display">\[
f(x_{ui}) = \theta_\text{gender} x_{\text{gender}_u} + \theta_{\text{age}} x_{\text{age}_u} + \theta_\text{zip} x_{\text{zip}_u} + \theta_\text{occupation} x_{\text{occupation}_u} + \theta_\text{uid} x_{\text{uid}_u} + \theta_{\text{mid}} x_{\text{mid}_i} \mathbf{+ x_{\text{tags}_i}\boldsymbol\theta_\text{tags}}
\]</span></p>
<p>The last term on the right-hand side (bolded) is the only difference wrt to our previous model.</p>
<p><strong>Question 5:</strong> How do you think that this new model will compare to the previous model of Section 2.2? Can you say something definitive about its performance?</p>
<p><strong>Hint:</strong> One model is a special case of another.</p>
<div class="cell">
<div class="sourceCode cell-code" id="cb54"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb54-1"><a href="#cb54-1" aria-hidden="true" tabindex="-1"></a><span class="co"># This is very similar to how we constructed our dataset above except that we add the tags columns</span></span>
<span id="cb54-2"><a href="#cb54-2" aria-hidden="true" tabindex="-1"></a>X_tags <span class="op">=</span> data_pd_dum.<span class="bu">filter</span>(regex<span class="op">=</span>(<span class="st">'('</span><span class="op">+</span>attributes<span class="op">+</span><span class="st">"|tid_*"</span><span class="op">+</span><span class="st">')'</span>))</span>
<span id="cb54-3"><a href="#cb54-3" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(X_tags.shape)</span>
<span id="cb54-4"><a href="#cb54-4" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb54-5"><a href="#cb54-5" aria-hidden="true" tabindex="-1"></a><span class="co"># Split Train/Test. Notice that we use the same seed as above to replicate that split.</span></span>
<span id="cb54-6"><a href="#cb54-6" aria-hidden="true" tabindex="-1"></a>X_train_tags, X_test_tags, y_train_tags, y_test_tags <span class="op">=</span> train_test_split(</span>
<span id="cb54-7"><a href="#cb54-7" aria-hidden="true" tabindex="-1"></a>    X_tags, rating, test_size<span class="op">=</span><span class="fl">0.2</span>, random_state<span class="op">=</span><span class="dv">1234</span>, shuffle<span class="op">=</span><span class="va">False</span>)</span>
<span id="cb54-8"><a href="#cb54-8" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(X_train_tags.shape)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<div class="cell">
<div class="sourceCode cell-code" id="cb55"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb55-1"><a href="#cb55-1" aria-hidden="true" tabindex="-1"></a><span class="co"># Create linear regression object</span></span>
<span id="cb55-2"><a href="#cb55-2" aria-hidden="true" tabindex="-1"></a>regr_tags <span class="op">=</span> linear_model.Ridge(alpha<span class="op">=</span><span class="dv">10</span>)</span>
<span id="cb55-3"><a href="#cb55-3" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb55-4"><a href="#cb55-4" aria-hidden="true" tabindex="-1"></a><span class="co"># Train the model using the training sets</span></span>
<span id="cb55-5"><a href="#cb55-5" aria-hidden="true" tabindex="-1"></a>start <span class="op">=</span> time.time()</span>
<span id="cb55-6"><a href="#cb55-6" aria-hidden="true" tabindex="-1"></a>regr_tags.fit(X_train_tags, y_train_tags)</span>
<span id="cb55-7"><a href="#cb55-7" aria-hidden="true" tabindex="-1"></a>fit_time <span class="op">=</span> time.time() <span class="op">-</span> start</span>
<span id="cb55-8"><a href="#cb55-8" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb55-9"><a href="#cb55-9" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="st">"fitting time: </span><span class="sc">%.2f</span><span class="st"> seconds"</span> <span class="op">%</span> fit_time)</span>
<span id="cb55-10"><a href="#cb55-10" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="st">"number of parameters:"</span>, regr_tags.coef_.shape[<span class="dv">0</span>]<span class="op">+</span><span class="dv">1</span>)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<div class="cell">
<div class="sourceCode cell-code" id="cb56"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb56-1"><a href="#cb56-1" aria-hidden="true" tabindex="-1"></a><span class="co"># Make train predictions</span></span>
<span id="cb56-2"><a href="#cb56-2" aria-hidden="true" tabindex="-1"></a>y_train_pred <span class="op">=</span> regr_tags.predict(X_train_tags)</span>
<span id="cb56-3"><a href="#cb56-3" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb56-4"><a href="#cb56-4" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="st">"Train Mean squared error: </span><span class="sc">%.4f</span><span class="st">"</span></span>
<span id="cb56-5"><a href="#cb56-5" aria-hidden="true" tabindex="-1"></a>      <span class="op">%</span> mean_squared_error(y_train_tags, y_train_pred))</span>
<span id="cb56-6"><a href="#cb56-6" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb56-7"><a href="#cb56-7" aria-hidden="true" tabindex="-1"></a><span class="co"># Make test predictions</span></span>
<span id="cb56-8"><a href="#cb56-8" aria-hidden="true" tabindex="-1"></a>y_test_pred <span class="op">=</span> regr_tags.predict(X_test_tags)</span>
<span id="cb56-9"><a href="#cb56-9" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb56-10"><a href="#cb56-10" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="st">"Test Mean squared error: </span><span class="sc">%.4f</span><span class="st">"</span></span>
<span id="cb56-11"><a href="#cb56-11" aria-hidden="true" tabindex="-1"></a>      <span class="op">%</span> mean_squared_error(y_test_tags, y_test_pred))</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<p>Remarks: We obtain a test MSE of 0.99 for model 2.3 compared to a test MSE of 1.03 for model 2.2. So the tags do seem to provide slightly better test performance at the expense of a slightly larger model (968 extra parameters to fit) which takes about 30% longer to fit. Take this with a grain of salt because it is hardware dependent. But, this hints at the fact that the fitting algorithm is not linear (i.e., increasing the number of parameters by 10% yields an increase of 30% in running time).</p>
<hr>
</section>
<section id="fitting-a-non-linear-model" class="level3">
<h3 class="anchored" data-anchor-id="fitting-a-non-linear-model">2.4 Fitting a non-linear model</h3>
<p>So far we have studied the effect of using different features on a linear model. We note that adding features seems to help, as long as the features provide novel and predictive information and are not redundant.</p>
<p>Here we explore a non-linear model, a one-hidden layer neural network for regression. The task and the data are the same as before, only the model changes.</p>
<p><strong>Neural network basics:</strong> (We will discuss these models in some depth over the next two weeks.) - A neural network is made up of interconnected <em>neurons</em>. Each neuron computes a few simple operations. - In a <em>feed-forward network</em>, neurons are organized into sets called <em>layers</em>. - Neurons in each layer get their inputs from the previous layer and send their outputs to the next layer. - The first layer is called the <em>input layer</em> it provides data to the next layer. The last layer is the <em>output layer</em> it provides a prediction <span class="math inline">\(\hat{y}\)</span>. - Layers in between the input layer and the output layer are called <em>hidden layers</em>. Each neuron in the hidden layers is a linear regression model followed by a non-linear function (<em>activation function</em>): <span class="math inline">\(f(x) = \sum_i x_i \theta_i\)</span>. - The number of neurons in the input and output layers are fixed by the data (the number of features and the number of predictions). - The number of neurons of a hidden layer is a hyperparameter. Another hyperparameter is the number of hidden layers.</p>
<p>Mathematically for a regression task (with a single output), a one-hidden layer neural net is: <span class="math display">\[
f(x) = f_\text{o} ( \sum_{j=0}^{|\text{hidden n.}|} \theta'_{j} f_\text{h}( \sum_{i=0}^{|p|}\theta_{ij} x_i ) )
\]</span> where - <span class="math inline">\(\theta_{ij}\)</span> are the parameters of input <span class="math inline">\(i\)</span> and neuron <span class="math inline">\(j\)</span> in the hidden layer. - <span class="math inline">\(f_h\)</span> is the activation function of the hidden layer - <span class="math inline">\(\theta'_{j}\)</span> are the parameters that connect the neuron <span class="math inline">\(j\)</span> in the hidden layer to the output layer. - <span class="math inline">\(f_o\)</span> is the activation function of the output layer</p>
<p>An intuitive way of visualization a neural net (especially large ones) is to draw neurons as nodes and connections between neurons as arcs:</p>
<div class="cell">
<div class="sourceCode cell-code" id="cb57"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb57-1"><a href="#cb57-1" aria-hidden="true" tabindex="-1"></a><span class="co"># a 1 hidden layer neural net, where the input has 10 dimensions (p=10) and the output 1</span></span>
<span id="cb57-2"><a href="#cb57-2" aria-hidden="true" tabindex="-1"></a>input_dims <span class="op">=</span> <span class="dv">10</span> <span class="co"># p</span></span>
<span id="cb57-3"><a href="#cb57-3" aria-hidden="true" tabindex="-1"></a>hidden_layers_size <span class="op">=</span> [<span class="dv">4</span>] <span class="co"># number of hidden neurons for each hidden layer (adding a dimension adds a layer)</span></span>
<span id="cb57-4"><a href="#cb57-4" aria-hidden="true" tabindex="-1"></a>output_dims <span class="op">=</span> <span class="dv">1</span> <span class="co"># number of outputs</span></span>
<span id="cb57-5"><a href="#cb57-5" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb57-6"><a href="#cb57-6" aria-hidden="true" tabindex="-1"></a>network <span class="op">=</span> DrawNN( [input_dims] <span class="op">+</span> hidden_layers_size <span class="op">+</span> [output_dims] )</span>
<span id="cb57-7"><a href="#cb57-7" aria-hidden="true" tabindex="-1"></a>network.draw()</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<div class="cell" data-scrolled="true">
<div class="sourceCode cell-code" id="cb58"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb58-1"><a href="#cb58-1" aria-hidden="true" tabindex="-1"></a><span class="co"># Fit a neural network on this data.</span></span>
<span id="cb58-2"><a href="#cb58-2" aria-hidden="true" tabindex="-1"></a>regr_nn <span class="op">=</span> neural_network.MLPRegressor(alpha<span class="op">=</span><span class="fl">0.1</span>, <span class="co"># l2-regularization (weight decay)</span></span>
<span id="cb58-3"><a href="#cb58-3" aria-hidden="true" tabindex="-1"></a>                                      hidden_layer_sizes<span class="op">=</span><span class="bu">tuple</span>(hidden_layers_size),</span>
<span id="cb58-4"><a href="#cb58-4" aria-hidden="true" tabindex="-1"></a>                                      early_stopping<span class="op">=</span><span class="va">True</span>, <span class="co"># stop if validation performance decreases</span></span>
<span id="cb58-5"><a href="#cb58-5" aria-hidden="true" tabindex="-1"></a>                                      verbose<span class="op">=</span><span class="va">True</span>,</span>
<span id="cb58-6"><a href="#cb58-6" aria-hidden="true" tabindex="-1"></a>                                      random_state<span class="op">=</span><span class="dv">1234</span>)</span>
<span id="cb58-7"><a href="#cb58-7" aria-hidden="true" tabindex="-1"></a>start <span class="op">=</span> time.time()</span>
<span id="cb58-8"><a href="#cb58-8" aria-hidden="true" tabindex="-1"></a>regr_nn.fit(X_train_tags.values, y_train_tags)</span>
<span id="cb58-9"><a href="#cb58-9" aria-hidden="true" tabindex="-1"></a>fit_time <span class="op">=</span> time.time() <span class="op">-</span> start</span>
<span id="cb58-10"><a href="#cb58-10" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb58-11"><a href="#cb58-11" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="st">"fitting time: </span><span class="sc">%.2f</span><span class="st"> seconds"</span> <span class="op">%</span> fit_time)</span>
<span id="cb58-12"><a href="#cb58-12" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="st">"number of parameters:"</span>, <span class="bu">reduce</span>(<span class="kw">lambda</span> x,y: x<span class="op">+</span>y,</span>
<span id="cb58-13"><a href="#cb58-13" aria-hidden="true" tabindex="-1"></a>                                       <span class="bu">list</span>(<span class="bu">map</span>(<span class="kw">lambda</span> x: x.size, regr_nn.coefs_<span class="op">+</span>regr_nn.intercepts_)) ))</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<p>Much like previous models we can regularize a neural net to combat overfitting: - Here we use the same L2-penalty regularizer on all parameters. The strength of this regularizer is given by <span class="math inline">\(\alpha\)</span>. - In addition, we use a second regularizer called <code>early-stopping</code>. Learning the parameters of a neural network is done iteratively using a method called gradient descent (as opposed to linear regression, there is no analytical solution for the parameters given the objective function). Early stopping simply evaluates the validation error after each iteration. It stops learning when the validation error stops improving. This can happen before the training loss converges. When it does not, then this regularizer has no effect on learning. In <code>scikit-learn</code>, the MLPRegressor class with <code>early_stopping=True</code> automatically splits a validation set from the training set to be used by this regularizer. The disadvantage, of course, is that this reduces the amount of data used to fit parameters.</p>
<p><strong>Question 6:</strong> Why does this model come with the possibility to set the random seed (i.e., <code>random_state</code>) while linear regression did not?</p>
<div class="cell">
<div class="sourceCode cell-code" id="cb59"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb59-1"><a href="#cb59-1" aria-hidden="true" tabindex="-1"></a><span class="co"># Make train predictions</span></span>
<span id="cb59-2"><a href="#cb59-2" aria-hidden="true" tabindex="-1"></a>y_train_pred <span class="op">=</span> regr_nn.predict(X_train_tags.values)</span>
<span id="cb59-3"><a href="#cb59-3" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb59-4"><a href="#cb59-4" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="st">"Train Mean squared error: </span><span class="sc">%.4f</span><span class="st">"</span></span>
<span id="cb59-5"><a href="#cb59-5" aria-hidden="true" tabindex="-1"></a>      <span class="op">%</span> mean_squared_error(y_train_tags, y_train_pred))</span>
<span id="cb59-6"><a href="#cb59-6" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb59-7"><a href="#cb59-7" aria-hidden="true" tabindex="-1"></a><span class="co"># Make test predictions</span></span>
<span id="cb59-8"><a href="#cb59-8" aria-hidden="true" tabindex="-1"></a>y_test_pred <span class="op">=</span> regr_nn.predict(X_test_tags.values)</span>
<span id="cb59-9"><a href="#cb59-9" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb59-10"><a href="#cb59-10" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="st">"Test Mean squared error: </span><span class="sc">%.4f</span><span class="st">"</span></span>
<span id="cb59-11"><a href="#cb59-11" aria-hidden="true" tabindex="-1"></a>      <span class="op">%</span> mean_squared_error(y_test_tags, y_test_pred))</span>
<span id="cb59-12"><a href="#cb59-12" aria-hidden="true" tabindex="-1"></a><span class="co">#Train Mean squared error: 0.6623</span></span>
<span id="cb59-13"><a href="#cb59-13" aria-hidden="true" tabindex="-1"></a><span class="co">#Test Mean squared error: 1.0465</span></span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<p>Here is our updated table of results</p>
<table class="table">
<thead>
<tr class="header">
<th>Model</th>
<th style="text-align: center;">Test MSE</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td>2.2 (Linear Reg. w. basic features)</td>
<td style="text-align: center;">1.031</td>
</tr>
<tr class="even">
<td>2.3 (2.2 + movie tags)</td>
<td style="text-align: center;">0.991</td>
</tr>
<tr class="odd">
<td>2.4 (Neural Network w. features from 2.3)</td>
<td style="text-align: center;">1.029</td>
</tr>
</tbody>
</table>
<p>Although neural networks are very powerful models, on this task the performance of our neural net does not outperform a simpler linear regression model. This of course does not mean that a different neural net (for example, one with more neurons per layer or more layers or just one trained from different hyperparameters) could not do better.</p>
<p><a id="concluding-remarks"></a> ### Section 3. Concluding Remarks</p>
<p>The goal of this tutorial was to put in practice some of the principles that we have discussed since the start of this course (and hint at some of the things that are coming in the next weeks). We will spend one full week (week #11) thinking about preference data including where it’s coming from and how to model it.</p>
<p>Here are a few more parting thoughts:</p>
<section id="machine-learning" class="level4">
<h4 class="anchored" data-anchor-id="machine-learning">Machine Learning</h4>
<p>As you might have noticed, applied machine learning is a very empirical endeavour. Once you have data in the right format, it is typical to fit it using several models, each time trying to understand the advantages/disadvantages of each model and getting a more thorough understanding of the data. In practice, this last part may be crucial and we did not adress it much in this tutorial (instead focussing on the models themeselves).</p>
</section>
<section id="scikit-learn" class="level4">
<h4 class="anchored" data-anchor-id="scikit-learn">Scikit-learn</h4>
<p><code>scikit-learn</code> is a powerful ML library. It is meant as a model (and data pre-processing) toolbox. It provides an interface to a wide variety of models, it is actively developped, and in general seen as a very good plateform. It is also open source and free to use.</p>
<p>Model Selection, i.e., which model should I use for a particular dataset/task can be daunting. <a href="https://scikit-learn.org/stable/tutorial/machine_learning_map/index.html">This page</a> provides some tips particular to <code>scikit-learn</code>. In general, when working on a new task/dataset it is often useful to try and compare different models. Remember that in practice (mean) test-performance is only one of the possible desiderata (others include running time both for training and other metrics like false positive rates).</p>
<p>Note that <code>scikit-learn</code> does not fit every use case. For example, its support of modern neural networks is fairly modest. It is also not meant as a development plateform for new models.</p>
</section>
<section id="other-packages" class="level4">
<h4 class="anchored" data-anchor-id="other-packages">Other packages</h4>
<p>Software is one of the reasons behind the rise of modern machine learning. Modern software automatize a number of tasks which allow programmers and researchers alike to be much more efficient. <code>scikit-learn</code> is one popular package for fitting machine learning models but there exist others (both applied and also for exploration/development purposes). All in all, it can be useful to know about these packages but (in my opinion) it is more useful to have a good understanding of the fundamentals of the field as the package landscape changes rapidly and one can always learn one more.</p>
</section>
<section id="food-for-thought" class="level4">
<h4 class="anchored" data-anchor-id="food-for-thought">Food for thought</h4>
<ul>
<li>In our models we assumed that ratings were the dependent variable (y) and that we had covariates (e.g., features of users and movies). Imagine a setting where we don’t have any features or, somewhat equivalently, only have features that end up not being predictive of ratings. In that case the linear regression model would be:</li>
</ul>
<p><span class="math display">\[
f(x_{ui}) = \theta_\text{uid} x_{\text{uid}_u} + \theta_{\text{mid}} x_{\text{mid}_i}
\]</span></p>
<ul>
<li><p><strong>Question 7:</strong> What’s wrong with the above model? Try to think about it for a minute or two before looking at the answer.</p></li>
<li><p>As we will see during week 11 (on recommender systems), many models take ratings as output <strong>and</strong> as input. For example, one could take a user’s previous ratings and try to predict one’s future ratings (for example using an auto-encoder model). This is a nice way to build models that do not require any user/item covariates (and these models can also be extended when that data exist).</p></li>
</ul>
</section>
</section>
</section>
<section id="references" class="level2">
<h2 class="anchored" data-anchor-id="references">References</h2>
<p>Scikit-learn - <a href="https://scikit-learn.org/stable/documentation.html">Documentation</a> - <a href="https://scikit-learn.org/stable/tutorial/index.html">Tutorials</a> - <a href="https://scikit-learn.org/stable/tutorial/machine_learning_map/index.html">Help for model selection</a></p>


</section>
</section>

</main> <!-- /main -->
<script id="quarto-html-after-body" type="application/javascript">
window.document.addEventListener("DOMContentLoaded", function (event) {
  const toggleBodyColorMode = (bsSheetEl) => {
    const mode = bsSheetEl.getAttribute("data-mode");
    const bodyEl = window.document.querySelector("body");
    if (mode === "dark") {
      bodyEl.classList.add("quarto-dark");
      bodyEl.classList.remove("quarto-light");
    } else {
      bodyEl.classList.add("quarto-light");
      bodyEl.classList.remove("quarto-dark");
    }
  }
  const toggleBodyColorPrimary = () => {
    const bsSheetEl = window.document.querySelector("link#quarto-bootstrap");
    if (bsSheetEl) {
      toggleBodyColorMode(bsSheetEl);
    }
  }
  toggleBodyColorPrimary();  
  const icon = "";
  const anchorJS = new window.AnchorJS();
  anchorJS.options = {
    placement: 'right',
    icon: icon
  };
  anchorJS.add('.anchored');
  const isCodeAnnotation = (el) => {
    for (const clz of el.classList) {
      if (clz.startsWith('code-annotation-')) {                     
        return true;
      }
    }
    return false;
  }
  const clipboard = new window.ClipboardJS('.code-copy-button', {
    text: function(trigger) {
      const codeEl = trigger.previousElementSibling.cloneNode(true);
      for (const childEl of codeEl.children) {
        if (isCodeAnnotation(childEl)) {
          childEl.remove();
        }
      }
      return codeEl.innerText;
    }
  });
  clipboard.on('success', function(e) {
    // button target
    const button = e.trigger;
    // don't keep focus
    button.blur();
    // flash "checked"
    button.classList.add('code-copy-button-checked');
    var currentTitle = button.getAttribute("title");
    button.setAttribute("title", "Copied!");
    let tooltip;
    if (window.bootstrap) {
      button.setAttribute("data-bs-toggle", "tooltip");
      button.setAttribute("data-bs-placement", "left");
      button.setAttribute("data-bs-title", "Copied!");
      tooltip = new bootstrap.Tooltip(button, 
        { trigger: "manual", 
          customClass: "code-copy-button-tooltip",
          offset: [0, -8]});
      tooltip.show();    
    }
    setTimeout(function() {
      if (tooltip) {
        tooltip.hide();
        button.removeAttribute("data-bs-title");
        button.removeAttribute("data-bs-toggle");
        button.removeAttribute("data-bs-placement");
      }
      button.setAttribute("title", currentTitle);
      button.classList.remove('code-copy-button-checked');
    }, 1000);
    // clear code selection
    e.clearSelection();
  });
  function tippyHover(el, contentFn) {
    const config = {
      allowHTML: true,
      content: contentFn,
      maxWidth: 500,
      delay: 100,
      arrow: false,
      appendTo: function(el) {
          return el.parentElement;
      },
      interactive: true,
      interactiveBorder: 10,
      theme: 'quarto',
      placement: 'bottom-start'
    };
    window.tippy(el, config); 
  }
  const noterefs = window.document.querySelectorAll('a[role="doc-noteref"]');
  for (var i=0; i<noterefs.length; i++) {
    const ref = noterefs[i];
    tippyHover(ref, function() {
      // use id or data attribute instead here
      let href = ref.getAttribute('data-footnote-href') || ref.getAttribute('href');
      try { href = new URL(href).hash; } catch {}
      const id = href.replace(/^#\/?/, "");
      const note = window.document.getElementById(id);
      return note.innerHTML;
    });
  }
      let selectedAnnoteEl;
      const selectorForAnnotation = ( cell, annotation) => {
        let cellAttr = 'data-code-cell="' + cell + '"';
        let lineAttr = 'data-code-annotation="' +  annotation + '"';
        const selector = 'span[' + cellAttr + '][' + lineAttr + ']';
        return selector;
      }
      const selectCodeLines = (annoteEl) => {
        const doc = window.document;
        const targetCell = annoteEl.getAttribute("data-target-cell");
        const targetAnnotation = annoteEl.getAttribute("data-target-annotation");
        const annoteSpan = window.document.querySelector(selectorForAnnotation(targetCell, targetAnnotation));
        const lines = annoteSpan.getAttribute("data-code-lines").split(",");
        const lineIds = lines.map((line) => {
          return targetCell + "-" + line;
        })
        let top = null;
        let height = null;
        let parent = null;
        if (lineIds.length > 0) {
            //compute the position of the single el (top and bottom and make a div)
            const el = window.document.getElementById(lineIds[0]);
            top = el.offsetTop;
            height = el.offsetHeight;
            parent = el.parentElement.parentElement;
          if (lineIds.length > 1) {
            const lastEl = window.document.getElementById(lineIds[lineIds.length - 1]);
            const bottom = lastEl.offsetTop + lastEl.offsetHeight;
            height = bottom - top;
          }
          if (top !== null && height !== null && parent !== null) {
            // cook up a div (if necessary) and position it 
            let div = window.document.getElementById("code-annotation-line-highlight");
            if (div === null) {
              div = window.document.createElement("div");
              div.setAttribute("id", "code-annotation-line-highlight");
              div.style.position = 'absolute';
              parent.appendChild(div);
            }
            div.style.top = top - 2 + "px";
            div.style.height = height + 4 + "px";
            let gutterDiv = window.document.getElementById("code-annotation-line-highlight-gutter");
            if (gutterDiv === null) {
              gutterDiv = window.document.createElement("div");
              gutterDiv.setAttribute("id", "code-annotation-line-highlight-gutter");
              gutterDiv.style.position = 'absolute';
              const codeCell = window.document.getElementById(targetCell);
              const gutter = codeCell.querySelector('.code-annotation-gutter');
              gutter.appendChild(gutterDiv);
            }
            gutterDiv.style.top = top - 2 + "px";
            gutterDiv.style.height = height + 4 + "px";
          }
          selectedAnnoteEl = annoteEl;
        }
      };
      const unselectCodeLines = () => {
        const elementsIds = ["code-annotation-line-highlight", "code-annotation-line-highlight-gutter"];
        elementsIds.forEach((elId) => {
          const div = window.document.getElementById(elId);
          if (div) {
            div.remove();
          }
        });
        selectedAnnoteEl = undefined;
      };
      // Attach click handler to the DT
      const annoteDls = window.document.querySelectorAll('dt[data-target-cell]');
      for (const annoteDlNode of annoteDls) {
        annoteDlNode.addEventListener('click', (event) => {
          const clickedEl = event.target;
          if (clickedEl !== selectedAnnoteEl) {
            unselectCodeLines();
            const activeEl = window.document.querySelector('dt[data-target-cell].code-annotation-active');
            if (activeEl) {
              activeEl.classList.remove('code-annotation-active');
            }
            selectCodeLines(clickedEl);
            clickedEl.classList.add('code-annotation-active');
          } else {
            // Unselect the line
            unselectCodeLines();
            clickedEl.classList.remove('code-annotation-active');
          }
        });
      }
  const findCites = (el) => {
    const parentEl = el.parentElement;
    if (parentEl) {
      const cites = parentEl.dataset.cites;
      if (cites) {
        return {
          el,
          cites: cites.split(' ')
        };
      } else {
        return findCites(el.parentElement)
      }
    } else {
      return undefined;
    }
  };
  var bibliorefs = window.document.querySelectorAll('a[role="doc-biblioref"]');
  for (var i=0; i<bibliorefs.length; i++) {
    const ref = bibliorefs[i];
    const citeInfo = findCites(ref);
    if (citeInfo) {
      tippyHover(citeInfo.el, function() {
        var popup = window.document.createElement('div');
        citeInfo.cites.forEach(function(cite) {
          var citeDiv = window.document.createElement('div');
          citeDiv.classList.add('hanging-indent');
          citeDiv.classList.add('csl-entry');
          var biblioDiv = window.document.getElementById('ref-' + cite);
          if (biblioDiv) {
            citeDiv.innerHTML = biblioDiv.innerHTML;
          }
          popup.appendChild(citeDiv);
        });
        return popup.innerHTML;
      });
    }
  }
});
</script>
</div> <!-- /content -->



</body></html>