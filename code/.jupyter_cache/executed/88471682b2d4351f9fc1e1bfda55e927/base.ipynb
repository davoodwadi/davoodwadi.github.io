{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "91f29089",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# imports\n",
    "import os\n",
    "import sys\n",
    "import types\n",
    "import json\n",
    "\n",
    "# figure size/format\n",
    "fig_width = 7\n",
    "fig_height = 5\n",
    "fig_format = 'retina'\n",
    "fig_dpi = 96\n",
    "\n",
    "# matplotlib defaults / format\n",
    "try:\n",
    "  import matplotlib.pyplot as plt\n",
    "  plt.rcParams['figure.figsize'] = (fig_width, fig_height)\n",
    "  plt.rcParams['figure.dpi'] = fig_dpi\n",
    "  plt.rcParams['savefig.dpi'] = fig_dpi\n",
    "  from IPython.display import set_matplotlib_formats\n",
    "  set_matplotlib_formats(fig_format)\n",
    "except Exception:\n",
    "  pass\n",
    "\n",
    "# plotly use connected mode\n",
    "try:\n",
    "  import plotly.io as pio\n",
    "  pio.renderers.default = \"notebook_connected\"\n",
    "except Exception:\n",
    "  pass\n",
    "\n",
    "# enable pandas latex repr when targeting pdfs\n",
    "try:\n",
    "  import pandas as pd\n",
    "  if fig_format == 'pdf':\n",
    "    pd.set_option('display.latex.repr', True)\n",
    "except Exception:\n",
    "  pass\n",
    "\n",
    "\n",
    "\n",
    "# output kernel dependencies\n",
    "kernel_deps = dict()\n",
    "for module in list(sys.modules.values()):\n",
    "  # Some modules play games with sys.modules (e.g. email/__init__.py\n",
    "  # in the standard library), and occasionally this can cause strange\n",
    "  # failures in getattr.  Just ignore anything that's not an ordinary\n",
    "  # module.\n",
    "  if not isinstance(module, types.ModuleType):\n",
    "    continue\n",
    "  path = getattr(module, \"__file__\", None)\n",
    "  if not path:\n",
    "    continue\n",
    "  if path.endswith(\".pyc\") or path.endswith(\".pyo\"):\n",
    "    path = path[:-1]\n",
    "  if not os.path.exists(path):\n",
    "    continue\n",
    "  kernel_deps[path] = os.stat(path).st_mtime\n",
    "print(json.dumps(kernel_deps))\n",
    "\n",
    "# set run_path if requested\n",
    "if r'/Users/davoodwadi/MLCourse/davoodwadi.github.io/code':\n",
    "  os.chdir(r'/Users/davoodwadi/MLCourse/davoodwadi.github.io/code')\n",
    "\n",
    "# reset state\n",
    "%reset\n",
    "\n",
    "def ojs_define(**kwargs):\n",
    "  import json\n",
    "  try:\n",
    "    # IPython 7.14 preferred import\n",
    "    from IPython.display import display, HTML\n",
    "  except:\n",
    "    from IPython.core.display import display, HTML\n",
    "\n",
    "  # do some minor magic for convenience when handling pandas\n",
    "  # dataframes\n",
    "  def convert(v):\n",
    "    try:\n",
    "      import pandas as pd\n",
    "    except ModuleNotFoundError: # don't do the magic when pandas is not available\n",
    "      return v\n",
    "    if type(v) == pd.Series:\n",
    "      v = pd.DataFrame(v)\n",
    "    if type(v) == pd.DataFrame:\n",
    "      j = json.loads(v.T.to_json(orient='split'))\n",
    "      return dict((k,v) for (k,v) in zip(j[\"index\"], j[\"data\"]))\n",
    "    else:\n",
    "      return v\n",
    "  \n",
    "  v = dict(contents=list(dict(name=key, value=convert(value)) for (key, value) in kwargs.items()))\n",
    "  display(HTML('<script type=\"ojs-define\">' + json.dumps(v) + '</script>'), metadata=dict(ojs_define = True))\n",
    "globals()[\"ojs_define\"] = ojs_define\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "dd797fcb",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import DataLoader\n",
    "import numpy as np\n",
    "import random\n",
    "\n",
    "# Set the random seed for reproducibility\n",
    "random.seed(42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "48468d92",
   "metadata": {},
   "outputs": [],
   "source": [
    "path = '../wikitext-2/'\n",
    "train_path = path + 'wiki.train.tokens'\n",
    "valid_path = path + 'wiki.valid.tokens'\n",
    "test_path = path + 'wiki.test.tokens'\n",
    "\n",
    "def read_file(path):\n",
    "    # Open the file in read mode\n",
    "    with open(file_path, 'r') as file:\n",
    "        # Read the contents of the file\n",
    "        file_contents = file.read()\n",
    "    return file_contents\n",
    "\n",
    "train_string = read_file(train_path)\n",
    "valid_string = read_file(valid_path)\n",
    "test_string = read_file(test_path)\n",
    "print(train_string[:100])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "28613d64",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_list = train_string.split(\"\\n\")\n",
    "valid_list = valid_string.split(\"\\n\")\n",
    "test_list = test_string.split(\"\\n\")\n",
    "train_list[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "aae3aec4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import spacy\n",
    "\n",
    "nlp = spacy.load(\"en_core_web_sm\")\n",
    "doc = nlp('''\"Let's go to N.Y.!\"''')\n",
    "\n",
    "for token in doc:\n",
    "    print(token.text)\n",
    "\n",
    "nlp.vocab.strings['Let']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "c1edb1e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "class RNNLanguageModel(nn.Module):\n",
    "    def __init__(self, vocab_size, embedding_dim, hidden_dim, num_layers):\n",
    "        super(RNNLanguageModel, self).__init__()\n",
    "        self.embedding = nn.Embedding(vocab_size, embedding_dim)\n",
    "        self.lstm = nn.LSTM(embedding_dim, hidden_dim, num_layers, batch_first=True)\n",
    "        self.fc = nn.Linear(hidden_dim, vocab_size)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        embedded = self.embedding(x)\n",
    "        output, _ = self.lstm(embedded)\n",
    "        output = self.fc(output.reshape(-1, output.size(2)))\n",
    "        return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "bdf1a30b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_model(model, train_iter, val_iter, num_epochs, lr):\n",
    "    optimizer = optim.Adam(model.parameters(), lr=lr)\n",
    "    criterion = nn.CrossEntropyLoss()\n",
    "    \n",
    "    best_val_loss = float('inf')\n",
    "    \n",
    "    for epoch in range(num_epochs):\n",
    "        model.train()\n",
    "        train_loss = 0\n",
    "        \n",
    "        for batch in train_iter:\n",
    "            optimizer.zero_grad()\n",
    "            \n",
    "            x = batch.text[:, :-1]\n",
    "            y = batch.text[:, 1:].flatten()\n",
    "            \n",
    "            output = model(x)\n",
    "            loss = criterion(output, y)\n",
    "            \n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            \n",
    "            train_loss += loss.item()\n",
    "        \n",
    "        train_loss /= len(train_iter)\n",
    "        \n",
    "        model.eval()\n",
    "        val_loss = 0\n",
    "        \n",
    "        with torch.no_grad():\n",
    "            for batch in val_iter:\n",
    "                x = batch.text[:, :-1]\n",
    "                y = batch.text[:, 1:].flatten()\n",
    "                \n",
    "                output = model(x)\n",
    "                loss = criterion(output, y)\n",
    "                \n",
    "                val_loss += loss.item()\n",
    "        \n",
    "        val_loss /= len(val_iter)\n",
    "        \n",
    "        if val_loss < best_val_loss:\n",
    "            best_val_loss = val_loss\n",
    "            torch.save(model.state_dict(), 'language_model.pt')\n",
    "        \n",
    "        print(f'Epoch: {epoch+1}/{num_epochs}, Train Loss: {train_loss:.4f}, Val Loss: {val_loss:.4f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "30a4168c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_text(model, seed_text, max_length):\n",
    "    model.eval()\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        tokens = seed_text.split()\n",
    "        current_length = len(tokens)\n",
    "        \n",
    "        while current_length < max_length:\n",
    "            x = torch.tensor([[TEXT.vocab.stoi[token] for token in tokens]]).to(device)\n",
    "            \n",
    "            output = model(x)\n",
    "            last_word_logits = output[0, -1]\n",
    "            \n",
    "            probabilities = F.softmax(last_word_logits, dim=0).numpy()\n",
    "            predicted_index = np.random.choice(len(probabilities), p=probabilities)\n",
    "            predicted_word = TEXT.vocab.itos[predicted_index]\n",
    "            \n",
    "            tokens.append(predicted_word)\n",
    "            current_length += 1\n",
    "            \n",
    "    generated_text = ' '.join(tokens)\n",
    "    return generated_text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "35eecbd9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set the device\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "# Preprocess the dataset\n",
    "train_iter, val_iter, test_iter = preprocess_dataset()\n",
    "\n",
    "# Define the model\n",
    "vocab_size = len(train_iter.dataset.fields['text'].vocab)\n",
    "embedding_dim = 100\n",
    "hidden_dim = 128\n",
    "num_layers = 2\n",
    "model = RNNLanguageModel(vocab_size, embedding_dim, hidden_dim, num_layers).to(device)\n",
    "\n",
    "# Train the model\n",
    "num_epochs = 10\n",
    "learning_rate = 0.001\n",
    "train_model(model, train_iter, val_iter, num_epochs, learning_rate)\n",
    "\n",
    "# Generate text using the trained model\n",
    "seed_text = \"The weather is\"\n",
    "max_length = 20\n",
    "generated_text = generate_text(model, seed_text, max_length)\n",
    "print(generated_text)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}