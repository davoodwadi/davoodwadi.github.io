{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "86a0ac5e-09c5-4551-8adc-a19a04daf7d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import DataLoader\n",
    "import numpy as np\n",
    "import random"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ce7eff43-622a-464f-981c-2224318332f1",
   "metadata": {},
   "source": [
    "# Load Wiki-Text-2 data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "338ff26a-16b7-4a11-9c9b-98ea193dddcd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " \n",
      " = Valkyria Chronicles III = \n",
      " \n",
      " Senjō no Valkyria 3 : <unk> Chronicles ( Japanese : 戦場のヴァルキュリア3 ,\n"
     ]
    }
   ],
   "source": [
    "path = '../wikitext-2/'\n",
    "train_path = path + 'wiki.train.tokens'\n",
    "valid_path = path + 'wiki.valid.tokens'\n",
    "test_path = path + 'wiki.test.tokens'\n",
    "\n",
    "def read_file(file_path):\n",
    "    # Open the file in read mode\n",
    "    with open(file_path, 'r') as file:\n",
    "        # Read the contents of the file\n",
    "        file_contents = file.read()\n",
    "    return file_contents\n",
    "\n",
    "train_string = read_file(train_path)\n",
    "valid_string = read_file(valid_path)\n",
    "test_string = read_file(test_path)\n",
    "print(train_string[:100])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "58f0dc93-a4c7-402a-bbfa-cdd8d24358d2",
   "metadata": {},
   "source": [
    "# Tokenization\n",
    "The preprocessing step that \n",
    "\n",
    "1. splits a corpus into words or characters (tokens),\n",
    "2. keeps the track of the words in a vocabulary, and\n",
    "3. maps each unique token into a unique integer"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ca12ccb2-a0fb-4cfd-9100-11a2bc8a25f5",
   "metadata": {},
   "source": [
    "## You can make your own tokenizer following these steps\n",
    "1. Go through all the words in your corpus and keep unique words in a dictionary\n",
    "2. Assign a unique integer to each unique word.\n",
    "3. Convert your corpus of text to integers representing each word"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "faf4b726-aa8a-402f-af1b-d8a87c77eeee",
   "metadata": {},
   "source": [
    "**Or you can use a python library (e.g. nltk, Scikit Learn, HF Tokenizer) to do this step for you.**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4f2c05e3-421c-4f4f-9c1f-00e320832ce4",
   "metadata": {},
   "source": [
    "## Advantages of using HF Tokenizer:\n",
    "1. It removes the boilerplate tokenization code.\n",
    "2. It is written in Rust, so it is faster than python."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2212380b-d71f-4893-8366-5b8f65c8d9eb",
   "metadata": {},
   "source": [
    "We will use the BPE (Byte-Pair Encoding) algorithm to tokenize our corpus"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "f532ea01-3cd4-4084-9b77-e39d527427f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tokenizers import Tokenizer\n",
    "from tokenizers.models import BPE, \n",
    "from tokenizers.trainers import BpeTrainer\n",
    "from tokenizers.pre_tokenizers import Whitespace"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "0fd83a52-1142-4410-b8fb-e2a1a737086b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "tokenizer = Tokenizer(BPE(unk_token=\"[UNK]\"))\n",
    "trainer = BpeTrainer(special_tokens=[\"[PAD]\",\"[UNK]\"], vocab_size=3000)\n",
    "\n",
    "tokenizer.pre_tokenizer = Whitespace()\n",
    "files = [train_path]\n",
    "tokenizer.train(files, trainer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "28ec0143-7fe0-452a-a6a0-339bfb925e28",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3000"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vocab = tokenizer.get_vocab()\n",
    "\n",
    "len(vocab)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "d9af1c98-1b9e-4311-9bd2-62973041664e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['A', 'single', 'sequ', 'ence']"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer.encode('A single sequence').tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "55427795-3999-4d9e-af0c-0bfe25181389",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['an',\n",
       " ',',\n",
       " 'is',\n",
       " 'a',\n",
       " 't',\n",
       " 'act',\n",
       " 'ical',\n",
       " 'role',\n",
       " '@-@',\n",
       " 'playing',\n",
       " 'video',\n",
       " 'game',\n",
       " 'de',\n",
       " 'v']"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer.encode(train_string[200:250]).tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "075a79a1-2200-4c3c-b227-240a763a592b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[41, 38, 36, 302]"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokens = tokenizer.encode('  HEC  is  ').ids\n",
    "tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "6750988c-9029-4f3c-a63b-f34015a84789",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['H', 'E', 'C', 'is']"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[tokenizer.decode([token]) for token in tokens]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "778593e1-559c-41fb-a5b7-deb56a1e338a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vocab['[PAD]']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "094ac171-ade8-4790-acf2-b614718c4c4a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vocab['[UNK]']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "ec60a1c7-b3b5-4f37-98a7-4b251f7f3e1a",
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer.save(path+'tokenizer.json')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "00b8da34-7909-4915-a4d1-34782e722224",
   "metadata": {},
   "source": [
    "# Load our pre-trained tokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "id": "b02e5ef9-1f9a-4153-a018-3f9579512eac",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import PreTrainedTokenizerFast\n",
    "\n",
    "tokenizer = PreTrainedTokenizerFast(tokenizer_file=path+\"tokenizer.json\", \n",
    "                                    bos_token='[BOS]', eos_token='[EOS]', \n",
    "                                    unk_token='[UNK]', pad_token='[PAD]')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "id": "7477a0bf-76e8-4fa6-88a7-e5b861241dd8",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using sep_token, but it is not set yet.\n",
      "Using cls_token, but it is not set yet.\n",
      "Using mask_token, but it is not set yet.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "PreTrainedTokenizerFast(name_or_path='', vocab_size=3000, model_max_length=1000000000000000019884624838656, is_fast=True, padding_side='right', truncation_side='right', special_tokens={'bos_token': '[BOS]', 'eos_token': '[EOS]', 'unk_token': '[UNK]', 'pad_token': '[PAD]'}, clean_up_tokenization_spaces=True),  added_tokens_decoder={\n",
       "\t0: AddedToken(\"[PAD]\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
       "\t1: AddedToken(\"[UNK]\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
       "\t3000: AddedToken(\"[BOS]\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
       "\t3001: AddedToken(\"[EOS]\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
       "}"
      ]
     },
     "execution_count": 88,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "id": "f75f7478-4dde-46da-bc98-3b41d1642d2d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[41, 38, 36, 302]"
      ]
     },
     "execution_count": 89,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokens = tokenizer.encode('  HEC  is  ')\n",
    "tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "id": "f269469e-2017-41f2-990d-59b10be41c52",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[41, 38, 36, 302, 65, 291, 1410, 15]"
      ]
     },
     "execution_count": 90,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokens = tokenizer.encode('HEC  is a university.')\n",
    "tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "id": "ed157b8a-e187-4965-a040-51c6e62c3428",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 91,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer.vocab['[PAD]']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "id": "89d72502-b0c5-4e32-9b7b-b27414b9afdc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3002"
      ]
     },
     "execution_count": 92,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(tokenizer.vocab)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "id": "40c24411-3658-4e26-96c3-0428e71cc0e3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0, 3000]"
      ]
     },
     "execution_count": 93,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer.convert_tokens_to_ids(['[PAD]','[BOS]'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "id": "96b3ad98-e3a0-4f58-9e6a-feb5f75249fe",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[3000, 0, 3001]"
      ]
     },
     "execution_count": 94,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer.convert_tokens_to_ids(['[BOS]','[PAD]','[EOS]'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "31883e92-637e-4be1-bd3c-6255aeaaff41",
   "metadata": {},
   "source": [
    "## Tokenize the training set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "id": "991a180d-38f0-4132-9863-89d5326c0f99",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_tokens = tokenizer(train_string)['input_ids']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "id": "1452eb3f-f862-4c39-90cb-d6ec180c9bdf",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3115026"
      ]
     },
     "execution_count": 101,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(train_tokens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "id": "11c39e4d-760e-4859-9649-210a8d796325",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[30, 2275, 2641, 353, 65, 453, 2685, 662, 2330, 30]"
      ]
     },
     "execution_count": 108,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_tokens[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "id": "50f8f887-e38a-4d3f-a551-b2f009be9cdd",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import Dataset, DataLoader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "id": "c9e6875f-6584-4641-a9a7-4af5ea7e873f",
   "metadata": {},
   "outputs": [],
   "source": [
    "class LanguageData(Dataset):\n",
    "    def __init__(self,token_list, seq_len):\n",
    "        self.token_list = token_list\n",
    "        self.seq_len = seq_len\n",
    "    def __getitem__(self, ind):\n",
    "        inp = torch.tensor(self.token_list[ind:ind+self.seq_len])\n",
    "        out = torch.tensor(self.token_list[ind+1:ind+self.seq_len+1])\n",
    "        return inp, out\n",
    "        \n",
    "    def __len__(self):\n",
    "        return len(self.token_list) - self.seq_len"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "id": "8d4e0246-4f14-4383-be9f-ec540cbb3a85",
   "metadata": {},
   "outputs": [],
   "source": [
    "seq_len = 5\n",
    "\n",
    "train_set = LanguageData(train_tokens, seq_len)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "id": "cc40751c-1481-4a77-b7e5-b8b106525e2d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3115021"
      ]
     },
     "execution_count": 145,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(train_set)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "id": "cdbef8ac-c4ab-43e7-8f9a-3ef3d9a398f7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([  15,   38,  475, 1078,  489]),\n",
       " tensor([  38,  475, 1078,  489, 2515]))"
      ]
     },
     "execution_count": 146,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_set[1000]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "id": "e0e7b4cf-3144-4288-ae61-256dc55aa295",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['. E ach character has', 'E ach character has specific']"
      ]
     },
     "execution_count": 147,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer.batch_decode(train_set[1000])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "64acaf0f-97a1-496d-85b3-09f1cbca8617",
   "metadata": {},
   "source": [
    "## Make a batch of data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "id": "c0320e42-b53d-4926-ac11-c9795d86bcf7",
   "metadata": {},
   "outputs": [],
   "source": [
    "bs = 8\n",
    "train_loader = DataLoader(train_set, batch_size=bs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "id": "e06dd34f-159c-43c8-ba73-2682bbdf52f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "bx, by = next(iter(train_loader))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "id": "bb14ac0b-98b4-4b2b-bf75-71e3c9a9fdc3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[  30, 2275, 2641,  353,   65],\n",
       "        [2275, 2641,  353,   65,  453],\n",
       "        [2641,  353,   65,  453, 2685],\n",
       "        [ 353,   65,  453, 2685,  662],\n",
       "        [  65,  453, 2685,  662, 2330],\n",
       "        [ 453, 2685,  662, 2330,   30],\n",
       "        [2685,  662, 2330,   30,   52],\n",
       "        [ 662, 2330,   30,   52, 2736]])"
      ]
     },
     "execution_count": 154,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "id": "675ef05c-b448-453f-96a2-b8f2181cdeca",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[2275, 2641,  353,   65,  453],\n",
       "        [2641,  353,   65,  453, 2685],\n",
       "        [ 353,   65,  453, 2685,  662],\n",
       "        [  65,  453, 2685,  662, 2330],\n",
       "        [ 453, 2685,  662, 2330,   30],\n",
       "        [2685,  662, 2330,   30,   52],\n",
       "        [ 662, 2330,   30,   52, 2736],\n",
       "        [2330,   30,   52, 2736,  152]])"
      ]
     },
     "execution_count": 155,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "by"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "id": "5945fc2d-9dab-4c20-8c68-7eca832911d2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['= Val ky ri a',\n",
       " 'Val ky ri a Ch',\n",
       " 'ky ri a Ch ronic',\n",
       " 'ri a Ch ronic les',\n",
       " 'a Ch ronic les III',\n",
       " 'Ch ronic les III =',\n",
       " 'ronic les III = S',\n",
       " 'les III = S enj']"
      ]
     },
     "execution_count": 156,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer.batch_decode(bx)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "id": "0b71e1ef-2234-4eb3-b6d9-b29302235a7e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Val ky ri a Ch',\n",
       " 'ky ri a Ch ronic',\n",
       " 'ri a Ch ronic les',\n",
       " 'a Ch ronic les III',\n",
       " 'Ch ronic les III =',\n",
       " 'ronic les III = S',\n",
       " 'les III = S enj',\n",
       " 'III = S enj ō']"
      ]
     },
     "execution_count": 157,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer.batch_decode(by)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e79a4e8f-0a85-4805-9359-a7db9c99ccbd",
   "metadata": {},
   "source": [
    "## Put it all together"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "63916927-6905-4eac-a48b-2cb2637635f4",
   "metadata": {},
   "source": [
    "Subset the training set to faster computation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 252,
   "id": "ca31238e-633b-4df0-90f0-7b92437cadb2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(10780437, 1120192)"
      ]
     },
     "execution_count": 252,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(train_string), len(valid_string)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 253,
   "id": "0ae606a1-bb89-4a4a-8423-a44f97b56cf8",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_tokens = tokenizer(train_string[:500_000])['input_ids']\n",
    "valid_tokens = tokenizer(valid_string)['input_ids']\n",
    "test_tokens = tokenizer(test_string)['input_ids']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 254,
   "id": "f49fdddf-1a58-480a-b470-5d8d97f4b7c1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train set has 144558 sequences\n",
      "Valid set has 323006 sequences\n",
      "Test set has 366126 sequences\n"
     ]
    }
   ],
   "source": [
    "seq_len = 8\n",
    "bs = 64\n",
    "\n",
    "train_set = LanguageData(train_tokens, seq_len)\n",
    "valid_set = LanguageData(valid_tokens, seq_len)\n",
    "test_set = LanguageData(test_tokens, seq_len)\n",
    "\n",
    "print(f'Train set has {len(train_set)} sequences')\n",
    "print(f'Valid set has {len(valid_set)} sequences')\n",
    "print(f'Test set has {len(test_set)} sequences')\n",
    "\n",
    "train_loader = DataLoader(train_set, batch_size=bs, drop_last=True)\n",
    "valid_loader = DataLoader(valid_set, batch_size=bs, drop_last=True)\n",
    "test_loader = DataLoader(test_set, batch_size=bs, drop_last=True)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7929a855-472b-45dd-b7be-028f0de21b33",
   "metadata": {},
   "source": [
    "# Embedding layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 242,
   "id": "8c34d11a-2e1b-4a5d-acba-9dcd51ee43ab",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 242,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vocab_size = len(tokenizer)\n",
    "embedding_dim = 10\n",
    "padding_idx = tokenizer.pad_token_id\n",
    "padding_idx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 174,
   "id": "5bbfbade-8fe8-4abe-9f74-63af902596a4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Embedding(3002, 10, padding_idx=0)"
      ]
     },
     "execution_count": 174,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "embed = nn.Embedding(num_embeddings=vocab_size, embedding_dim=embedding_dim, padding_idx=padding_idx)\n",
    "embed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 175,
   "id": "78cff1f9-2933-4401-a837-c41414deab8e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[72, 73]"
      ]
     },
     "execution_count": 175,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "hi = tokenizer('hi')['input_ids']\n",
    "hi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 176,
   "id": "0cc2a79d-73b3-4cf6-bd35-6093c54b2dd4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 0.4664, -0.9007,  1.2894,  0.7496,  0.2736,  0.2147,  0.2893, -0.1120,\n",
       "         -1.5148, -0.5786],\n",
       "        [-1.2685,  0.5601, -0.0723, -0.0527, -0.6910, -1.8882, -0.2942,  0.1605,\n",
       "          0.9129, -1.7694]], grad_fn=<EmbeddingBackward0>)"
      ]
     },
     "execution_count": 176,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "embed(torch.tensor(hi))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 177,
   "id": "c8fede02-1830-4a5f-960d-3dc7782c92fe",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([2, 10])"
      ]
     },
     "execution_count": 177,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "embed(torch.tensor(hi)).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 180,
   "id": "3845d30b-0bdc-4e2d-8493-3edbb8948926",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([64, 100])"
      ]
     },
     "execution_count": 180,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bx, by = next(iter(train_loader))\n",
    "bx.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 181,
   "id": "0cb08477-ac47-4e39-8f14-9531db410dc5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([64, 100, 10])"
      ]
     },
     "execution_count": 181,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "embed(bx).shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "567a493b-c459-4b13-885b-18ec20585122",
   "metadata": {},
   "source": [
    "# Create an RNN to predict the next word"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 327,
   "id": "a600adfe-2f8d-4e39-9a3d-6206ed728568",
   "metadata": {},
   "outputs": [],
   "source": [
    "class RNN(nn.Module):\n",
    "    def __init__(self, vocab_size, embedding_dim, hidden_size, seq_len):\n",
    "        super(RNN, self).__init__()\n",
    "\n",
    "        self.vocab_size = vocab_size\n",
    "        self.embedding_dim = embedding_dim\n",
    "        self.hidden_size = hidden_size\n",
    "        self.seq_len = seq_len\n",
    "\n",
    "        self.embed = nn.Embedding(self.vocab_size, self.embedding_dim, 0)\n",
    "        self.rnn = nn.RNN(embedding_dim, hidden_size, batch_first=True) # [bs, seq_len, embedding_dim]\n",
    "        # self.project = nn.Linear(hidden_size*seq_len, seq_len*self.vocab_size)\n",
    "        self.project = nn.Linear(hidden_size, vocab_size)\n",
    "    def init_h(self, bs):\n",
    "        # input shape\n",
    "        bs, self.seq_len, self.embedding_dim\n",
    "        # (D * num_layers, bs, H_{out})\n",
    "        h = torch.zeros(1, bs, self.hidden_size, requires_grad=False)\n",
    "        return h\n",
    "    def forward(self, x, h):\n",
    "        x = self.embed(x)\n",
    "        x, h = self.rnn(x, h)\n",
    "        # x.shape -> bs, seq_len, hidden_size\n",
    "        # x = x.contiguous().view(-1, self.seq_len*self.hidden_size)\n",
    "        # x = self.project(x) # shape -> bs, seq_len*vocab_size\n",
    "        x = self.project(x) # shape -> bs, seq_len, vocab_size\n",
    "        x = x.contiguous().view(-1, self.vocab_size, self.seq_len) # multi-dim cross-entropy loss\n",
    "        return x, h"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 345,
   "id": "bb4a5300-b921-4826-b889-aede11a89381",
   "metadata": {},
   "outputs": [],
   "source": [
    "embedding_dim = 16\n",
    "hidden_size = 20\n",
    "model = RNN(vocab_size, embedding_dim, hidden_size, seq_len)\n",
    "ce = nn.CrossEntropyLoss()\n",
    "lr = 1e-3\n",
    "optimizer = torch.optim.SGD(model.parameters(), lr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 346,
   "id": "44ea6c0d-39f7-4751-bf70-9b2245ec3323",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "111834"
      ]
     },
     "execution_count": 346,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sum([p.numel() for p in model.parameters()])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "43369496-f531-4513-bda6-1e261015e9c1",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 347,
   "id": "36dc4271-ee56-4e2b-867e-02a32ecdec66",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8.052412684561405\n",
      "8.046844196699698\n",
      "8.041544349347731\n",
      "8.036416841250167\n",
      "8.031389635996653\n",
      "8.026406132087336\n",
      "8.021419736112083\n",
      "8.016390332930694\n",
      "8.011282468074397\n",
      "8.006063566680922\n"
     ]
    }
   ],
   "source": [
    "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "epochs = 10\n",
    "\n",
    "h = model.init_h(bs)\n",
    "for e in range(epochs):\n",
    "    losses=[]\n",
    "    model.train()\n",
    "    for bx, by in train_loader:\n",
    "        bx, by, model = bx.to(device), by.to(device), model.to(device)\n",
    "        out, h = model(bx, h)\n",
    "        loss = ce(out, by)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        optimizer.zero_grad()\n",
    "        h.detach_()\n",
    "        losses.append(loss.item())\n",
    "    print(np.mean(losses))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "76bb0776-fd51-4c8a-a53c-ef5af8576cba",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "9a74b4cf-41e3-4852-9eaf-d5589c640d49",
   "metadata": {},
   "source": [
    "# Transformer architecture"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 269,
   "id": "dcf0db71-eebc-4ea9-9f44-4f5fd57ec58c",
   "metadata": {},
   "outputs": [],
   "source": [
    "embedding_dim = 16"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 276,
   "id": "fadcf830-68ba-464f-8c47-9c1f936f87fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "transformer_layer = nn.TransformerEncoderLayer(embedding_dim, 8, 2048, batch_first=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 284,
   "id": "f4204768-418c-4a9a-b03a-eec137199b78",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TransformerEncoderLayer(\n",
       "  (self_attn): MultiheadAttention(\n",
       "    (out_proj): NonDynamicallyQuantizableLinear(in_features=16, out_features=16, bias=True)\n",
       "  )\n",
       "  (linear1): Linear(in_features=16, out_features=2048, bias=True)\n",
       "  (dropout): Dropout(p=0.1, inplace=False)\n",
       "  (linear2): Linear(in_features=2048, out_features=16, bias=True)\n",
       "  (norm1): LayerNorm((16,), eps=1e-05, elementwise_affine=True)\n",
       "  (norm2): LayerNorm((16,), eps=1e-05, elementwise_affine=True)\n",
       "  (dropout1): Dropout(p=0.1, inplace=False)\n",
       "  (dropout2): Dropout(p=0.1, inplace=False)\n",
       ")"
      ]
     },
     "execution_count": 284,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "transformer_layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 286,
   "id": "472b201e-edab-434c-be13-788990c8c812",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([2048, 16]), torch.Size([16, 2048]))"
      ]
     },
     "execution_count": 286,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "transformer_layer.linear1.weight.shape, transformer_layer.linear2.weight.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 277,
   "id": "44929b1b-32ea-4b2c-99ad-7f373bb77adf",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([64, 8]), 16, 8)"
      ]
     },
     "execution_count": 277,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bx.shape, embedding_dim, seq_len"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 278,
   "id": "264f6964-f222-413a-ad65-96efc971df46",
   "metadata": {},
   "outputs": [],
   "source": [
    "embedd = nn.Embedding(vocab_size, embedding_dim)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 279,
   "id": "e18e6a9d-dbbb-4b5e-8c66-1d6d2105b307",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([64, 8, 16])\n",
      "torch.Size([64, 8, 16])\n"
     ]
    }
   ],
   "source": [
    "out = embedd(bx)\n",
    "print(out.shape)\n",
    "out = transformer_layer(out)\n",
    "print(out.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 285,
   "id": "2c90e353-05d6-42e6-bb43-40a2d6a8f108",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TransformerEncoder(\n",
       "  (layers): ModuleList(\n",
       "    (0-5): 6 x TransformerEncoderLayer(\n",
       "      (self_attn): MultiheadAttention(\n",
       "        (out_proj): NonDynamicallyQuantizableLinear(in_features=16, out_features=16, bias=True)\n",
       "      )\n",
       "      (linear1): Linear(in_features=16, out_features=2048, bias=True)\n",
       "      (dropout): Dropout(p=0.1, inplace=False)\n",
       "      (linear2): Linear(in_features=2048, out_features=16, bias=True)\n",
       "      (norm1): LayerNorm((16,), eps=1e-05, elementwise_affine=True)\n",
       "      (norm2): LayerNorm((16,), eps=1e-05, elementwise_affine=True)\n",
       "      (dropout1): Dropout(p=0.1, inplace=False)\n",
       "      (dropout2): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 285,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "num_layers = 6\n",
    "encoder = nn.TransformerEncoder(transformer_layer, num_layers)\n",
    "encoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 281,
   "id": "ba3c00d7-9a75-420b-96f7-a1719d3129cb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([64, 8, 16])\n",
      "torch.Size([64, 8, 16])\n"
     ]
    }
   ],
   "source": [
    "out = embedd(bx)\n",
    "print(out.shape)\n",
    "out = encoder(out)\n",
    "print(out.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 338,
   "id": "cff97193-d204-440a-8c4a-b3e328782ec4",
   "metadata": {},
   "outputs": [],
   "source": [
    "class TransformerEncoder(nn.Module):\n",
    "    def __init__(self, vocab_size, seq_len, embedding_dim, n_layers, n_heads, dim_feedforward):\n",
    "        super(TransformerEncoder, self).__init__()\n",
    "\n",
    "        self.vocab_size = vocab_size\n",
    "        self.embedding_dim = embedding_dim\n",
    "        self.seq_len = seq_len\n",
    "        self.n_layers = n_layers\n",
    "        \n",
    "        self.relu = nn.ReLU()\n",
    "        self.embed = nn.Embedding(vocab_size, embedding_dim)\n",
    "        self.transformer_layers = nn.ModuleList([nn.TransformerEncoderLayer(self.embedding_dim, n_heads, dim_feedforward, batch_first=True) for _ in range(n_layers)])\n",
    "        self.fc = nn.Linear(self.embedding_dim, self.vocab_size)\n",
    "    def forward(self, x):\n",
    "        x = self.embed(x)\n",
    "        for layer in self.transformer_layers:\n",
    "            x = self.relu(layer(x))\n",
    "        # x = x.contiguous().view(-1, self.seq_len*self.embedding_dim)\n",
    "        x = self.fc(x)\n",
    "        return x.contiguous().view(-1, self.vocab_size, self.seq_len)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 339,
   "id": "6e539d5f-721b-416f-a72f-53fcc57240e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "embedding_dim = 16\n",
    "model = TransformerEncoder(vocab_size, seq_len, embedding_dim, 6, 8, hidden_size)\n",
    "lr = 1e-3\n",
    "optimizer = torch.optim.SGD(model.parameters(), lr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 340,
   "id": "59e53bd7-173f-4c76-b166-c62c8772161e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8.124975384812739\n",
      "8.093722384413118\n",
      "8.046181983500059\n",
      "8.01690059979475\n",
      "8.004818373807666\n",
      "7.998558104618975\n",
      "7.9944436172133955\n",
      "7.990597010292344\n",
      "7.986975481491156\n",
      "7.983121994430772\n"
     ]
    }
   ],
   "source": [
    "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "epochs = 10\n",
    "\n",
    "for e in range(epochs):\n",
    "    losses=[]\n",
    "    model.train()\n",
    "    for bx, by in train_loader:\n",
    "        bx, by, model = bx.to(device), by.to(device), model.to(device)\n",
    "        out = model(bx)\n",
    "        loss = ce(out, by)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        optimizer.zero_grad()\n",
    "        losses.append(loss.item())\n",
    "    print(np.mean(losses))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 341,
   "id": "3e6f3d27-328b-4cf6-a881-d2e45348792a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "110034"
      ]
     },
     "execution_count": 341,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sum([p.numel() for p in model.parameters()])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0922e903-e757-4a53-9bf0-250aa2971d11",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
