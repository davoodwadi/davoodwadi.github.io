{
  "hash": "10ccdc58b98ad1052d5f6bf7c9a2066e",
  "result": {
    "engine": "jupyter",
    "markdown": "---\ntitle: \"Model capacity\"\nformat:\n  html:\n    code-fold: false\njupyter: python3\nexecute: \n  cache: true\n---\n\n\n\n\nModel capacity refers to the ability of a machine learning model to capture and represent complex relationships between the input variables (features) and the target variable (labels). It determines the complexity and flexibility of the model in fitting the training data.\n\nIn other words, model capacity represents the amount of information or patterns that a model can learn from the data. A model with a high capacity can learn intricate relationships in the training data, which may result in overfitting. On the other hand, a model with low capacity may not be able to capture the underlying patterns in the data, leading to underfitting.\n\nThe capacity of a model can be controlled by adjusting its architectural complexity. For example, in neural networks, increasing the number of hidden layers and hidden units increases the capacity of the model.\n\nMathematically, we can define model capacity as the number of parameters that the model has to learn. For example, in linear regression, the model capacity is determined by the number of coefficients (slope and intercept) that the model needs to estimate. In neural networks, the model capacity is determined by the number of weights and biases associated with each neuron.\n\nNow, let's understand the concept of model capacity using a simple example with polynomial regression. Polynomial regression is a form of linear regression where the relationship between the input feature (x) and the target variable (y) is modeled as an nth-degree polynomial.\n\nFirst, let's generate some synthetic data that follows a quadratic relationship between x and y:\n\n::: {#f89b8c81 .cell execution_count=1}\n``` {.python .cell-code}\nimport numpy as np\nimport matplotlib.pyplot as plt\n\n# Generate synthetic data\nnp.random.seed(42)\nx = np.linspace(-5, 5, 100)\ny = 2 * x ** 2 + np.random.normal(0, 4, 100)\n\n# Plot the data\nplt.scatter(x, y)\nplt.xlabel('x')\nplt.ylabel('y')\nplt.title('Quadratic Relationship')\nplt.show()\n```\n\n::: {.cell-output .cell-output-display}\n![](Model_files/figure-html/cell-2-output-1.png){width=585 height=449}\n:::\n:::\n\n\nBy visualizing the data, we can observe that the relationship between x and y follows a quadratic curve. Now, let's try fitting this data using different polynomial regression models with different degrees of complexity.\n\n::: {#acdb2b37 .cell execution_count=2}\n``` {.python .cell-code}\nfrom sklearn.linear_model import LinearRegression\nfrom sklearn.preprocessing import PolynomialFeatures\nfrom sklearn.pipeline import make_pipeline\n\n# Fit linear regression model\nlinear_model = make_pipeline(PolynomialFeatures(degree=1), LinearRegression())\nlinear_model.fit(x.reshape(-1, 1), y)\n\n# Fit quadratic regression model\nquadratic_model = make_pipeline(PolynomialFeatures(degree=2), LinearRegression())\nquadratic_model.fit(x.reshape(-1, 1), y)\n\n# Fit cubic regression model\ncubic_model = make_pipeline(PolynomialFeatures(degree=3), LinearRegression())\ncubic_model.fit(x.reshape(-1, 1), y)\n\n# Predict on new data points\nx_test = np.linspace(-5, 5, 100)\ny_linear = linear_model.predict(x_test.reshape(-1, 1))\ny_quadratic = quadratic_model.predict(x_test.reshape(-1, 1))\ny_cubic = cubic_model.predict(x_test.reshape(-1, 1))\n\n# Plot the regression curves\nplt.scatter(x, y, label='Data')\nplt.plot(x_test, y_linear, label='Linear')\nplt.plot(x_test, y_quadratic, label='Quadratic')\nplt.plot(x_test, y_cubic, label='Cubic')\nplt.xlabel('x')\nplt.ylabel('y')\nplt.title('Polynomial Regression')\nplt.legend()\nplt.show()\n```\n\n::: {.cell-output .cell-output-display}\n![](Model_files/figure-html/cell-3-output-1.png){width=585 height=449}\n:::\n:::\n\n\nIn the above code, we fit three polynomial regression models: linear, quadratic, and cubic regression. The degree of the polynomial is indicated by the `degree` parameter in the `PolynomialFeatures` class. We can observe that as we increase the complexity (degree) of the polynomial, the models can better capture the underlying quadratic relationship.\n\nHowever, it's important to note that high-capacity models can also be prone to overfitting, especially when the amount of training data is limited. Therefore, it's crucial to balance the model's capacity with the complexity of the problem at hand and the size of the training dataset.\n\nTo summarize, model capacity refers to the amount of information or patterns a machine learning model can learn from the data. It is determined by the number of parameters that the model needs to estimate. Increasing the model's capacity can improve its ability to represent complex relationships in the data, but it can also increase the risk of overfitting.\n\n",
    "supporting": [
      "Model_files"
    ],
    "filters": [],
    "includes": {}
  }
}