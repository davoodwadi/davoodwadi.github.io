{"title":"Multiple Linear Regression - Part 2","markdown":{"yaml":{"title":"Multiple Linear Regression - Part 2","format":{"html":{"code-fold":false}},"jupyter":"python3","execute":{"cache":true}},"headingText":"Define the design matrix X","containsRefs":false,"markdown":"\n\n\nMultiple linear regression is a powerful technique used for predicting a continuous outcome variable based on multiple predictor variables. In this tutorial, we will learn how to perform multiple linear regression using a design matrix in Python. \n\nFirst, let's define the problem. In multiple linear regression, we have a dependent variable (also called the response or target variable) and several independent variables (also called features, input variables, or predictors). The goal is to find the best linear relationship between the predictors and the target variable.\n\nThe general equation for a multiple linear regression model with 'p' predictors is given by:\n\nY = β₀ + β₁X₁ + β₂X₂ + ... + βₚXₚ + ε\n\nWhere:\n- Y is the target variable\n- X₁, X₂, ..., Xₚ are the predictor variables\n- β₀, β₁, β₂, ..., βₚ are the coefficients (or weights) of the predictors\n- ε is the error term, representing the randomness or noise in the relationship\n\nTo estimate the coefficients (β₀, β₁, β₂, ..., βₚ), we need to minimize the sum of squared residuals, which measures the differences between the actual values of the target variable (Y) and the predicted values from the regression model.\n\nIn multiple linear regression, the predictors are often organized into a design matrix (X), where each row represents an observation and each column represents a predictor variable.\n\nNow let's see how to perform multiple linear regression using a design matrix in Python.\n\n```{python}\nimport numpy as np\n\nX = np.array([[3,  3, -3],\n              [-4, 5,  6],\n              [7, -8,  9]])\n\n# Define the target variable Y\nY = np.array([10, 20, 30])\n\n# Calculate beta coefficients using the normal equation\nbeta = np.linalg.inv(X.T @ X) @ X.T @ Y\n\nprint('Beta coefficients:', beta)\n```\n\nIn the above code, we first import the necessary libraries. Then, we define the design matrix X as a 2-dimensional numpy array that contains the predictor variables. Each row represents an observation, and each column represents a predictor variable. We also define the target variable Y as a 1-dimensional numpy array.\n\nNext, we use the normal equation to calculate the beta coefficients. The normal equation is given by:\n\n$$β = (X^T \\cdot X)^{-1} \\cdot X^T \\cdot Y$$\n\n- $X^T$ is the transpose of X\n- $(X^T \\cdot X)^{-1}$ is the inverse of the matrix product of $X^T$ and $X$\n- $X^T \\cdot Y$ is the matrix product of $X^T$ and $Y$\n\nFinally, we print the beta coefficients, which represent the weights or coefficients of the predictors in the multiple linear regression model.","srcMarkdownNoYaml":"\n\n\nMultiple linear regression is a powerful technique used for predicting a continuous outcome variable based on multiple predictor variables. In this tutorial, we will learn how to perform multiple linear regression using a design matrix in Python. \n\nFirst, let's define the problem. In multiple linear regression, we have a dependent variable (also called the response or target variable) and several independent variables (also called features, input variables, or predictors). The goal is to find the best linear relationship between the predictors and the target variable.\n\nThe general equation for a multiple linear regression model with 'p' predictors is given by:\n\nY = β₀ + β₁X₁ + β₂X₂ + ... + βₚXₚ + ε\n\nWhere:\n- Y is the target variable\n- X₁, X₂, ..., Xₚ are the predictor variables\n- β₀, β₁, β₂, ..., βₚ are the coefficients (or weights) of the predictors\n- ε is the error term, representing the randomness or noise in the relationship\n\nTo estimate the coefficients (β₀, β₁, β₂, ..., βₚ), we need to minimize the sum of squared residuals, which measures the differences between the actual values of the target variable (Y) and the predicted values from the regression model.\n\nIn multiple linear regression, the predictors are often organized into a design matrix (X), where each row represents an observation and each column represents a predictor variable.\n\nNow let's see how to perform multiple linear regression using a design matrix in Python.\n\n```{python}\nimport numpy as np\n\n# Define the design matrix X\nX = np.array([[3,  3, -3],\n              [-4, 5,  6],\n              [7, -8,  9]])\n\n# Define the target variable Y\nY = np.array([10, 20, 30])\n\n# Calculate beta coefficients using the normal equation\nbeta = np.linalg.inv(X.T @ X) @ X.T @ Y\n\nprint('Beta coefficients:', beta)\n```\n\nIn the above code, we first import the necessary libraries. Then, we define the design matrix X as a 2-dimensional numpy array that contains the predictor variables. Each row represents an observation, and each column represents a predictor variable. We also define the target variable Y as a 1-dimensional numpy array.\n\nNext, we use the normal equation to calculate the beta coefficients. The normal equation is given by:\n\n$$β = (X^T \\cdot X)^{-1} \\cdot X^T \\cdot Y$$\n\n- $X^T$ is the transpose of X\n- $(X^T \\cdot X)^{-1}$ is the inverse of the matrix product of $X^T$ and $X$\n- $X^T \\cdot Y$ is the matrix product of $X^T$ and $Y$\n\nFinally, we print the beta coefficients, which represent the weights or coefficients of the predictors in the multiple linear regression model."},"formats":{"html":{"identifier":{"display-name":"HTML","target-format":"html","base-format":"html"},"execute":{"fig-width":7,"fig-height":5,"fig-format":"retina","fig-dpi":96,"df-print":"default","error":false,"eval":true,"cache":true,"freeze":true,"echo":true,"output":true,"warning":true,"include":true,"keep-md":false,"keep-ipynb":false,"ipynb":null,"enabled":null,"daemon":null,"daemon-restart":false,"debug":false,"ipynb-filters":[],"ipynb-shell-interactivity":null,"plotly-connected":true,"engine":"jupyter"},"render":{"keep-tex":false,"keep-typ":false,"keep-source":false,"keep-hidden":false,"prefer-html":false,"output-divs":true,"output-ext":"html","fig-align":"default","fig-pos":null,"fig-env":null,"code-fold":false,"code-overflow":"scroll","code-link":false,"code-line-numbers":false,"code-tools":false,"tbl-colwidths":"auto","merge-includes":true,"inline-includes":false,"preserve-yaml":false,"latex-auto-mk":true,"latex-auto-install":true,"latex-clean":true,"latex-min-runs":1,"latex-max-runs":10,"latex-makeindex":"makeindex","latex-makeindex-opts":[],"latex-tlmgr-opts":[],"latex-input-paths":[],"latex-output-dir":null,"link-external-icon":false,"link-external-newwindow":false,"self-contained-math":false,"format-resources":[],"notebook-links":true},"pandoc":{"standalone":true,"wrap":"none","default-image-extension":"png","to":"html","css":["../styles.css"],"toc":true,"output-file":"multip2.html"},"language":{"toc-title-document":"Table of contents","toc-title-website":"On this page","related-formats-title":"Other Formats","related-notebooks-title":"Notebooks","source-notebooks-prefix":"Source","other-links-title":"Other Links","code-links-title":"Code Links","launch-dev-container-title":"Launch Dev Container","launch-binder-title":"Launch Binder","article-notebook-label":"Article Notebook","notebook-preview-download":"Download Notebook","notebook-preview-download-src":"Download Source","notebook-preview-back":"Back to Article","manuscript-meca-bundle":"MECA Bundle","section-title-abstract":"Abstract","section-title-appendices":"Appendices","section-title-footnotes":"Footnotes","section-title-references":"References","section-title-reuse":"Reuse","section-title-copyright":"Copyright","section-title-citation":"Citation","appendix-attribution-cite-as":"For attribution, please cite this work as:","appendix-attribution-bibtex":"BibTeX citation:","appendix-view-license":"View License","title-block-author-single":"Author","title-block-author-plural":"Authors","title-block-affiliation-single":"Affiliation","title-block-affiliation-plural":"Affiliations","title-block-published":"Published","title-block-modified":"Modified","title-block-keywords":"Keywords","callout-tip-title":"Tip","callout-note-title":"Note","callout-warning-title":"Warning","callout-important-title":"Important","callout-caution-title":"Caution","code-summary":"Code","code-tools-menu-caption":"Code","code-tools-show-all-code":"Show All Code","code-tools-hide-all-code":"Hide All Code","code-tools-view-source":"View Source","code-tools-source-code":"Source Code","tools-share":"Share","tools-download":"Download","code-line":"Line","code-lines":"Lines","copy-button-tooltip":"Copy to Clipboard","copy-button-tooltip-success":"Copied!","repo-action-links-edit":"Edit this page","repo-action-links-source":"View source","repo-action-links-issue":"Report an issue","back-to-top":"Back to top","search-no-results-text":"No results","search-matching-documents-text":"matching documents","search-copy-link-title":"Copy link to search","search-hide-matches-text":"Hide additional matches","search-more-match-text":"more match in this document","search-more-matches-text":"more matches in this document","search-clear-button-title":"Clear","search-text-placeholder":"","search-detached-cancel-button-title":"Cancel","search-submit-button-title":"Submit","search-label":"Search","toggle-section":"Toggle section","toggle-sidebar":"Toggle sidebar navigation","toggle-dark-mode":"Toggle dark mode","toggle-reader-mode":"Toggle reader mode","toggle-navigation":"Toggle navigation","crossref-fig-title":"Figure","crossref-tbl-title":"Table","crossref-lst-title":"Listing","crossref-thm-title":"Theorem","crossref-lem-title":"Lemma","crossref-cor-title":"Corollary","crossref-prp-title":"Proposition","crossref-cnj-title":"Conjecture","crossref-def-title":"Definition","crossref-exm-title":"Example","crossref-exr-title":"Exercise","crossref-ch-prefix":"Chapter","crossref-apx-prefix":"Appendix","crossref-sec-prefix":"Section","crossref-eq-prefix":"Equation","crossref-lof-title":"List of Figures","crossref-lot-title":"List of Tables","crossref-lol-title":"List of Listings","environment-proof-title":"Proof","environment-remark-title":"Remark","environment-solution-title":"Solution","listing-page-order-by":"Order By","listing-page-order-by-default":"Default","listing-page-order-by-date-asc":"Oldest","listing-page-order-by-date-desc":"Newest","listing-page-order-by-number-desc":"High to Low","listing-page-order-by-number-asc":"Low to High","listing-page-field-date":"Date","listing-page-field-title":"Title","listing-page-field-description":"Description","listing-page-field-author":"Author","listing-page-field-filename":"File Name","listing-page-field-filemodified":"Modified","listing-page-field-subtitle":"Subtitle","listing-page-field-readingtime":"Reading Time","listing-page-field-wordcount":"Word Count","listing-page-field-categories":"Categories","listing-page-minutes-compact":"{0} min","listing-page-category-all":"All","listing-page-no-matches":"No matching items","listing-page-words":"{0} words","listing-page-filter":"Filter","draft":"Draft"},"metadata":{"lang":"en","fig-responsive":true,"quarto-version":"1.5.55","theme":"cosmo","title":"Multiple Linear Regression - Part 2","jupyter":"python3"},"extensions":{"book":{"multiFile":true}}}},"projectFormats":["html"]}