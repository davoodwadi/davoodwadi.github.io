{"title":"Overfitting","markdown":{"yaml":{"title":"Overfitting","format":{"html":{"code-fold":false}},"jupyter":"python3","execute":{"cache":true}},"headingText":"Generate the dataset","containsRefs":false,"markdown":"\n\nOverfitting occurs when a machine learning model performs very well on the training data, but fails to generalize well on unseen data. It happens when the model captures noise and random fluctuations in the training data instead of the underlying pattern or relationship.\n\nOne way to understand overfitting is to consider fitting a polynomial to data points. The degree of the polynomial determines its complexity. A higher degree polynomial can fit the training data more closely, but it may also capture random noise, resulting in poor performance on new data.\n\nTo demonstrate overfitting using polynomials, we will generate a dataset with some noise and fit polynomials of different degrees to it. We will then visualize the models to see how they fit the data.\n\nLet's start by importing the necessary libraries and generating the dataset. We will use the `numpy` library for array operations and random number generation, and the `matplotlib` library for data visualization.\n\n```{python}\nimport numpy as np\nimport matplotlib.pyplot as plt\n\nnp.random.seed(0)\nX = np.linspace(-1, 1, 20)\ny = 2 * X + np.random.normal(0, 0.5, 20)\n```\n\nIn the above code, we first import the required libraries: `numpy` and `matplotlib.pyplot`. We then set a random seed to ensure reproducibility.\n\nNext, we create an array `X` with 20 equally spaced points between -1 and 1 using the `linspace` function. We add some noise to the array `y` using the `numpy.random.normal` function. Here, we use a linear relationship with some Gaussian noise to generate our dataset.\n\nNow, we will plot the generated dataset to visualize it.\n\n```{python}\nplt.scatter(X, y)\nplt.xlabel('X')\nplt.ylabel('y')\nplt.title('Dataset')\nplt.show()\n```\n\nThe code above uses the `scatter` function from `matplotlib.pyplot` to create a scatter plot of the dataset. It also adds labels to the x and y axes and sets a title for the plot. Finally, the `show` function is called to display the plot.\n\nNow, let's fit polynomials of different degrees to the dataset and see how they fit the data.\n\n```{python}\n# Polynomial fitting and visualization\ndegrees = [1, 3, 9, 12]\n\nplt.scatter(X, y)\n\nfor degree in degrees:\n    # Fit polynomial of given degree\n    coeffs = np.polyfit(X, y, degree)\n    poly = np.poly1d(coeffs)\n    \n    # Generate x values for plotting\n    x_plot = np.linspace(-1, 1, 100)\n    \n    # Compute predicted y values\n    y_plot = poly(x_plot)\n    \n    # Plot the polynomial\n    plt.plot(x_plot, y_plot, label=f'Degree {degree}')\n\nplt.xlabel('X')\nplt.ylabel('y')\nplt.title('Fitting Polynomials')\nplt.legend()\nplt.show()\n```\n\nIn the above code, we define a list `degrees` with the degrees of the polynomials that we want to fit to the dataset. We then iterate over each degree and perform the following steps:\n\n- Fit a polynomial of the given degree to the dataset using the `polyfit` function from `numpy`.\n- Create a polynomial object using the computed coefficients using the `poly1d` function from `numpy`.\n- Generate a set of x values for plotting using the `linspace` function from `numpy`.\n- Compute the predicted y values for the generated x values using the polynomial.\n- Plot the polynomial curve using the `plot` function from `matplotlib.pyplot` with a label indicating the degree of the polynomial.\n\nFinally, we add labels and a title to the plot, and display a legend to distinguish the different polynomial curves.\n\nWhen you run the code, you will see a plot showing the dataset points as scatter points, and different polynomial curves fitted to the data. From this visualization, you can observe the effect of overfitting as the degree of the polynomial increases. Higher degree polynomials tend to fit the training data more closely, but they also capture random noise and fluctuations, resulting in poor generalization to new data.","srcMarkdownNoYaml":"\n\nOverfitting occurs when a machine learning model performs very well on the training data, but fails to generalize well on unseen data. It happens when the model captures noise and random fluctuations in the training data instead of the underlying pattern or relationship.\n\nOne way to understand overfitting is to consider fitting a polynomial to data points. The degree of the polynomial determines its complexity. A higher degree polynomial can fit the training data more closely, but it may also capture random noise, resulting in poor performance on new data.\n\nTo demonstrate overfitting using polynomials, we will generate a dataset with some noise and fit polynomials of different degrees to it. We will then visualize the models to see how they fit the data.\n\nLet's start by importing the necessary libraries and generating the dataset. We will use the `numpy` library for array operations and random number generation, and the `matplotlib` library for data visualization.\n\n```{python}\nimport numpy as np\nimport matplotlib.pyplot as plt\n\n# Generate the dataset\nnp.random.seed(0)\nX = np.linspace(-1, 1, 20)\ny = 2 * X + np.random.normal(0, 0.5, 20)\n```\n\nIn the above code, we first import the required libraries: `numpy` and `matplotlib.pyplot`. We then set a random seed to ensure reproducibility.\n\nNext, we create an array `X` with 20 equally spaced points between -1 and 1 using the `linspace` function. We add some noise to the array `y` using the `numpy.random.normal` function. Here, we use a linear relationship with some Gaussian noise to generate our dataset.\n\nNow, we will plot the generated dataset to visualize it.\n\n```{python}\nplt.scatter(X, y)\nplt.xlabel('X')\nplt.ylabel('y')\nplt.title('Dataset')\nplt.show()\n```\n\nThe code above uses the `scatter` function from `matplotlib.pyplot` to create a scatter plot of the dataset. It also adds labels to the x and y axes and sets a title for the plot. Finally, the `show` function is called to display the plot.\n\nNow, let's fit polynomials of different degrees to the dataset and see how they fit the data.\n\n```{python}\n# Polynomial fitting and visualization\ndegrees = [1, 3, 9, 12]\n\nplt.scatter(X, y)\n\nfor degree in degrees:\n    # Fit polynomial of given degree\n    coeffs = np.polyfit(X, y, degree)\n    poly = np.poly1d(coeffs)\n    \n    # Generate x values for plotting\n    x_plot = np.linspace(-1, 1, 100)\n    \n    # Compute predicted y values\n    y_plot = poly(x_plot)\n    \n    # Plot the polynomial\n    plt.plot(x_plot, y_plot, label=f'Degree {degree}')\n\nplt.xlabel('X')\nplt.ylabel('y')\nplt.title('Fitting Polynomials')\nplt.legend()\nplt.show()\n```\n\nIn the above code, we define a list `degrees` with the degrees of the polynomials that we want to fit to the dataset. We then iterate over each degree and perform the following steps:\n\n- Fit a polynomial of the given degree to the dataset using the `polyfit` function from `numpy`.\n- Create a polynomial object using the computed coefficients using the `poly1d` function from `numpy`.\n- Generate a set of x values for plotting using the `linspace` function from `numpy`.\n- Compute the predicted y values for the generated x values using the polynomial.\n- Plot the polynomial curve using the `plot` function from `matplotlib.pyplot` with a label indicating the degree of the polynomial.\n\nFinally, we add labels and a title to the plot, and display a legend to distinguish the different polynomial curves.\n\nWhen you run the code, you will see a plot showing the dataset points as scatter points, and different polynomial curves fitted to the data. From this visualization, you can observe the effect of overfitting as the degree of the polynomial increases. Higher degree polynomials tend to fit the training data more closely, but they also capture random noise and fluctuations, resulting in poor generalization to new data."},"formats":{"html":{"identifier":{"display-name":"HTML","target-format":"html","base-format":"html"},"execute":{"fig-width":7,"fig-height":5,"fig-format":"retina","fig-dpi":96,"df-print":"default","error":false,"eval":true,"cache":true,"freeze":true,"echo":true,"output":true,"warning":true,"include":true,"keep-md":false,"keep-ipynb":false,"ipynb":null,"enabled":null,"daemon":null,"daemon-restart":false,"debug":false,"ipynb-filters":[],"ipynb-shell-interactivity":null,"plotly-connected":true,"engine":"jupyter"},"render":{"keep-tex":false,"keep-typ":false,"keep-source":false,"keep-hidden":false,"prefer-html":false,"output-divs":true,"output-ext":"html","fig-align":"default","fig-pos":null,"fig-env":null,"code-fold":false,"code-overflow":"scroll","code-link":false,"code-line-numbers":false,"code-tools":false,"tbl-colwidths":"auto","merge-includes":true,"inline-includes":false,"preserve-yaml":false,"latex-auto-mk":true,"latex-auto-install":true,"latex-clean":true,"latex-min-runs":1,"latex-max-runs":10,"latex-makeindex":"makeindex","latex-makeindex-opts":[],"latex-tlmgr-opts":[],"latex-input-paths":[],"latex-output-dir":null,"link-external-icon":false,"link-external-newwindow":false,"self-contained-math":false,"format-resources":[],"notebook-links":true},"pandoc":{"standalone":true,"wrap":"none","default-image-extension":"png","to":"html","css":["../styles.css"],"toc":true,"output-file":"overfi.html"},"language":{"toc-title-document":"Table of contents","toc-title-website":"On this page","related-formats-title":"Other Formats","related-notebooks-title":"Notebooks","source-notebooks-prefix":"Source","other-links-title":"Other Links","code-links-title":"Code Links","launch-dev-container-title":"Launch Dev Container","launch-binder-title":"Launch Binder","article-notebook-label":"Article Notebook","notebook-preview-download":"Download Notebook","notebook-preview-download-src":"Download Source","notebook-preview-back":"Back to Article","manuscript-meca-bundle":"MECA Bundle","section-title-abstract":"Abstract","section-title-appendices":"Appendices","section-title-footnotes":"Footnotes","section-title-references":"References","section-title-reuse":"Reuse","section-title-copyright":"Copyright","section-title-citation":"Citation","appendix-attribution-cite-as":"For attribution, please cite this work as:","appendix-attribution-bibtex":"BibTeX citation:","appendix-view-license":"View License","title-block-author-single":"Author","title-block-author-plural":"Authors","title-block-affiliation-single":"Affiliation","title-block-affiliation-plural":"Affiliations","title-block-published":"Published","title-block-modified":"Modified","title-block-keywords":"Keywords","callout-tip-title":"Tip","callout-note-title":"Note","callout-warning-title":"Warning","callout-important-title":"Important","callout-caution-title":"Caution","code-summary":"Code","code-tools-menu-caption":"Code","code-tools-show-all-code":"Show All Code","code-tools-hide-all-code":"Hide All Code","code-tools-view-source":"View Source","code-tools-source-code":"Source Code","tools-share":"Share","tools-download":"Download","code-line":"Line","code-lines":"Lines","copy-button-tooltip":"Copy to Clipboard","copy-button-tooltip-success":"Copied!","repo-action-links-edit":"Edit this page","repo-action-links-source":"View source","repo-action-links-issue":"Report an issue","back-to-top":"Back to top","search-no-results-text":"No results","search-matching-documents-text":"matching documents","search-copy-link-title":"Copy link to search","search-hide-matches-text":"Hide additional matches","search-more-match-text":"more match in this document","search-more-matches-text":"more matches in this document","search-clear-button-title":"Clear","search-text-placeholder":"","search-detached-cancel-button-title":"Cancel","search-submit-button-title":"Submit","search-label":"Search","toggle-section":"Toggle section","toggle-sidebar":"Toggle sidebar navigation","toggle-dark-mode":"Toggle dark mode","toggle-reader-mode":"Toggle reader mode","toggle-navigation":"Toggle navigation","crossref-fig-title":"Figure","crossref-tbl-title":"Table","crossref-lst-title":"Listing","crossref-thm-title":"Theorem","crossref-lem-title":"Lemma","crossref-cor-title":"Corollary","crossref-prp-title":"Proposition","crossref-cnj-title":"Conjecture","crossref-def-title":"Definition","crossref-exm-title":"Example","crossref-exr-title":"Exercise","crossref-ch-prefix":"Chapter","crossref-apx-prefix":"Appendix","crossref-sec-prefix":"Section","crossref-eq-prefix":"Equation","crossref-lof-title":"List of Figures","crossref-lot-title":"List of Tables","crossref-lol-title":"List of Listings","environment-proof-title":"Proof","environment-remark-title":"Remark","environment-solution-title":"Solution","listing-page-order-by":"Order By","listing-page-order-by-default":"Default","listing-page-order-by-date-asc":"Oldest","listing-page-order-by-date-desc":"Newest","listing-page-order-by-number-desc":"High to Low","listing-page-order-by-number-asc":"Low to High","listing-page-field-date":"Date","listing-page-field-title":"Title","listing-page-field-description":"Description","listing-page-field-author":"Author","listing-page-field-filename":"File Name","listing-page-field-filemodified":"Modified","listing-page-field-subtitle":"Subtitle","listing-page-field-readingtime":"Reading Time","listing-page-field-wordcount":"Word Count","listing-page-field-categories":"Categories","listing-page-minutes-compact":"{0} min","listing-page-category-all":"All","listing-page-no-matches":"No matching items","listing-page-words":"{0} words","listing-page-filter":"Filter","draft":"Draft"},"metadata":{"lang":"en","fig-responsive":true,"quarto-version":"1.5.55","theme":"cosmo","title":"Overfitting","jupyter":"python3"},"extensions":{"book":{"multiFile":true}}}},"projectFormats":["html","revealjs"]}