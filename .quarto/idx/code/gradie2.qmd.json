{"title":"Gradient Descent with PyTorch","markdown":{"yaml":{"title":"","format":{"html":{"code-fold":false}},"jupyter":"python3","execute":{"cache":true}},"headingText":"Gradient Descent with PyTorch","containsRefs":false,"markdown":"\n\n\n\nIn this tutorial, we will learn how to implement the Gradient Descent algorithm using PyTorch. Gradient Descent is an optimization algorithm commonly used in machine learning to find the optimal parameters of a model by iteratively updating them based on the gradient of a cost function.\n\nWe will start by explaining the theory behind Gradient Descent, then move on to implementing it in PyTorch.\n\n## Theory\n\nGradient Descent works by iteratively updating the parameters of a model in the opposite direction of the gradient of a cost function. The goal is to find the minimum of the cost function, which corresponds to the optimal parameters for the model.\n\nThe update rule for Gradient Descent is given by:\n\n\n$\\theta = \\theta - \\alpha \\cdot \\nabla J(\\theta)$\n\n\nwhere:\n- $\\theta$ represents the current parameters of the model,\n- $\\alpha$ is the learning rate (step size),\n- $J(\\theta)$ is the cost function, and\n- $\\nabla J(\\theta)$ is the gradient of the cost function with respect to $\\theta$.\n\nThe learning rate $\\alpha$ determines the size of the steps taken in each iteration. Too small of a learning rate may cause the algorithm to converge slowly, while too large of a learning rate may cause it to overshoot the minimum.\n\n## Implementation\n\nNow let's implement Gradient Descent using PyTorch. We will start by generating some sample data and defining a linear regression model. Then, we will define the cost function and gradient descent function.\n\n### Step 1: Generate Sample Data\n\n```{python}\nimport torch\n\n# Set random seed for reproducibility\ntorch.manual_seed(0)\n\n# Generate some dummy data\nX = torch.tensor([[1], [2], [3], [4]], dtype=torch.float32)\ny = torch.tensor([[2], [4], [6], [8]], dtype=torch.float32)\nprint(f\"X is {X}\")\nprint(f\"y is {y}\")\n```\n\nIn this step, we import the `torch` module, set the random seed for reproducibility, and generate some dummy data. Here, `X` represents the input features and `y` represents the corresponding output values.\n\n### Step 2: Define Linear Regression Model\n\n```{python}\nclass LinearRegression(torch.nn.Module):\n    def __init__(self):\n        super(LinearRegression, self).__init__()\n        self.linear = torch.nn.Linear(1, 1)\n        \n    def forward(self, x):\n        y_pred = self.linear(x)\n        return y_pred\n    \nmodel = LinearRegression()\nprint(f\"weight: {model.linear.weight.data}\")\nprint(f\"bias: {model.linear.bias.data}\")\n```\n\nIn this step, we define a linear regression model using PyTorch's `torch.nn.Module` class. The model consists of a single linear layer `self.linear`, which maps the input features to the output values. The `forward` method is used to define the forward pass of the model.\n\n### Step 3: Define Cost Function\n\n```{python}\ncriterion = torch.nn.MSELoss()\n```\n\nIn this step, we define the Mean Squared Error (MSE) loss function using PyTorch's `torch.nn.MSELoss` class. The loss function measures the difference between the predicted values and the actual values.\n\n### Step 4: Define Gradient Descent Function\n\n```{python}\noptimizer = torch.optim.SGD(model.parameters(), lr=0.01)\n\ndef gradient_descent(X, y, model, criterion, optimizer, num_epochs):\n    for epoch in range(num_epochs):\n        # Forward pass\n        y_pred = model(X)\n        \n        # Compute loss\n        loss = criterion(y_pred, y)\n        \n        # Backward pass and optimization\n        optimizer.zero_grad()\n        loss.backward()\n        optimizer.step()\n        \n        if (epoch+1) % 200 == 0:\n            print(f'Epoch: {epoch+1}, Loss: {loss.item():.3f}, Weight: {model.linear.weight.data.item():.3f}, bias: {model.linear.bias.data.item():.3f}')\n```\n\nIn this step, we define the gradient descent function `gradient_descent`. The function takes the input features `X`, target values `y`, model, criterion (loss function), optimizer, and the number of epochs as input.\n\nIn each epoch, we perform the following steps:\n1. Compute the forward pass of the model to obtain the predicted values.\n2. Compute the loss between the predicted values and the actual values.\n3. Perform backpropagation to compute the gradients.\n4. Update the parameters of the model using the optimizer.\n\nWe also print the loss value every 10 epochs to track the progress of the algorithm.\n\n### Step 5: Run Gradient Descent\n\n```{python}\nnum_epochs = 2000\ngradient_descent(X, y, model, criterion, optimizer, num_epochs)\n```\n\nFinally, we run the gradient descent function with the specified number of epochs. The function will update the parameters of the model in each epoch to minimize the loss.\n\n## Conclusion\n\nIn this tutorial, we learned how to implement the Gradient Descent algorithm using PyTorch. Gradient Descent is a fundamental optimization algorithm used to find the optimal parameters of a model. By iteratively updating the parameters in the direction of the negative gradient, we can find the minimum of a cost function.","srcMarkdownNoYaml":"\n\n\n# Gradient Descent with PyTorch\n\nIn this tutorial, we will learn how to implement the Gradient Descent algorithm using PyTorch. Gradient Descent is an optimization algorithm commonly used in machine learning to find the optimal parameters of a model by iteratively updating them based on the gradient of a cost function.\n\nWe will start by explaining the theory behind Gradient Descent, then move on to implementing it in PyTorch.\n\n## Theory\n\nGradient Descent works by iteratively updating the parameters of a model in the opposite direction of the gradient of a cost function. The goal is to find the minimum of the cost function, which corresponds to the optimal parameters for the model.\n\nThe update rule for Gradient Descent is given by:\n\n\n$\\theta = \\theta - \\alpha \\cdot \\nabla J(\\theta)$\n\n\nwhere:\n- $\\theta$ represents the current parameters of the model,\n- $\\alpha$ is the learning rate (step size),\n- $J(\\theta)$ is the cost function, and\n- $\\nabla J(\\theta)$ is the gradient of the cost function with respect to $\\theta$.\n\nThe learning rate $\\alpha$ determines the size of the steps taken in each iteration. Too small of a learning rate may cause the algorithm to converge slowly, while too large of a learning rate may cause it to overshoot the minimum.\n\n## Implementation\n\nNow let's implement Gradient Descent using PyTorch. We will start by generating some sample data and defining a linear regression model. Then, we will define the cost function and gradient descent function.\n\n### Step 1: Generate Sample Data\n\n```{python}\nimport torch\n\n# Set random seed for reproducibility\ntorch.manual_seed(0)\n\n# Generate some dummy data\nX = torch.tensor([[1], [2], [3], [4]], dtype=torch.float32)\ny = torch.tensor([[2], [4], [6], [8]], dtype=torch.float32)\nprint(f\"X is {X}\")\nprint(f\"y is {y}\")\n```\n\nIn this step, we import the `torch` module, set the random seed for reproducibility, and generate some dummy data. Here, `X` represents the input features and `y` represents the corresponding output values.\n\n### Step 2: Define Linear Regression Model\n\n```{python}\nclass LinearRegression(torch.nn.Module):\n    def __init__(self):\n        super(LinearRegression, self).__init__()\n        self.linear = torch.nn.Linear(1, 1)\n        \n    def forward(self, x):\n        y_pred = self.linear(x)\n        return y_pred\n    \nmodel = LinearRegression()\nprint(f\"weight: {model.linear.weight.data}\")\nprint(f\"bias: {model.linear.bias.data}\")\n```\n\nIn this step, we define a linear regression model using PyTorch's `torch.nn.Module` class. The model consists of a single linear layer `self.linear`, which maps the input features to the output values. The `forward` method is used to define the forward pass of the model.\n\n### Step 3: Define Cost Function\n\n```{python}\ncriterion = torch.nn.MSELoss()\n```\n\nIn this step, we define the Mean Squared Error (MSE) loss function using PyTorch's `torch.nn.MSELoss` class. The loss function measures the difference between the predicted values and the actual values.\n\n### Step 4: Define Gradient Descent Function\n\n```{python}\noptimizer = torch.optim.SGD(model.parameters(), lr=0.01)\n\ndef gradient_descent(X, y, model, criterion, optimizer, num_epochs):\n    for epoch in range(num_epochs):\n        # Forward pass\n        y_pred = model(X)\n        \n        # Compute loss\n        loss = criterion(y_pred, y)\n        \n        # Backward pass and optimization\n        optimizer.zero_grad()\n        loss.backward()\n        optimizer.step()\n        \n        if (epoch+1) % 200 == 0:\n            print(f'Epoch: {epoch+1}, Loss: {loss.item():.3f}, Weight: {model.linear.weight.data.item():.3f}, bias: {model.linear.bias.data.item():.3f}')\n```\n\nIn this step, we define the gradient descent function `gradient_descent`. The function takes the input features `X`, target values `y`, model, criterion (loss function), optimizer, and the number of epochs as input.\n\nIn each epoch, we perform the following steps:\n1. Compute the forward pass of the model to obtain the predicted values.\n2. Compute the loss between the predicted values and the actual values.\n3. Perform backpropagation to compute the gradients.\n4. Update the parameters of the model using the optimizer.\n\nWe also print the loss value every 10 epochs to track the progress of the algorithm.\n\n### Step 5: Run Gradient Descent\n\n```{python}\nnum_epochs = 2000\ngradient_descent(X, y, model, criterion, optimizer, num_epochs)\n```\n\nFinally, we run the gradient descent function with the specified number of epochs. The function will update the parameters of the model in each epoch to minimize the loss.\n\n## Conclusion\n\nIn this tutorial, we learned how to implement the Gradient Descent algorithm using PyTorch. Gradient Descent is a fundamental optimization algorithm used to find the optimal parameters of a model. By iteratively updating the parameters in the direction of the negative gradient, we can find the minimum of a cost function."},"formats":{"html":{"identifier":{"display-name":"HTML","target-format":"html","base-format":"html"},"execute":{"fig-width":7,"fig-height":5,"fig-format":"retina","fig-dpi":96,"df-print":"default","error":false,"eval":true,"cache":true,"freeze":true,"echo":true,"output":true,"warning":true,"include":true,"keep-md":false,"keep-ipynb":false,"ipynb":null,"enabled":null,"daemon":null,"daemon-restart":false,"debug":false,"ipynb-filters":[],"ipynb-shell-interactivity":null,"plotly-connected":true,"engine":"jupyter"},"render":{"keep-tex":false,"keep-typ":false,"keep-source":false,"keep-hidden":false,"prefer-html":false,"output-divs":true,"output-ext":"html","fig-align":"default","fig-pos":null,"fig-env":null,"code-fold":false,"code-overflow":"scroll","code-link":false,"code-line-numbers":false,"code-tools":false,"tbl-colwidths":"auto","merge-includes":true,"inline-includes":false,"preserve-yaml":false,"latex-auto-mk":true,"latex-auto-install":true,"latex-clean":true,"latex-min-runs":1,"latex-max-runs":10,"latex-makeindex":"makeindex","latex-makeindex-opts":[],"latex-tlmgr-opts":[],"latex-input-paths":[],"latex-output-dir":null,"link-external-icon":false,"link-external-newwindow":false,"self-contained-math":false,"format-resources":[],"notebook-links":true},"pandoc":{"standalone":true,"wrap":"none","default-image-extension":"png","to":"html","css":["../styles.css"],"toc":true,"output-file":"gradie2.html"},"language":{"toc-title-document":"Table of contents","toc-title-website":"On this page","related-formats-title":"Other Formats","related-notebooks-title":"Notebooks","source-notebooks-prefix":"Source","other-links-title":"Other Links","code-links-title":"Code Links","launch-dev-container-title":"Launch Dev Container","launch-binder-title":"Launch Binder","article-notebook-label":"Article Notebook","notebook-preview-download":"Download Notebook","notebook-preview-download-src":"Download Source","notebook-preview-back":"Back to Article","manuscript-meca-bundle":"MECA Bundle","section-title-abstract":"Abstract","section-title-appendices":"Appendices","section-title-footnotes":"Footnotes","section-title-references":"References","section-title-reuse":"Reuse","section-title-copyright":"Copyright","section-title-citation":"Citation","appendix-attribution-cite-as":"For attribution, please cite this work as:","appendix-attribution-bibtex":"BibTeX citation:","appendix-view-license":"View License","title-block-author-single":"Author","title-block-author-plural":"Authors","title-block-affiliation-single":"Affiliation","title-block-affiliation-plural":"Affiliations","title-block-published":"Published","title-block-modified":"Modified","title-block-keywords":"Keywords","callout-tip-title":"Tip","callout-note-title":"Note","callout-warning-title":"Warning","callout-important-title":"Important","callout-caution-title":"Caution","code-summary":"Code","code-tools-menu-caption":"Code","code-tools-show-all-code":"Show All Code","code-tools-hide-all-code":"Hide All Code","code-tools-view-source":"View Source","code-tools-source-code":"Source Code","tools-share":"Share","tools-download":"Download","code-line":"Line","code-lines":"Lines","copy-button-tooltip":"Copy to Clipboard","copy-button-tooltip-success":"Copied!","repo-action-links-edit":"Edit this page","repo-action-links-source":"View source","repo-action-links-issue":"Report an issue","back-to-top":"Back to top","search-no-results-text":"No results","search-matching-documents-text":"matching documents","search-copy-link-title":"Copy link to search","search-hide-matches-text":"Hide additional matches","search-more-match-text":"more match in this document","search-more-matches-text":"more matches in this document","search-clear-button-title":"Clear","search-text-placeholder":"","search-detached-cancel-button-title":"Cancel","search-submit-button-title":"Submit","search-label":"Search","toggle-section":"Toggle section","toggle-sidebar":"Toggle sidebar navigation","toggle-dark-mode":"Toggle dark mode","toggle-reader-mode":"Toggle reader mode","toggle-navigation":"Toggle navigation","crossref-fig-title":"Figure","crossref-tbl-title":"Table","crossref-lst-title":"Listing","crossref-thm-title":"Theorem","crossref-lem-title":"Lemma","crossref-cor-title":"Corollary","crossref-prp-title":"Proposition","crossref-cnj-title":"Conjecture","crossref-def-title":"Definition","crossref-exm-title":"Example","crossref-exr-title":"Exercise","crossref-ch-prefix":"Chapter","crossref-apx-prefix":"Appendix","crossref-sec-prefix":"Section","crossref-eq-prefix":"Equation","crossref-lof-title":"List of Figures","crossref-lot-title":"List of Tables","crossref-lol-title":"List of Listings","environment-proof-title":"Proof","environment-remark-title":"Remark","environment-solution-title":"Solution","listing-page-order-by":"Order By","listing-page-order-by-default":"Default","listing-page-order-by-date-asc":"Oldest","listing-page-order-by-date-desc":"Newest","listing-page-order-by-number-desc":"High to Low","listing-page-order-by-number-asc":"Low to High","listing-page-field-date":"Date","listing-page-field-title":"Title","listing-page-field-description":"Description","listing-page-field-author":"Author","listing-page-field-filename":"File Name","listing-page-field-filemodified":"Modified","listing-page-field-subtitle":"Subtitle","listing-page-field-readingtime":"Reading Time","listing-page-field-wordcount":"Word Count","listing-page-field-categories":"Categories","listing-page-minutes-compact":"{0} min","listing-page-category-all":"All","listing-page-no-matches":"No matching items","listing-page-words":"{0} words","listing-page-filter":"Filter","draft":"Draft"},"metadata":{"lang":"en","fig-responsive":true,"quarto-version":"1.5.55","theme":"cosmo","title":"","jupyter":"python3"},"extensions":{"book":{"multiFile":true}}}},"projectFormats":["html","revealjs"]}