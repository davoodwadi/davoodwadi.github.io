{
  "hash": "9ab65c48fe23dfefa850f888fe4ed721",
  "result": {
    "engine": "jupyter",
    "markdown": "---\ntitle: \"Overfitting\"\nformat:\n  html:\n    code-fold: false\njupyter: python3\nexecute: \n  cache: true\n---\n\n\n\n\nOverfitting occurs when a machine learning model performs very well on the training data, but fails to generalize well on unseen data. It happens when the model captures noise and random fluctuations in the training data instead of the underlying pattern or relationship.\n\nOne way to understand overfitting is to consider fitting a polynomial to data points. The degree of the polynomial determines its complexity. A higher degree polynomial can fit the training data more closely, but it may also capture random noise, resulting in poor performance on new data.\n\nTo demonstrate overfitting using polynomials, we will generate a dataset with some noise and fit polynomials of different degrees to it. We will then visualize the models to see how they fit the data.\n\nLet's start by importing the necessary libraries and generating the dataset. We will use the `numpy` library for array operations and random number generation, and the `matplotlib` library for data visualization.\n\n::: {#587b2fb5 .cell execution_count=1}\n``` {.python .cell-code}\nimport numpy as np\nimport matplotlib.pyplot as plt\n\n# Generate the dataset\nnp.random.seed(0)\nX = np.linspace(-1, 1, 20)\ny = 2 * X + np.random.normal(0, 0.5, 20)\n```\n:::\n\n\nIn the above code, we first import the required libraries: `numpy` and `matplotlib.pyplot`. We then set a random seed to ensure reproducibility.\n\nNext, we create an array `X` with 20 equally spaced points between -1 and 1 using the `linspace` function. We add some noise to the array `y` using the `numpy.random.normal` function. Here, we use a linear relationship with some Gaussian noise to generate our dataset.\n\nNow, we will plot the generated dataset to visualize it.\n\n::: {#ba30b44d .cell execution_count=2}\n``` {.python .cell-code}\nplt.scatter(X, y)\nplt.xlabel('X')\nplt.ylabel('y')\nplt.title('Dataset')\nplt.show()\n```\n\n::: {.cell-output .cell-output-display}\n![](overfi_files/figure-html/cell-3-output-1.png){width=600 height=449}\n:::\n:::\n\n\nThe code above uses the `scatter` function from `matplotlib.pyplot` to create a scatter plot of the dataset. It also adds labels to the x and y axes and sets a title for the plot. Finally, the `show` function is called to display the plot.\n\nNow, let's fit polynomials of different degrees to the dataset and see how they fit the data.\n\n::: {#2b11cd24 .cell execution_count=3}\n``` {.python .cell-code}\n# Polynomial fitting and visualization\ndegrees = [1, 3, 9, 12]\n\nplt.scatter(X, y)\n\nfor degree in degrees:\n    # Fit polynomial of given degree\n    coeffs = np.polyfit(X, y, degree)\n    poly = np.poly1d(coeffs)\n    \n    # Generate x values for plotting\n    x_plot = np.linspace(-1, 1, 100)\n    \n    # Compute predicted y values\n    y_plot = poly(x_plot)\n    \n    # Plot the polynomial\n    plt.plot(x_plot, y_plot, label=f'Degree {degree}')\n\nplt.xlabel('X')\nplt.ylabel('y')\nplt.title('Fitting Polynomials')\nplt.legend()\nplt.show()\n```\n\n::: {.cell-output .cell-output-display}\n![](overfi_files/figure-html/cell-4-output-1.png){width=587 height=449}\n:::\n:::\n\n\nIn the above code, we define a list `degrees` with the degrees of the polynomials that we want to fit to the dataset. We then iterate over each degree and perform the following steps:\n\n- Fit a polynomial of the given degree to the dataset using the `polyfit` function from `numpy`.\n- Create a polynomial object using the computed coefficients using the `poly1d` function from `numpy`.\n- Generate a set of x values for plotting using the `linspace` function from `numpy`.\n- Compute the predicted y values for the generated x values using the polynomial.\n- Plot the polynomial curve using the `plot` function from `matplotlib.pyplot` with a label indicating the degree of the polynomial.\n\nFinally, we add labels and a title to the plot, and display a legend to distinguish the different polynomial curves.\n\nWhen you run the code, you will see a plot showing the dataset points as scatter points, and different polynomial curves fitted to the data. From this visualization, you can observe the effect of overfitting as the degree of the polynomial increases. Higher degree polynomials tend to fit the training data more closely, but they also capture random noise and fluctuations, resulting in poor generalization to new data.\n\n",
    "supporting": [
      "overfi_files"
    ],
    "filters": [],
    "includes": {}
  }
}