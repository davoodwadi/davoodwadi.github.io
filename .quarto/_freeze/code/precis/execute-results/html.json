{
  "hash": "18365cc613ffdf9ce016b976fe676e2d",
  "result": {
    "engine": "jupyter",
    "markdown": "---\ntitle: \"\"\nformat:\n  html:\n    code-fold: false\njupyter: python3\nexecute: \n  cache: true\n---\n\n\n\n\n\nThe precision-recall curve is a graphical representation of the trade-off between precision and recall for different threshold values. It is commonly used in binary classification problems where the goal is to classify data into one of two classes.\n\nLet's start by understanding precision and recall:\n\nPrecision is defined as the number of true positives (TP) divided by the sum of true positives and false positives (FP):\n\\[\nPrecision = \\frac{TP}{TP + FP}\n\\]\n\nRecall is defined as the number of true positives (TP) divided by the sum of true positives and false negatives (FN):\n\\[\nRecall = \\frac{TP}{TP + FN}\n\\]\n\nIn a classification problem, a high precision means that the classifier is making fewer false positive predictions, while a high recall means that it is making fewer false negative predictions.\n\nTo create a precision-recall curve, we need a classifier that can provide prediction probabilities or scores for each instance. Then, by varying the threshold on these scores, we can generate different points on the precision-recall curve.\n\nWe will demonstrate this process using the scikit-learn library and the Breast Cancer Wisconsin (Diagnostic) dataset. Let's get started:\n\nStep 1: Import the necessary libraries\n\n::: {#8678dc32 .cell execution_count=1}\n``` {.python .cell-code}\nimport numpy as np\nimport matplotlib.pyplot as plt\nfrom sklearn.datasets import load_breast_cancer\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.linear_model import LogisticRegression\nfrom sklearn.metrics import precision_recall_curve\n```\n:::\n\n\nStep 2: Load and prepare the dataset\n\n::: {#84be8cfc .cell execution_count=2}\n``` {.python .cell-code}\ndata = load_breast_cancer()\nX, y = data.data, data.target\n\n# Split the data into training and testing sets\nX_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n```\n:::\n\n\nStep 3: Train a classifier and obtain prediction probabilities\n\n::: {#ad539055 .cell execution_count=3}\n``` {.python .cell-code}\n# Train a logistic regression classifier\nclassifier = LogisticRegression(max_iter=10_000)\nclassifier.fit(X_train, y_train)\n\n# Obtain prediction probabilities for the test set\ny_prob = classifier.predict_proba(X_test)[:, 1]\n```\n:::\n\n\nStep 4: Calculate precision and recall for different threshold values\n\n::: {#250c35c0 .cell execution_count=4}\n``` {.python .cell-code}\nprecision, recall, thresholds = precision_recall_curve(y_test, y_prob)\n```\n:::\n\n\nStep 5: Plot the precision-recall curve\n\n::: {#454c23ea .cell execution_count=5}\n``` {.python .cell-code}\nplt.plot(thresholds, precision[:-1], label='Precision')\nplt.plot(thresholds, recall[:-1], label='Recall')\nplt.xlabel('Threshold')\nplt.title('Precision-Recall Curve')\nplt.legend()\nplt.show()\n```\n\n::: {.cell-output .cell-output-display}\n![](precis_files/figure-html/cell-6-output-1.png){width=571 height=449}\n:::\n:::\n\n\nIn this code, we first import the necessary libraries such as numpy, matplotlib, scikit-learn modules, and data from scikit-learn's built-in Breast Cancer Wisconsin dataset.\n\nNext, we load and prepare the dataset. We split it into training and testing sets using the `train_test_split` function.\n\nThen, we train a logistic regression classifier on the training set and obtain prediction probabilities for the test set using the `predict_proba` method.\n\nFinally, we calculate precision and recall values for different threshold values using the `precision_recall_curve` function. We plot these values to visualize the precision-recall curve using the `plt.plot` function.\n\nThe resulting precision-recall curve shows how the precision and recall values change for different threshold values. A higher precision and recall value indicates a better classifier performance.\n\nThis curve can be useful in identifying an appropriate threshold value that balances precision and recall according to the specific problem requirements.\n\n",
    "supporting": [
      "precis_files/figure-html"
    ],
    "filters": [],
    "includes": {}
  }
}